# =============================================================================
# ç”¨æˆ·é…ç½®å‚æ•° - åœ¨è¿™é‡Œä¿®æ”¹æ‰€æœ‰è®¾ç½®
# =============================================================================

# è¾“å…¥æ–‡ä»¶é…ç½®
PROTEIN_FEATURE_FILE = "protein_features.csv"
COMPOUND_FEATURE_FILE = "69ä¸‡å…¨éƒ¨ç‰¹å¾.csv"

# æ¨¡å‹ç›®å½•é…ç½®
MODEL_BASE_DIR = "æ–°è›‹ç™½ç‰¹å¾æ ¸å—ä½“Combine_BioAssayæ–°ç‰¹å¾"
SELECTED_MODEL_TYPES = ["æ ‡å‡†éšæœºåˆ†å‰²"]

# æ‰¹å¤„ç†é…ç½® - å†…å­˜ä¼˜åŒ–å…³é”®å‚æ•°
BATCH_SIZE = 100000  # å‡å°æ‰¹å¤„ç†å¤§å°ä»¥èŠ‚çœå†…å­˜
MAX_MEMORY_GB = 16  # ä¿å®ˆçš„å†…å­˜é™åˆ¶
USE_MEMORY_EFFICIENT_MODE = True

# å…·ä½“æ¨¡å‹é€‰æ‹© - æ¨èåªé€‰æ‹©è½»é‡çº§æ¨¡å‹
SELECTED_MODELS = {
    "æ ‡å‡†éšæœºåˆ†å‰²": ["å †å åˆ†ç±»å™¨_æ ‡å‡†éšæœºåˆ†å‰²", "éšæœºæ£®æ—", "æç«¯éšæœºæ ‘"],  # åªé€‰æ‹©å†…å­˜æ•ˆç‡é«˜çš„æ¨¡å‹
    # "è›‹ç™½è´¨å†·å¯åŠ¨": ["é€»è¾‘å›å½’", "æœ´ç´ è´å¶æ–¯"],
    # "è¯ç‰©å†·å¯åŠ¨": ["é€»è¾‘å›å½’", "æœ´ç´ è´å¶æ–¯"],
    # "åŒé‡å†·å¯åŠ¨": ["é€»è¾‘å›å½’", "æœ´ç´ è´å¶æ–¯"],
}

# è¾“å‡ºé…ç½®
OUTPUT_BASE_DIR = "å…±è¯†é¢„æµ‹69ä¸‡æ¡"
DETAILED_OUTPUT = True
SAVE_PROBABILITIES = True
SEPARATE_MODEL_RESULTS = True

# é¢„æµ‹è®¾ç½®
USE_ENSEMBLE_MODELS = False  # å¤§æ•°æ®é‡æ—¶å»ºè®®å…³é—­é›†æˆæ¨¡å‹
CONFIDENCE_THRESHOLD = 0.5
PREDICTION_MODE = "all_combinations"  # åä¸‡æ¡æ•°æ®åº”è¯¥æ˜¯å¤šç»„åˆæ¨¡å¼

# äº¤äº’å¼æ¨¡å‹é€‰æ‹©
INTERACTIVE_MODEL_SELECTION = False  # æ”¹ä¸ºFalseä½¿ç”¨ä¸Šé¢çš„SELECTED_MODELSé…ç½®

# è¿›åº¦æ˜¾ç¤º
SHOW_PROGRESS = True

# è·³è¿‡æœ‰é—®é¢˜çš„æ¨¡å‹
SKIP_ENSEMBLE_MODELS = False  # è·³è¿‡å †å åˆ†ç±»å™¨å’ŒæŠ•ç¥¨åˆ†ç±»å™¨
SKIP_MEMORY_INTENSIVE_MODELS = False  # è·³è¿‡SVMã€éšæœºæ£®æ—ç­‰å†…å­˜å¯†é›†æ¨¡å‹

# ============= æ–°å¢ï¼šå…±è¯†é¢„æµ‹é…ç½® =============
ENABLE_CONSENSUS_ANALYSIS = True  # å¯ç”¨å…±è¯†åˆ†æ
MIN_CONSENSUS_MODELS = 2  # è‡³å°‘å‡ ä¸ªæ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹æ‰ç®—å…±è¯†ï¼ˆè®¾ä¸º2è¡¨ç¤ºè‡³å°‘2ä¸ªæ¨¡å‹åŒæ„ï¼‰
CONSENSUS_PROBABILITY_THRESHOLD = 0.5  # å…±è¯†é¢„æµ‹çš„æ¦‚ç‡é˜ˆå€¼
SAVE_CONSENSUS_RESULTS = True  # ä¿å­˜å…±è¯†ç»“æœ
CONSENSUS_OUTPUT_DETAILED = True  # è¾“å‡ºè¯¦ç»†çš„å…±è¯†ä¿¡æ¯

# å…±è¯†åˆ†æç±»å‹
CONSENSUS_ANALYSIS_TYPES = [
    "all_positive",  # æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹
    #"majority_positive",  # å¤§å¤šæ•°æ¨¡å‹é¢„æµ‹ä¸ºæ­£ä¾‹
    #"high_confidence_positive"  # é«˜ç½®ä¿¡åº¦æ­£ä¾‹é¢„æµ‹
]

# =============================================================================
# å¯¼å…¥æ‰€éœ€åº“
# =============================================================================

import os
import sys
import numpy as np
import pandas as pd
import joblib
import warnings
from datetime import datetime
import json
import gc
from tqdm import tqdm
from sklearn.base import clone
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import StratifiedKFold
from joblib import Parallel, delayed
from collections import defaultdict, Counter

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')


# =============================================================================
# æ–°å¢ï¼šJSONåºåˆ—åŒ–è¾…åŠ©å‡½æ•°
# =============================================================================

def convert_numpy_types(obj):
    """é€’å½’è½¬æ¢NumPyæ•°æ®ç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹ï¼Œç”¨äºJSONåºåˆ—åŒ–"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj


def safe_json_dump(obj, file_path, **kwargs):
    """å®‰å…¨åœ°å°†å¯¹è±¡ä¿å­˜ä¸ºJSONï¼Œè‡ªåŠ¨å¤„ç†NumPyç±»å‹è½¬æ¢"""
    try:
        converted_obj = convert_numpy_types(obj)
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(converted_obj, f, **kwargs)
        return True
    except Exception as e:
        print(f"ä¿å­˜JSONæ–‡ä»¶å¤±è´¥: {e}")
        return False


# =============================================================================
# å…³é”®ä¿®å¤ï¼šè‡ªå®šä¹‰åˆ†ç±»å™¨ç±»å®šä¹‰ï¼ˆå¿…é¡»åœ¨å¯¼å…¥å‰å®šä¹‰ï¼‰
# =============================================================================

class CustomVotingClassifier:
    """è‡ªå®šä¹‰æŠ•ç¥¨åˆ†ç±»å™¨ - ä¸è®­ç»ƒä»£ç å®Œå…¨ä¸€è‡´"""

    def __init__(self, estimators, voting='soft'):
        self.estimators = estimators
        self.voting = voting
        self.classes_ = None
        self.named_estimators_ = dict(estimators)

    def get_params(self, deep=True):
        params = {'voting': self.voting}
        if deep:
            estimators_params = {}
            for name, estimator in self.estimators:
                if hasattr(estimator, 'get_params'):
                    for key, val in estimator.get_params(deep).items():
                        estimators_params[f'{name}__{key}'] = val
            params.update(estimators_params)
        params['estimators'] = self.estimators
        return params

    def set_params(self, **params):
        for key, value in params.items():
            if key == 'estimators':
                self.estimators = value
                self.named_estimators_ = dict(value)
            elif key == 'voting':
                self.voting = value
            else:
                try:
                    est_name, param_name = key.split('__', 1)
                    for i, (name, est) in enumerate(self.estimators):
                        if name == est_name and hasattr(est, 'set_params'):
                            self.estimators[i] = (name, est.set_params(**{param_name: value}))
                            break
                except:
                    pass
        return self

    def fit(self, X, y):
        self.classes_ = np.unique(y)
        for name, est in self.estimators:
            try:
                est.fit(X, y)
            except Exception as e:
                print(f"è®­ç»ƒåˆ†ç±»å™¨ {name} æ—¶å‡ºé”™: {e}")
        return self

    def predict(self, X):
        if self.voting == 'hard':
            predictions = np.array([clf.predict(X) for _, clf in self.estimators])
            maj = np.apply_along_axis(
                lambda x: np.argmax(np.bincount(x, minlength=len(self.classes_))),
                axis=0, arr=predictions)
            return self.classes_[maj]
        else:
            predictions = self._collect_probas(X)
            avg = np.average(predictions, axis=0)
            return self.classes_[np.argmax(avg, axis=1)]

    def predict_proba(self, X):
        if self.voting == 'hard':
            raise AttributeError("predict_proba is not available when voting='hard'")
        return np.average(self._collect_probas(X), axis=0)

    def _collect_probas(self, X):
        probas = []
        for name, clf in self.estimators:
            try:
                proba = clf.predict_proba(X)
                probas.append(proba)
            except Exception as e:
                print(f"è·å–åˆ†ç±»å™¨ {name} æ¦‚ç‡æ—¶å‡ºé”™: {e}")
                probas.append(np.zeros((X.shape[0], len(self.classes_))))
        return np.asarray(probas)


class CustomStackingClassifier:
    """è‡ªå®šä¹‰å †å åˆ†ç±»å™¨ - ä¸è®­ç»ƒä»£ç å®Œå…¨ä¸€è‡´"""

    def __init__(self, estimators, final_estimator, cv=5):
        self.estimators = estimators
        self.final_estimator = final_estimator
        self.cv = cv
        self.named_estimators_ = dict(estimators)
        self.classes_ = None

    def get_params(self, deep=True):
        params = {'cv': self.cv}
        params['estimators'] = self.estimators
        params['final_estimator'] = self.final_estimator
        if deep:
            estimators_params = {}
            for name, estimator in self.estimators:
                if hasattr(estimator, 'get_params'):
                    for key, val in estimator.get_params(deep).items():
                        estimators_params[f'{name}__{key}'] = val
            params.update(estimators_params)
            if hasattr(self.final_estimator, 'get_params'):
                for key, val in self.final_estimator.get_params(deep).items():
                    params[f'final_estimator__{key}'] = val
        return params

    def set_params(self, **params):
        for key, value in params.items():
            if key == 'estimators':
                self.estimators = value
                self.named_estimators_ = dict(value)
            elif key == 'final_estimator':
                self.final_estimator = value
            elif key == 'cv':
                self.cv = value
            elif key.startswith('final_estimator__'):
                if hasattr(self.final_estimator, 'set_params'):
                    param_name = key.split('__', 1)[1]
                    self.final_estimator.set_params(**{param_name: value})
            else:
                try:
                    est_name, param_name = key.split('__', 1)
                    for i, (name, est) in enumerate(self.estimators):
                        if name == est_name and hasattr(est, 'set_params'):
                            self.estimators[i] = (name, est.set_params(**{param_name: value}))
                            break
                except:
                    pass
        return self

    def fit(self, X, y):
        self.classes_ = np.unique(y)
        kf = StratifiedKFold(n_splits=self.cv, shuffle=True, random_state=42)
        meta_features = np.zeros((X.shape[0], len(self.estimators) * len(self.classes_)))

        for i, (name, est) in enumerate(self.estimators):
            for train_idx, val_idx in kf.split(X, y):
                X_train, X_val = X[train_idx], X[val_idx]
                y_train = y.iloc[train_idx] if hasattr(y, 'iloc') else y[train_idx]

                try:
                    est_clone = clone(est)
                    est_clone.fit(X_train, y_train)
                    prob = est_clone.predict_proba(X_val)
                    meta_features[val_idx, i * len(self.classes_):(i + 1) * len(self.classes_)] = prob
                except Exception as e:
                    print(f"è®­ç»ƒåŸºç¡€åˆ†ç±»å™¨ {name} æ—¶å‡ºé”™: {e}")

        for name, est in self.estimators:
            try:
                est.fit(X, y)
            except Exception as e:
                print(f"è®­ç»ƒåŸºç¡€åˆ†ç±»å™¨ {name} æœ€ç»ˆç‰ˆæœ¬æ—¶å‡ºé”™: {e}")

        try:
            self.final_estimator.fit(meta_features, y)
        except Exception as e:
            print(f"è®­ç»ƒå…ƒåˆ†ç±»å™¨æ—¶å‡ºé”™: {e}")

        return self

    def predict(self, X):
        meta_features = self._make_meta_features(X)
        return self.final_estimator.predict(meta_features)

    def predict_proba(self, X):
        meta_features = self._make_meta_features(X)
        return self.final_estimator.predict_proba(meta_features)

    def _make_meta_features(self, X):
        meta_features = np.zeros((X.shape[0], len(self.estimators) * len(self.classes_)))

        for i, (name, est) in enumerate(self.estimators):
            try:
                prob = est.predict_proba(X)
                meta_features[:, i * len(self.classes_):(i + 1) * len(self.classes_)] = prob
            except Exception as e:
                print(f"è·å–å…ƒç‰¹å¾æ—¶åˆ†ç±»å™¨ {name} å‡ºé”™: {e}")

        return meta_features


# =============================================================================
# å†…å­˜ç›‘æ§å·¥å…·
# =============================================================================

def get_memory_usage():
    """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆMBï¼‰"""
    try:
        import psutil
        process = psutil.Process(os.getpid())
        return process.memory_info().rss / 1024 / 1024
    except ImportError:
        return 0


def estimate_batch_size(feature_count, max_memory_gb=1):
    """æ ¹æ®ç‰¹å¾æ•°é‡å’Œå¯ç”¨å†…å­˜ä¼°ç®—åˆé€‚çš„æ‰¹å¤„ç†å¤§å°"""
    bytes_per_feature = 8  # float64
    bytes_per_sample = feature_count * bytes_per_feature
    available_memory = max_memory_gb * 1024 * 1024 * 1024 * 0.3  # 30%çš„å†…å­˜ç”¨äºæ‰¹å¤„ç†
    estimated_batch_size = int(available_memory / bytes_per_sample)
    estimated_batch_size = max(50, min(estimated_batch_size, 500))  # é™åˆ¶åœ¨åˆç†èŒƒå›´
    return estimated_batch_size


# =============================================================================
# æ¨¡å‹è¿‡æ»¤å™¨
# =============================================================================

def should_skip_model(model_name):
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æŸä¸ªæ¨¡å‹"""
    model_name_lower = model_name.lower()

    # è·³è¿‡é›†æˆæ¨¡å‹
    if SKIP_ENSEMBLE_MODELS:
        if any(x in model_name_lower for x in ['å †å ', 'æŠ•ç¥¨', 'stacking', 'voting']):
            print(f"    â­ï¸  è·³è¿‡é›†æˆæ¨¡å‹: {model_name}")
            return True

    # è·³è¿‡å†…å­˜å¯†é›†æ¨¡å‹
    if SKIP_MEMORY_INTENSIVE_MODELS:
        if any(x in model_name_lower for x in ['svm', 'éšæœºæ£®æ—', 'æ¢¯åº¦æå‡', 'xgboost', 'lightgbm', 'catboost']):
            print(f"    â­ï¸  è·³è¿‡å†…å­˜å¯†é›†æ¨¡å‹: {model_name}")
            return True

    return False


# =============================================================================
# æ–°å¢ï¼šå…±è¯†åˆ†æç±»ï¼ˆä¿®å¤ç‰ˆï¼‰
# =============================================================================

class ConsensusAnalyzer:
    """å…±è¯†é¢„æµ‹åˆ†æå™¨ï¼ˆä¿®å¤NumPyåºåˆ—åŒ–é—®é¢˜ï¼‰"""

    def __init__(self, min_consensus_models=2, probability_threshold=0.6):
        self.min_consensus_models = min_consensus_models
        self.probability_threshold = probability_threshold
        self.consensus_results = defaultdict(list)

    def analyze_consensus(self, all_results):
        """åˆ†ææ‰€æœ‰æ¨¡å‹çš„å…±è¯†é¢„æµ‹"""
        print(f"\nå¼€å§‹å…±è¯†åˆ†æ...")
        print(f"å…±è¯†è¦æ±‚: è‡³å°‘{self.min_consensus_models}ä¸ªæ¨¡å‹åŒæ„")
        print(f"æ¦‚ç‡é˜ˆå€¼: {self.probability_threshold}")

        # æŒ‰åŒ–åˆç‰©-è›‹ç™½è´¨å¯¹åˆ†ç»„
        compound_predictions = defaultdict(list)

        for result in all_results:
            key = f"{result['protein_id']}_{result['compound_id']}"
            compound_predictions[key].append(result)

        print(f"å…±åˆ†æ {len(compound_predictions)} ä¸ªåŒ–åˆç‰©-è›‹ç™½è´¨å¯¹")

        # åˆ†æä¸åŒç±»å‹çš„å…±è¯†
        consensus_stats = {}

        if "all_positive" in CONSENSUS_ANALYSIS_TYPES:
            all_positive = self._find_all_positive_consensus(compound_predictions)
            consensus_stats["all_positive"] = all_positive
            print(f"æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹: {len(all_positive)} ä¸ª")

        if "majority_positive" in CONSENSUS_ANALYSIS_TYPES:
            majority_positive = self._find_majority_positive_consensus(compound_predictions)
            consensus_stats["majority_positive"] = majority_positive
            print(f"å¤§å¤šæ•°æ¨¡å‹é¢„æµ‹ä¸ºæ­£ä¾‹: {len(majority_positive)} ä¸ª")

        if "high_confidence_positive" in CONSENSUS_ANALYSIS_TYPES:
            high_confidence = self._find_high_confidence_positive(compound_predictions)
            consensus_stats["high_confidence_positive"] = high_confidence
            print(f"é«˜ç½®ä¿¡åº¦æ­£ä¾‹é¢„æµ‹: {len(high_confidence)} ä¸ª")

        return consensus_stats

    def _find_all_positive_consensus(self, compound_predictions):
        """æ‰¾åˆ°æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹çš„åŒ–åˆç‰©"""
        all_positive = []

        for compound_key, predictions in compound_predictions.items():
            if len(predictions) < self.min_consensus_models:
                continue

            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹
            all_positive_pred = all(pred['prediction'] == 1 for pred in predictions)

            if all_positive_pred:
                # è®¡ç®—å¹³å‡æ¦‚ç‡ - ä¿®å¤ï¼šç¡®ä¿è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹
                avg_prob_0 = float(np.mean([pred.get('probability_0', 0.5) for pred in predictions]))
                avg_prob_1 = float(np.mean([pred.get('probability_1', 0.5) for pred in predictions]))
                avg_confidence = float(np.mean([pred.get('confidence', 0.5) for pred in predictions]))

                consensus_info = {
                    'protein_id': str(predictions[0]['protein_id']),
                    'compound_id': str(predictions[0]['compound_id']),
                    'num_models': int(len(predictions)),
                    'consensus_type': 'all_positive',
                    'avg_probability_0': avg_prob_0,
                    'avg_probability_1': avg_prob_1,
                    'avg_confidence': avg_confidence,
                    'model_details': []
                }

                # æ·»åŠ æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯ - ä¿®å¤ï¼šç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯PythonåŸç”Ÿç±»å‹
                for pred in predictions:
                    model_detail = {
                        'model_type': str(pred['model_type']),
                        'model_name': str(pred['model_name']),
                        'prediction': int(pred['prediction']),
                        'prediction_label': str(pred['prediction_label']),
                        'probability_0': float(pred.get('probability_0', 0.5)),
                        'probability_1': float(pred.get('probability_1', 0.5)),
                        'confidence': float(pred.get('confidence', 0.5))
                    }
                    consensus_info['model_details'].append(model_detail)

                all_positive.append(consensus_info)

        return all_positive

    def _find_majority_positive_consensus(self, compound_predictions):
        """æ‰¾åˆ°å¤§å¤šæ•°æ¨¡å‹é¢„æµ‹ä¸ºæ­£ä¾‹çš„åŒ–åˆç‰©"""
        majority_positive = []

        for compound_key, predictions in compound_predictions.items():
            if len(predictions) < self.min_consensus_models:
                continue

            # è®¡ç®—æ­£ä¾‹é¢„æµ‹çš„æ¯”ä¾‹
            positive_count = sum(1 for pred in predictions if pred['prediction'] == 1)
            positive_ratio = positive_count / len(predictions)

            # è¦æ±‚è¶…è¿‡50%çš„æ¨¡å‹é¢„æµ‹ä¸ºæ­£ä¾‹
            if positive_ratio > 0.5 and positive_count >= self.min_consensus_models:
                avg_prob_0 = float(np.mean([pred.get('probability_0', 0.5) for pred in predictions]))
                avg_prob_1 = float(np.mean([pred.get('probability_1', 0.5) for pred in predictions]))
                avg_confidence = float(np.mean([pred.get('confidence', 0.5) for pred in predictions]))

                consensus_info = {
                    'protein_id': str(predictions[0]['protein_id']),
                    'compound_id': str(predictions[0]['compound_id']),
                    'num_models': int(len(predictions)),
                    'positive_models': int(positive_count),
                    'positive_ratio': float(positive_ratio),
                    'consensus_type': 'majority_positive',
                    'avg_probability_0': avg_prob_0,
                    'avg_probability_1': avg_prob_1,
                    'avg_confidence': avg_confidence,
                    'model_details': []
                }

                for pred in predictions:
                    model_detail = {
                        'model_type': str(pred['model_type']),
                        'model_name': str(pred['model_name']),
                        'prediction': int(pred['prediction']),
                        'prediction_label': str(pred['prediction_label']),
                        'probability_0': float(pred.get('probability_0', 0.5)),
                        'probability_1': float(pred.get('probability_1', 0.5)),
                        'confidence': float(pred.get('confidence', 0.5))
                    }
                    consensus_info['model_details'].append(model_detail)

                majority_positive.append(consensus_info)

        return majority_positive

    def _find_high_confidence_positive(self, compound_predictions):
        """æ‰¾åˆ°é«˜ç½®ä¿¡åº¦æ­£ä¾‹é¢„æµ‹çš„åŒ–åˆç‰©"""
        high_confidence = []

        for compound_key, predictions in compound_predictions.items():
            if len(predictions) < self.min_consensus_models:
                continue

            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿæ•°é‡çš„é«˜ç½®ä¿¡åº¦æ­£ä¾‹é¢„æµ‹
            high_conf_positive = [
                pred for pred in predictions
                if pred['prediction'] == 1 and pred.get('probability_1', 0) >= self.probability_threshold
            ]

            if len(high_conf_positive) >= self.min_consensus_models:
                # åªè®¡ç®—é«˜ç½®ä¿¡åº¦é¢„æµ‹çš„å¹³å‡å€¼
                avg_prob_0 = float(np.mean([pred.get('probability_0', 0.5) for pred in high_conf_positive]))
                avg_prob_1 = float(np.mean([pred.get('probability_1', 0.5) for pred in high_conf_positive]))
                avg_confidence = float(np.mean([pred.get('confidence', 0.5) for pred in high_conf_positive]))

                consensus_info = {
                    'protein_id': str(predictions[0]['protein_id']),
                    'compound_id': str(predictions[0]['compound_id']),
                    'num_models': int(len(predictions)),
                    'high_conf_positive_models': int(len(high_conf_positive)),
                    'consensus_type': 'high_confidence_positive',
                    'avg_probability_0': avg_prob_0,
                    'avg_probability_1': avg_prob_1,
                    'avg_confidence': avg_confidence,
                    'min_probability_threshold': float(self.probability_threshold),
                    'model_details': []
                }

                # åŒ…å«æ‰€æœ‰æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯ï¼Œä½†æ ‡è®°å“ªäº›æ˜¯é«˜ç½®ä¿¡åº¦çš„
                for pred in predictions:
                    is_high_conf = (pred['prediction'] == 1 and
                                    pred.get('probability_1', 0) >= self.probability_threshold)

                    model_detail = {
                        'model_type': str(pred['model_type']),
                        'model_name': str(pred['model_name']),
                        'prediction': int(pred['prediction']),
                        'prediction_label': str(pred['prediction_label']),
                        'probability_0': float(pred.get('probability_0', 0.5)),
                        'probability_1': float(pred.get('probability_1', 0.5)),
                        'confidence': float(pred.get('confidence', 0.5)),
                        'is_high_confidence': bool(is_high_conf)
                    }
                    consensus_info['model_details'].append(model_detail)

                high_confidence.append(consensus_info)

        return high_confidence

    def save_consensus_results(self, consensus_stats, output_dir):
        """ä¿å­˜å…±è¯†åˆ†æç»“æœï¼ˆä¿®å¤JSONåºåˆ—åŒ–é—®é¢˜ï¼‰"""
        if not SAVE_CONSENSUS_RESULTS:
            return

        print(f"\nä¿å­˜å…±è¯†åˆ†æç»“æœ...")

        # åˆ›å»ºå…±è¯†åˆ†æå­ç›®å½•
        consensus_dir = os.path.join(output_dir, "consensus_analysis")
        os.makedirs(consensus_dir, exist_ok=True)

        for consensus_type, results in consensus_stats.items():
            if not results:
                continue

            print(f"  ä¿å­˜ {consensus_type} ç»“æœ: {len(results)} ä¸ªåŒ–åˆç‰©")

            # åˆ›å»ºç®€åŒ–çš„æ•°æ®è¡¨æ ¼
            simplified_data = []
            detailed_data = []

            for result in results:
                # ç®€åŒ–è¡¨æ ¼
                simplified_row = {
                    'protein_id': result['protein_id'],
                    'compound_id': result['compound_id'],
                    'num_models': result['num_models'],
                    'consensus_type': result['consensus_type'],
                    'avg_probability_0': f"{result['avg_probability_0']:.4f}",
                    'avg_probability_1': f"{result['avg_probability_1']:.4f}",
                    'avg_confidence': f"{result['avg_confidence']:.4f}"
                }

                # æ·»åŠ ç‰¹å®šç±»å‹çš„é¢å¤–ä¿¡æ¯
                if consensus_type == "majority_positive":
                    simplified_row['positive_models'] = result['positive_models']
                    simplified_row['positive_ratio'] = f"{result['positive_ratio']:.4f}"
                elif consensus_type == "high_confidence_positive":
                    simplified_row['high_conf_positive_models'] = result['high_conf_positive_models']
                    simplified_row['min_probability_threshold'] = result['min_probability_threshold']

                simplified_data.append(simplified_row)

                # è¯¦ç»†è¡¨æ ¼ - å±•å¼€æ¯ä¸ªæ¨¡å‹çš„ä¿¡æ¯
                if CONSENSUS_OUTPUT_DETAILED:
                    for model_detail in result['model_details']:
                        detailed_row = {
                            'protein_id': result['protein_id'],
                            'compound_id': result['compound_id'],
                            'consensus_type': result['consensus_type'],
                            'num_models': result['num_models'],
                            'avg_probability_1': f"{result['avg_probability_1']:.4f}",
                            'avg_confidence': f"{result['avg_confidence']:.4f}",
                            'model_type': model_detail['model_type'],
                            'model_name': model_detail['model_name'],
                            'model_prediction': model_detail['prediction'],
                            'model_prediction_label': model_detail['prediction_label'],
                            'model_probability_0': f"{model_detail['probability_0']:.4f}",
                            'model_probability_1': f"{model_detail['probability_1']:.4f}",
                            'model_confidence': f"{model_detail['confidence']:.4f}"
                        }

                        if consensus_type == "high_confidence_positive":
                            detailed_row['is_high_confidence'] = model_detail.get('is_high_confidence', False)

                        detailed_data.append(detailed_row)

            # ä¿å­˜ç®€åŒ–è¡¨æ ¼
            if simplified_data:
                try:
                    simplified_df = pd.DataFrame(simplified_data)
                    simplified_file = os.path.join(consensus_dir, f"{consensus_type}_summary.csv")
                    simplified_df.to_csv(simplified_file, index=False, encoding='utf-8-sig')
                    print(f"    âœ“ ç®€åŒ–è¡¨æ ¼: {simplified_file}")
                except Exception as e:
                    print(f"    âœ— ä¿å­˜ç®€åŒ–è¡¨æ ¼å¤±è´¥: {e}")

            # ä¿å­˜è¯¦ç»†è¡¨æ ¼
            if detailed_data and CONSENSUS_OUTPUT_DETAILED:
                try:
                    detailed_df = pd.DataFrame(detailed_data)
                    detailed_file = os.path.join(consensus_dir, f"{consensus_type}_detailed.csv")
                    detailed_df.to_csv(detailed_file, index=False, encoding='utf-8-sig')
                    print(f"    âœ“ è¯¦ç»†è¡¨æ ¼: {detailed_file}")
                except Exception as e:
                    print(f"    âœ— ä¿å­˜è¯¦ç»†è¡¨æ ¼å¤±è´¥: {e}")

            # ä¿å­˜JSONæ ¼å¼çš„å®Œæ•´ä¿¡æ¯ - ä¿®å¤ï¼šä½¿ç”¨å®‰å…¨çš„JSONä¿å­˜å‡½æ•°
            json_file = os.path.join(consensus_dir, f"{consensus_type}_complete.json")
            if safe_json_dump(results, json_file, indent=2, ensure_ascii=False):
                print(f"    âœ“ å®Œæ•´JSON: {json_file}")
            else:
                print(f"    âœ— å®Œæ•´JSONä¿å­˜å¤±è´¥: {json_file}")

        # åˆ›å»ºæ€»ç»“æŠ¥å‘Š
        try:
            self._create_consensus_summary_report(consensus_stats, consensus_dir)
        except Exception as e:
            print(f"    âœ— åˆ›å»ºæ€»ç»“æŠ¥å‘Šå¤±è´¥: {e}")

    def _create_consensus_summary_report(self, consensus_stats, consensus_dir):
        """åˆ›å»ºå…±è¯†åˆ†ææ€»ç»“æŠ¥å‘Š"""
        report_file = os.path.join(consensus_dir, "consensus_summary_report.txt")

        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("å…±è¯†é¢„æµ‹åˆ†ææ€»ç»“æŠ¥å‘Š\n")
                f.write("=" * 50 + "\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æœ€å°å…±è¯†æ¨¡å‹æ•°: {self.min_consensus_models}\n")
                f.write(f"æ¦‚ç‡é˜ˆå€¼: {self.probability_threshold}\n\n")

                for consensus_type, results in consensus_stats.items():
                    f.write(f"{consensus_type.upper()}:\n")
                    f.write("-" * 30 + "\n")
                    f.write(f"ç¬¦åˆæ¡ä»¶çš„åŒ–åˆç‰©æ•°é‡: {len(results)}\n")

                    if results:
                        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                        avg_probs = [r['avg_probability_1'] for r in results]
                        avg_confs = [r['avg_confidence'] for r in results]

                        f.write(f"å¹³å‡æ­£ä¾‹æ¦‚ç‡èŒƒå›´: {min(avg_probs):.4f} - {max(avg_probs):.4f}\n")
                        f.write(f"å¹³å‡ç½®ä¿¡åº¦èŒƒå›´: {min(avg_confs):.4f} - {max(avg_confs):.4f}\n")
                        f.write(f"å¹³å‡æ­£ä¾‹æ¦‚ç‡å‡å€¼: {np.mean(avg_probs):.4f}\n")
                        f.write(f"å¹³å‡ç½®ä¿¡åº¦å‡å€¼: {np.mean(avg_confs):.4f}\n")

                        # æ˜¾ç¤ºå‰10ä¸ªæœ€é«˜ç½®ä¿¡åº¦çš„åŒ–åˆç‰©
                        sorted_results = sorted(results, key=lambda x: x['avg_confidence'], reverse=True)
                        f.write(f"\nå‰10ä¸ªæœ€é«˜ç½®ä¿¡åº¦çš„åŒ–åˆç‰©:\n")
                        for i, result in enumerate(sorted_results[:10], 1):
                            f.write(f"  {i}. {result['compound_id']} "
                                    f"(ç½®ä¿¡åº¦: {result['avg_confidence']:.4f}, "
                                    f"æ­£ä¾‹æ¦‚ç‡: {result['avg_probability_1']:.4f})\n")

                    f.write("\n")

            print(f"    âœ“ æ€»ç»“æŠ¥å‘Š: {report_file}")

        except Exception as e:
            print(f"    âœ— åˆ›å»ºæ€»ç»“æŠ¥å‘Šå¤±è´¥: {e}")


# =============================================================================
# æ‰¹å¤„ç†é¢„æµ‹å™¨ç±»ï¼ˆå¢å¼ºç‰ˆï¼‰
# =============================================================================

class BatchProteinCompoundPredictor:
    """æ”¯æŒæ‰¹å¤„ç†çš„è›‹ç™½è´¨-åŒ–åˆç‰©ç›¸äº’ä½œç”¨é¢„æµ‹å™¨ï¼ˆå¢å¼ºç‰ˆï¼‰"""

    def __init__(self, model_base_dir, selected_model_types=None, selected_models=None):
        self.model_base_dir = model_base_dir
        self.selected_model_types = selected_model_types or SELECTED_MODEL_TYPES
        self.selected_models = selected_models or SELECTED_MODELS
        self.models = {}
        self.feature_pipelines = {}
        self.available_models = {}

        # æ–°å¢ï¼šå…±è¯†åˆ†æå™¨
        if ENABLE_CONSENSUS_ANALYSIS:
            self.consensus_analyzer = ConsensusAnalyzer(
                min_consensus_models=MIN_CONSENSUS_MODELS,
                probability_threshold=CONSENSUS_PROBABILITY_THRESHOLD
            )

    def scan_available_models(self):
        """æ‰«ææ‰€æœ‰å¯ç”¨çš„æ¨¡å‹"""
        print("æ‰«æå¯ç”¨æ¨¡å‹...")

        self.available_models = {}

        for model_type in self.selected_model_types:
            model_dir = os.path.join(self.model_base_dir, model_type)

            if not os.path.exists(model_dir):
                print(f"æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}")
                continue

            pipeline_path = os.path.join(model_dir, 'feature_pipeline.pkl')
            if not os.path.exists(pipeline_path):
                print(f"ç‰¹å¾ç®¡é“æ–‡ä»¶ä¸å­˜åœ¨: {pipeline_path}")
                continue

            model_files = [f for f in os.listdir(model_dir) if f.endswith('_model.pkl')]

            if model_files:
                available_model_names = []
                for f in model_files:
                    model_name = f.replace('_model.pkl', '')
                    if not should_skip_model(model_name):
                        available_model_names.append(model_name)

                if available_model_names:
                    self.available_models[model_type] = available_model_names
                    print(f"  {model_type}: {len(available_model_names)} ä¸ªå¯ç”¨æ¨¡å‹")
                    for model_name in available_model_names:
                        if any(x in model_name.lower() for x in ['é€»è¾‘å›å½’', 'æœ´ç´ è´å¶æ–¯', 'kè¿‘é‚»']):
                            print(f"    ğŸŸ¢ æ¨è: {model_name}")
                        else:
                            print(f"    - {model_name}")
                else:
                    print(f"  {model_type}: æ‰€æœ‰æ¨¡å‹éƒ½è¢«è·³è¿‡")
            else:
                print(f"  {model_type}: æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")

        total_available = sum(len(models) for models in self.available_models.values())
        print(f"\næ€»å…±æ‰«æåˆ° {total_available} ä¸ªå¯ç”¨æ¨¡å‹")

        return total_available > 0

    def interactive_model_selection(self):
        """äº¤äº’å¼æ¨¡å‹é€‰æ‹©ï¼ˆå†…å­˜ä¼˜åŒ–å»ºè®®ï¼‰"""
        if not INTERACTIVE_MODEL_SELECTION:
            print("ä½¿ç”¨é¢„é…ç½®çš„æ¨¡å‹é€‰æ‹©...")
            return True

        print("\n" + "=" * 60)
        print("äº¤äº’å¼æ¨¡å‹é€‰æ‹© - å¤§æ•°æ®é‡ä¼˜åŒ–å»ºè®®")
        print("=" * 60)
        print("æ³¨æ„: ç”±äºæ•°æ®é‡è¾ƒå¤§ï¼Œå»ºè®®:")
        print("1. ğŸŸ¢ ä¼˜å…ˆé€‰æ‹©å†…å­˜æ•ˆç‡é«˜çš„æ¨¡å‹ï¼ˆé€»è¾‘å›å½’ã€æœ´ç´ è´å¶æ–¯ã€Kè¿‘é‚»ï¼‰")
        print("2. ğŸ”´ é¿å…é€‰æ‹©å†…å­˜å¯†é›†å‹æ¨¡å‹ï¼ˆSVMã€å †å åˆ†ç±»å™¨ã€éšæœºæ£®æ—ï¼‰")
        print("3. ä¸€æ¬¡åªé€‰æ‹©å°‘æ•°å‡ ä¸ªæ¨¡å‹è¿›è¡Œé¢„æµ‹")

        for model_type in self.available_models:
            print(f"\n{model_type} å¯ç”¨æ¨¡å‹:")
            available_models = self.available_models[model_type]

            for i, model_name in enumerate(available_models, 1):
                if any(x in model_name.lower() for x in ['é€»è¾‘å›å½’', 'æœ´ç´ è´å¶æ–¯', 'kè¿‘é‚»']):
                    print(f"  {i}. ğŸŸ¢ æ¨è: {model_name}")
                else:
                    print(f"  {i}. {model_name}")

            print(f"  0. å…¨é€‰")
            print(f"  -1. è·³è¿‡æ­¤ç±»å‹")

            while True:
                try:
                    selection = input(f"\nè¯·é€‰æ‹©è¦ä½¿ç”¨çš„ {model_type} æ¨¡å‹: ").strip()

                    if selection == "-1":
                        if model_type in self.selected_models:
                            del self.selected_models[model_type]
                        break
                    elif selection == "0":
                        self.selected_models[model_type] = available_models.copy()
                        print(f"å·²é€‰æ‹© {model_type} çš„æ‰€æœ‰æ¨¡å‹")
                        break
                    else:
                        indices = [int(x.strip()) for x in selection.split(',')]
                        selected_models = [available_models[i - 1] for i in indices if 1 <= i <= len(available_models)]

                        if selected_models:
                            self.selected_models[model_type] = selected_models
                            print(f"å·²é€‰æ‹© {model_type} çš„æ¨¡å‹: {', '.join(selected_models)}")
                            break
                        else:
                            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

                except (ValueError, IndexError):
                    print("è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·é‡æ–°è¾“å…¥")

        confirm = input(f"\nç¡®è®¤ä½¿ç”¨é€‰æ‹©çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹å—ï¼Ÿ(y/n): ").strip().lower()
        return confirm == 'y'

    def load_selected_models(self):
        """åŠ è½½é€‰æ‹©çš„æ¨¡å‹"""
        print("\nå¼€å§‹åŠ è½½é€‰æ‹©çš„æ¨¡å‹...")

        loaded_count = 0

        for model_type in self.selected_model_types:
            if model_type not in self.available_models:
                continue

            model_dir = os.path.join(self.model_base_dir, model_type)
            print(f"\nåŠ è½½ {model_type} æ¨¡å‹...")

            # åŠ è½½ç‰¹å¾ç®¡é“
            pipeline_path = os.path.join(model_dir, 'feature_pipeline.pkl')
            try:
                self.feature_pipelines[model_type] = joblib.load(pipeline_path)
                print(f"  âœ“ ç‰¹å¾ç®¡é“å·²åŠ è½½")
            except Exception as e:
                print(f"  âœ— åŠ è½½ç‰¹å¾ç®¡é“å¤±è´¥: {e}")
                continue

            # ç¡®å®šè¦åŠ è½½çš„æ¨¡å‹åˆ—è¡¨
            if model_type in self.selected_models:
                models_to_load = self.selected_models[model_type]
            else:
                models_to_load = self.available_models[model_type]

            # åŠ è½½æ¨¡å‹
            self.models[model_type] = {}

            for model_name in models_to_load:
                if should_skip_model(model_name):
                    continue

                model_path = os.path.join(model_dir, f'{model_name}_model.pkl')

                if os.path.exists(model_path):
                    try:
                        print(f"  æ­£åœ¨åŠ è½½ {model_name}...")
                        model = joblib.load(model_path)
                        self.models[model_type][model_name] = model
                        print(f"  âœ“ {model_name} æ¨¡å‹å·²åŠ è½½")
                        loaded_count += 1
                    except Exception as e:
                        print(f"  âœ— åŠ è½½ {model_name} æ¨¡å‹å¤±è´¥: {e}")
                        if "CustomStackingClassifier" in str(e) or "CustomVotingClassifier" in str(e):
                            print(f"    è¿™æ˜¯é›†æˆæ¨¡å‹ï¼Œå·²è¢«è·³è¿‡ä»¥é¿å…å…¼å®¹æ€§é—®é¢˜")
                else:
                    print(f"  âœ— {model_name} æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

            if self.models[model_type]:
                print(f"  æˆåŠŸåŠ è½½ {len(self.models[model_type])} ä¸ªæ¨¡å‹")
            else:
                print(f"  æœªèƒ½åŠ è½½ä»»ä½•æ¨¡å‹")

        print(f"\næ¨¡å‹åŠ è½½å®Œæˆï¼Œå…±åŠ è½½ {loaded_count} ä¸ªæ¨¡å‹")
        return loaded_count > 0

    def load_and_prepare_features(self, protein_file, compound_file):
        """åŠ è½½å’Œå‡†å¤‡ç‰¹å¾æ•°æ®ï¼ˆæ”¯æŒå¤§æ•°æ®é‡ï¼‰"""
        print(f"\nåŠ è½½ç‰¹å¾æ–‡ä»¶...")

        # åŠ è½½è›‹ç™½è´¨ç‰¹å¾
        try:
            protein_df = pd.read_csv(protein_file)
            print(f"  è›‹ç™½è´¨ç‰¹å¾æ–‡ä»¶: {protein_df.shape}")
        except Exception as e:
            raise ValueError(f"åŠ è½½è›‹ç™½è´¨ç‰¹å¾æ–‡ä»¶å¤±è´¥: {e}")

        # åŠ è½½åŒ–åˆç‰©ç‰¹å¾
        try:
            compound_df = pd.read_csv(compound_file)
            print(f"  åŒ–åˆç‰©ç‰¹å¾æ–‡ä»¶: {compound_df.shape}")
        except Exception as e:
            raise ValueError(f"åŠ è½½åŒ–åˆç‰©ç‰¹å¾æ–‡ä»¶å¤±è´¥: {e}")

        # æ£€æŸ¥æ•°æ®
        if len(protein_df) == 0 or len(compound_df) == 0:
            raise ValueError("ç‰¹å¾æ–‡ä»¶ä¸ºç©º")

        # å¤„ç†ç‰¹å¾æ•°æ®
        if protein_df.shape[1] > 1:
            protein_ids = protein_df.iloc[:, 0].values
            protein_features_matrix = protein_df.iloc[:, 1:].values
        else:
            protein_ids = [f"Protein_{i + 1}" for i in range(len(protein_df))]
            protein_features_matrix = protein_df.values

        if compound_df.shape[1] > 1:
            compound_ids = compound_df.iloc[:, 0].values
            compound_features_matrix = compound_df.iloc[:, 1:].values
        else:
            compound_ids = [f"Compound_{i + 1}" for i in range(len(compound_df))]
            compound_features_matrix = compound_df.values

        # è®¡ç®—æ€»ç»„åˆæ•°
        total_combinations = len(protein_ids) * len(compound_ids)
        print(f"  æ€»ç»„åˆæ•°: {len(protein_ids)} Ã— {len(compound_ids)} = {total_combinations:,}")

        # ä¼°ç®—å†…å­˜éœ€æ±‚
        feature_dim = protein_features_matrix.shape[1] + compound_features_matrix.shape[1]
        memory_gb = (total_combinations * feature_dim * 8) / (1024 ** 3)
        print(f"  é¢„è®¡å†…å­˜éœ€æ±‚: {memory_gb:.2f} GB")

        if memory_gb > MAX_MEMORY_GB:
            print(f"  è­¦å‘Š: é¢„è®¡å†…å­˜éœ€æ±‚è¶…è¿‡é™åˆ¶({MAX_MEMORY_GB}GB)ï¼Œå°†ä½¿ç”¨æ‰¹å¤„ç†æ¨¡å¼")

        # è°ƒæ•´æ‰¹å¤„ç†å¤§å°
        optimal_batch_size = estimate_batch_size(feature_dim, MAX_MEMORY_GB)
        actual_batch_size = min(BATCH_SIZE, optimal_batch_size)
        print(f"  å»ºè®®çš„æ‰¹å¤„ç†å¤§å°: {actual_batch_size}")

        return {
            'protein_ids': protein_ids,
            'compound_ids': compound_ids,
            'protein_features': protein_features_matrix,
            'compound_features': compound_features_matrix,
            'total_combinations': total_combinations,
            'feature_dim': feature_dim,
            'batch_size': actual_batch_size
        }

    def apply_feature_pipeline(self, features, model_type):
        """åº”ç”¨ç‰¹å¾å·¥ç¨‹ç®¡é“ï¼ˆæ‰¹å¤„ç†ä¼˜åŒ–ï¼‰"""
        if model_type not in self.feature_pipelines:
            raise ValueError(f"æœªæ‰¾åˆ° {model_type} çš„ç‰¹å¾ç®¡é“")

        pipeline = self.feature_pipelines[model_type]

        # ç¡®ä¿è¾“å…¥æ˜¯2Dæ•°ç»„
        if features.ndim == 1:
            features = features.reshape(1, -1)

        # åˆ†æ‰¹å¤„ç†ä»¥èŠ‚çœå†…å­˜
        batch_size = min(500, features.shape[0])
        processed_features = []

        for start_idx in range(0, features.shape[0], batch_size):
            end_idx = min(start_idx + batch_size, features.shape[0])
            batch_features = features[start_idx:end_idx]

            # åº”ç”¨å¡«å……å™¨
            if 'imputer' in pipeline and pipeline['imputer'] is not None:
                try:
                    batch_features = pipeline['imputer'].transform(batch_features)
                except Exception as e:
                    print(f"åº”ç”¨å¡«å……å™¨å¤±è´¥: {e}")

            # åº”ç”¨ç‰¹å¾é€‰æ‹©
            if 'selected_features' in pipeline and pipeline['selected_features']:
                try:
                    selected_count = len(pipeline['selected_features'])
                    if batch_features.shape[1] >= selected_count:
                        batch_features = batch_features[:, :selected_count]
                    else:
                        padding = np.zeros((batch_features.shape[0], selected_count - batch_features.shape[1]))
                        batch_features = np.hstack([batch_features, padding])
                except Exception as e:
                    print(f"åº”ç”¨ç‰¹å¾é€‰æ‹©å¤±è´¥: {e}")

            # åº”ç”¨é™ç»´å™¨
            if 'reducer' in pipeline and pipeline['reducer'] is not None:
                try:
                    batch_features = pipeline['reducer'].transform(batch_features)
                except Exception as e:
                    print(f"åº”ç”¨é™ç»´å™¨å¤±è´¥: {e}")

            # åº”ç”¨ç¼©æ”¾å™¨
            if 'scaler' in pipeline and pipeline['scaler'] is not None:
                try:
                    batch_features = pipeline['scaler'].transform(batch_features)
                except Exception as e:
                    print(f"åº”ç”¨ç¼©æ”¾å™¨å¤±è´¥: {e}")

            # å¤„ç†å¯èƒ½çš„NaNå’Œinfå€¼
            batch_features = np.nan_to_num(batch_features, nan=0.0, posinf=0.0, neginf=0.0)
            processed_features.append(batch_features)

            # æ¸…ç†å†…å­˜
            del batch_features
            gc.collect()

        return np.vstack(processed_features)

    def predict_single_model_batch(self, data_info, model_type, model_name, model):
        """ä½¿ç”¨å•ä¸ªæ¨¡å‹è¿›è¡Œæ‰¹é‡é¢„æµ‹ï¼ˆä¿®å¤NumPyç±»å‹è½¬æ¢ï¼‰"""
        print(f"    å¼€å§‹æ‰¹é‡é¢„æµ‹: {model_name}")

        protein_ids = data_info['protein_ids']
        compound_ids = data_info['compound_ids']
        protein_features = data_info['protein_features']
        compound_features = data_info['compound_features']
        batch_size = data_info['batch_size']
        total_combinations = data_info['total_combinations']

        results = []

        # ä½¿ç”¨è¿›åº¦æ¡
        if SHOW_PROGRESS:
            pbar = tqdm(total=total_combinations, desc=f"    {model_name}")

        processed_count = 0

        try:
            for i in range(len(protein_ids)):
                protein_id = protein_ids[i]
                protein_feature = protein_features[i]

                # æ‰¹é‡å¤„ç†åŒ–åˆç‰©
                for start_j in range(0, len(compound_ids), batch_size):
                    end_j = min(start_j + batch_size, len(compound_ids))

                    # å‡†å¤‡å½“å‰æ‰¹æ¬¡çš„ç‰¹å¾
                    batch_features = []
                    batch_combinations = []

                    for j in range(start_j, end_j):
                        compound_id = compound_ids[j]
                        compound_feature = compound_features[j]
                        combined_feature = np.concatenate([protein_feature, compound_feature])

                        batch_features.append(combined_feature)
                        batch_combinations.append((protein_id, compound_id))

                    batch_features = np.array(batch_features)

                    try:
                        # åº”ç”¨ç‰¹å¾å·¥ç¨‹ç®¡é“
                        features_processed = self.apply_feature_pipeline(batch_features, model_type)

                        # è¿›è¡Œé¢„æµ‹
                        predictions = model.predict(features_processed)

                        # å¦‚æœæ¨¡å‹æ”¯æŒæ¦‚ç‡é¢„æµ‹
                        probabilities = None
                        if hasattr(model, 'predict_proba'):
                            try:
                                probabilities = model.predict_proba(features_processed)
                            except Exception as e:
                                probabilities = None

                        # æ„å»ºç»“æœ - ä¿®å¤ï¼šç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯PythonåŸç”Ÿç±»å‹
                        for k, (protein_id, compound_id) in enumerate(batch_combinations):
                            result = {
                                'protein_id': str(protein_id),
                                'compound_id': str(compound_id),
                                'model_type': str(model_type),
                                'model_name': str(model_name),
                                'prediction': int(predictions[k]),
                                'prediction_label': 'ç›¸äº’ä½œç”¨' if int(predictions[k]) == 1 else 'æ— ç›¸äº’ä½œç”¨'
                            }

                            if probabilities is not None:
                                result['probability_0'] = float(probabilities[k][0])
                                result['probability_1'] = float(probabilities[k][1])
                                result['confidence'] = float(max(probabilities[k]))
                            else:
                                # å¦‚æœæ²¡æœ‰æ¦‚ç‡ï¼Œè®¾ç½®é»˜è®¤å€¼
                                result['probability_0'] = 0.5
                                result['probability_1'] = 0.5
                                result['confidence'] = 0.5

                            results.append(result)

                        processed_count += len(batch_combinations)

                        if SHOW_PROGRESS:
                            pbar.update(len(batch_combinations))

                        # æ¸…ç†å†…å­˜
                        del batch_features, features_processed, predictions
                        if probabilities is not None:
                            del probabilities
                        gc.collect()

                        # å®šæœŸæ£€æŸ¥å†…å­˜ä½¿ç”¨
                        if processed_count % (batch_size * 5) == 0:
                            current_memory = get_memory_usage()
                            if current_memory > MAX_MEMORY_GB * 1024:
                                print(f"      è­¦å‘Š: å†…å­˜ä½¿ç”¨è¿‡é«˜ ({current_memory:.0f}MB)ï¼Œå¼ºåˆ¶åƒåœ¾å›æ”¶")
                                gc.collect()

                    except Exception as e:
                        print(f"      æ‰¹æ¬¡é¢„æµ‹å¤±è´¥: {e}")
                        # ä¸è¦è®©å•ä¸ªæ‰¹æ¬¡çš„å¤±è´¥å½±å“æ•´ä¸ªé¢„æµ‹
                        continue

        except Exception as e:
            print(f"    âœ— {model_name} é¢„æµ‹è¿‡ç¨‹å‡ºé”™: {e}")

        finally:
            if SHOW_PROGRESS:
                pbar.close()

        print(f"    âœ“ {model_name} é¢„æµ‹å®Œæˆï¼Œå…± {len(results)} ä¸ªç»“æœ")
        return results

    def predict_and_save_separately_batch(self, data_info):
        """æ‰¹é‡é¢„æµ‹å¹¶åˆ†åˆ«ä¿å­˜æ¯ä¸ªæ¨¡å‹çš„ç»“æœï¼ˆå¢å¼ºç‰ˆï¼Œä¿®å¤JSONåºåˆ—åŒ–ï¼‰"""
        print(f"\nå¼€å§‹æ‰¹é‡é¢„æµ‹å¹¶åˆ†åˆ«ä¿å­˜ç»“æœ...")

        # åˆ›å»ºè¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_dir = os.path.join(OUTPUT_BASE_DIR, f"batch_prediction_{timestamp}")
        os.makedirs(output_dir, exist_ok=True)

        all_results = []  # ç”¨äºå…±è¯†åˆ†æ
        model_summary = {}

        for model_type in self.models:
            if not self.models[model_type]:
                continue

            print(f"\nä½¿ç”¨ {model_type} æ¨¡å‹è¿›è¡Œæ‰¹é‡é¢„æµ‹...")

            # ä¸ºæ¯ä¸ªæ¨¡å‹ç±»å‹åˆ›å»ºå­ç›®å½•
            type_dir = os.path.join(output_dir, model_type.replace('/', '_'))
            os.makedirs(type_dir, exist_ok=True)

            model_summary[model_type] = {}

            for model_name, model in self.models[model_type].items():
                print(f"  é¢„æµ‹æ¨¡å‹: {model_name}")

                # ä½¿ç”¨å•ä¸ªæ¨¡å‹è¿›è¡Œæ‰¹é‡é¢„æµ‹
                model_results = self.predict_single_model_batch(data_info, model_type, model_name, model)

                if model_results:
                    # ä¿å­˜å•ä¸ªæ¨¡å‹çš„ç»“æœï¼ˆåˆ†æ‰¹ä¿å­˜ä»¥èŠ‚çœå†…å­˜ï¼‰
                    model_file = os.path.join(type_dir, f"{model_name}_prediction.csv")

                    # åˆ†æ‰¹å†™å…¥CSVæ–‡ä»¶
                    batch_write_size = 5000
                    for i in range(0, len(model_results), batch_write_size):
                        batch_results = model_results[i:i + batch_write_size]
                        batch_df = pd.DataFrame(batch_results)

                        if i == 0:
                            batch_df.to_csv(model_file, index=False, encoding='utf-8-sig')
                        else:
                            batch_df.to_csv(model_file, mode='a', header=False, index=False, encoding='utf-8-sig')

                        del batch_df
                        gc.collect()

                    print(f"    âœ“ ç»“æœå·²ä¿å­˜: {model_file}")

                    # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
                    positive_count = sum(1 for r in model_results if r['prediction'] == 1)
                    negative_count = len(model_results) - positive_count

                    model_summary[model_type][model_name] = {
                        'total_predictions': len(model_results),
                        'positive_predictions': positive_count,
                        'negative_predictions': negative_count,
                        'positive_ratio': positive_count / len(model_results) if model_results else 0,
                        'output_file': model_file
                    }

                    print(f"    é¢„æµ‹ç»“æœ: {positive_count:,} ä¸ªç›¸äº’ä½œç”¨, {negative_count:,} ä¸ªæ— ç›¸äº’ä½œç”¨")

                    # æ–°å¢ï¼šæ”¶é›†æ‰€æœ‰ç»“æœç”¨äºå…±è¯†åˆ†æ
                    if ENABLE_CONSENSUS_ANALYSIS:
                        all_results.extend(model_results)

                    # æ¸…ç†å†…å­˜
                    del model_results
                    gc.collect()

                else:
                    print(f"    âœ— é¢„æµ‹å¤±è´¥")

        # æ–°å¢ï¼šè¿›è¡Œå…±è¯†åˆ†æ
        if ENABLE_CONSENSUS_ANALYSIS and all_results:
            print(f"\nå¼€å§‹å…±è¯†åˆ†æï¼Œæ€»å…± {len(all_results)} ä¸ªé¢„æµ‹ç»“æœ...")
            try:
                consensus_stats = self.consensus_analyzer.analyze_consensus(all_results)
                self.consensus_analyzer.save_consensus_results(consensus_stats, output_dir)
            except Exception as e:
                print(f"å…±è¯†åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()

        # ä¿å­˜æ¨¡å‹å¯¹æ¯”ç»“æœ
        comparison_data = []
        for model_type, models in model_summary.items():
            for model_name, stats in models.items():
                comparison_data.append({
                    'model_type': model_type,
                    'model_name': model_name,
                    'total_predictions': stats['total_predictions'],
                    'positive_predictions': stats['positive_predictions'],
                    'negative_predictions': stats['negative_predictions'],
                    'positive_ratio': f"{stats['positive_ratio']:.4f}"
                })

        if comparison_data:
            try:
                comparison_df = pd.DataFrame(comparison_data)
                comparison_file = os.path.join(output_dir, "model_comparison.csv")
                comparison_df.to_csv(comparison_file, index=False, encoding='utf-8-sig')
                print(f"\næ¨¡å‹å¯¹æ¯”ç»“æœå·²ä¿å­˜: {comparison_file}")
            except Exception as e:
                print(f"ä¿å­˜æ¨¡å‹å¯¹æ¯”ç»“æœå¤±è´¥: {e}")

        # ä¿å­˜è¯¦ç»†çš„æ¨¡å‹æ‘˜è¦ - ä¿®å¤ï¼šä½¿ç”¨å®‰å…¨çš„JSONä¿å­˜
        summary_file = os.path.join(output_dir, "prediction_summary.json")
        if safe_json_dump(model_summary, summary_file, indent=2, ensure_ascii=False):
            print(f"é¢„æµ‹æ‘˜è¦å·²ä¿å­˜: {summary_file}")
        else:
            print(f"ä¿å­˜é¢„æµ‹æ‘˜è¦å¤±è´¥: {summary_file}")

        print(f"æ‰€æœ‰ç»“æœä¿å­˜åœ¨ç›®å½•: {output_dir}")

        return all_results, model_summary, output_dir


def display_final_results(data_info, model_summary):
    """æ˜¾ç¤ºæœ€ç»ˆé¢„æµ‹ç»“æœæ‘˜è¦"""
    print(f"\n" + "=" * 80)
    print("æœ€ç»ˆé¢„æµ‹ç»“æœæ‘˜è¦")
    print("=" * 80)

    # ç”Ÿæˆæ€»ä½“ç»Ÿè®¡
    total_models = sum(len(models) for models in model_summary.values())

    print(f"æ€»ç»„åˆæ•°: {data_info['total_combinations']:,}")
    print(f"ä½¿ç”¨æ¨¡å‹æ•°é‡: {total_models}")

    print(f"\nå„æ¨¡å‹ç±»å‹ç»Ÿè®¡:")
    for model_type, models in model_summary.items():
        print(f"  {model_type}: {len(models)} ä¸ªæ¨¡å‹")
        for model_name, stats in models.items():
            print(f"    {model_name}:")
            print(f"      æ€»é¢„æµ‹: {stats['total_predictions']:,}")
            print(f"      æ­£ä¾‹: {stats['positive_predictions']:,} ({stats['positive_ratio']:.4f})")
            print(f"      è´Ÿä¾‹: {stats['negative_predictions']:,}")
            print(f"      è¾“å‡º: {stats['output_file']}")


def display_consensus_highlights(consensus_stats):
    """æ˜¾ç¤ºå…±è¯†åˆ†æäº®ç‚¹"""
    if not consensus_stats:
        return

    print(f"\n" + "ğŸ¯" + "=" * 60)
    print("å…±è¯†åˆ†æäº®ç‚¹")
    print("=" * 60 + "ğŸ¯")

    for consensus_type, results in consensus_stats.items():
        if not results:
            continue

        print(f"\nğŸ“Š {consensus_type.upper()}:")
        print(f"   ç­›é€‰å‡º {len(results)} ä¸ªåŒ–åˆç‰©")

        if results:
            # æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œæ˜¾ç¤ºå‰5ä¸ª
            sorted_results = sorted(results, key=lambda x: x['avg_confidence'], reverse=True)

            print(f"   ğŸ† ç½®ä¿¡åº¦æœ€é«˜çš„å‰5ä¸ªåŒ–åˆç‰©:")
            for i, result in enumerate(sorted_results[:5], 1):
                print(f"      {i}. {result['compound_id']} "
                      f"(ç½®ä¿¡åº¦: {result['avg_confidence']:.4f}, "
                      f"æ­£ä¾‹æ¦‚ç‡: {result['avg_probability_1']:.4f})")

            if len(results) > 5:
                print(f"      ... è¿˜æœ‰ {len(results) - 5} ä¸ªåŒ–åˆç‰©")


def main():
    """ä¸»å‡½æ•°"""
    try:
        print(f"æ‰¹å¤„ç†è›‹ç™½è´¨-åŒ–åˆç‰©ç›¸äº’ä½œç”¨é¢„æµ‹å™¨ï¼ˆå¢å¼ºç‰ˆï¼‰")
        print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)

        # æ˜¾ç¤ºé…ç½®
        print(f"é…ç½®å‚æ•°:")
        print(f"  æœ€å¤§å†…å­˜é™åˆ¶: {MAX_MEMORY_GB} GB")
        print(f"  æ‰¹å¤„ç†å¤§å°: {BATCH_SIZE}")
        print(f"  è·³è¿‡é›†æˆæ¨¡å‹: {SKIP_ENSEMBLE_MODELS}")
        print(f"  è·³è¿‡å†…å­˜å¯†é›†æ¨¡å‹: {SKIP_MEMORY_INTENSIVE_MODELS}")
        print(f"  äº¤äº’å¼é€‰æ‹©: {INTERACTIVE_MODEL_SELECTION}")
        print(f"  å…±è¯†åˆ†æ: {ENABLE_CONSENSUS_ANALYSIS}")
        if ENABLE_CONSENSUS_ANALYSIS:
            print(f"    æœ€å°å…±è¯†æ¨¡å‹æ•°: {MIN_CONSENSUS_MODELS}")
            print(f"    æ¦‚ç‡é˜ˆå€¼: {CONSENSUS_PROBABILITY_THRESHOLD}")
            print(f"    åˆ†æç±»å‹: {', '.join(CONSENSUS_ANALYSIS_TYPES)}")

        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(PROTEIN_FEATURE_FILE):
            raise FileNotFoundError(f"è›‹ç™½è´¨ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {PROTEIN_FEATURE_FILE}")

        if not os.path.exists(COMPOUND_FEATURE_FILE):
            raise FileNotFoundError(f"åŒ–åˆç‰©ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {COMPOUND_FEATURE_FILE}")

        if not os.path.exists(MODEL_BASE_DIR):
            raise FileNotFoundError(f"æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {MODEL_BASE_DIR}")

        # åˆå§‹åŒ–é¢„æµ‹å™¨
        predictor = BatchProteinCompoundPredictor(MODEL_BASE_DIR, SELECTED_MODEL_TYPES, SELECTED_MODELS)

        # æ‰«æå¯ç”¨æ¨¡å‹
        if not predictor.scan_available_models():
            raise RuntimeError("æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨æ¨¡å‹")

        # äº¤äº’å¼æ¨¡å‹é€‰æ‹©
        if not predictor.interactive_model_selection():
            return

        # åŠ è½½é€‰æ‹©çš„æ¨¡å‹
        if not predictor.load_selected_models():
            raise RuntimeError("æœªèƒ½åŠ è½½ä»»ä½•æ¨¡å‹")

        # åŠ è½½å’Œå‡†å¤‡ç‰¹å¾æ•°æ®
        data_info = predictor.load_and_prepare_features(PROTEIN_FEATURE_FILE, COMPOUND_FEATURE_FILE)

        print(f"\nå‡†å¤‡å¼€å§‹æ‰¹é‡é¢„æµ‹...")
        print(f"æ•°æ®ä¿¡æ¯:")
        print(f"  æ€»ç»„åˆæ•°: {data_info['total_combinations']:,}")
        print(f"  ç‰¹å¾ç»´åº¦: {data_info['feature_dim']}")
        print(f"  æ‰¹å¤„ç†å¤§å°: {data_info['batch_size']}")

        # ç¡®è®¤å¼€å§‹é¢„æµ‹
        confirm = input(f"\nç¡®è®¤å¼€å§‹æ‰¹é‡é¢„æµ‹å—ï¼Ÿ(y/n): ").strip().lower()
        if confirm != 'y':
            print("å·²å–æ¶ˆé¢„æµ‹")
            return

        # è¿›è¡Œæ‰¹é‡é¢„æµ‹å¹¶åˆ†åˆ«ä¿å­˜ç»“æœ
        all_results, model_summary, output_dir = predictor.predict_and_save_separately_batch(data_info)

        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        display_final_results(data_info, model_summary)

        # æ–°å¢ï¼šå¦‚æœè¿›è¡Œäº†å…±è¯†åˆ†æï¼Œæ˜¾ç¤ºå…±è¯†åˆ†æçš„äº®ç‚¹
        if ENABLE_CONSENSUS_ANALYSIS and hasattr(predictor, 'consensus_analyzer'):
            try:
                # é‡æ–°åŠ è½½å…±è¯†åˆ†æç»“æœè¿›è¡Œå±•ç¤º
                consensus_dir = os.path.join(output_dir, "consensus_analysis")
                if os.path.exists(consensus_dir):
                    consensus_stats = {}

                    for consensus_type in CONSENSUS_ANALYSIS_TYPES:
                        json_file = os.path.join(consensus_dir, f"{consensus_type}_complete.json")
                        if os.path.exists(json_file):
                            try:
                                with open(json_file, 'r', encoding='utf-8') as f:
                                    consensus_stats[consensus_type] = json.load(f)
                            except Exception as e:
                                print(f"è¯»å–å…±è¯†åˆ†æç»“æœæ–‡ä»¶å¤±è´¥ {json_file}: {e}")

                    if consensus_stats:
                        display_consensus_highlights(consensus_stats)

                        # ç”Ÿæˆå¿«é€Ÿç­›é€‰å»ºè®®
                        print(f"\n" + "ğŸ’¡" + "=" * 60)
                        print("å¿«é€Ÿç­›é€‰å»ºè®®")
                        print("=" * 60 + "ğŸ’¡")

                        # ç»Ÿè®¡ä¸åŒå…±è¯†ç±»å‹çš„åŒ–åˆç‰©æ•°é‡
                        all_positive_count = len(consensus_stats.get('all_positive', []))
                        majority_positive_count = len(consensus_stats.get('majority_positive', []))
                        high_confidence_count = len(consensus_stats.get('high_confidence_positive', []))

                        print(f"ğŸ¥‡ æœ€é«˜ä¼˜å…ˆçº§ - æ‰€æœ‰æ¨¡å‹éƒ½åŒæ„: {all_positive_count} ä¸ªåŒ–åˆç‰©")
                        print(f"   æ¨è: ä¼˜å…ˆè¿›è¡Œå®éªŒéªŒè¯")
                        print(f"   æ–‡ä»¶: all_positive_summary.csv")

                        print(f"ğŸ¥ˆ ä¸­ç­‰ä¼˜å…ˆçº§ - é«˜ç½®ä¿¡åº¦é¢„æµ‹: {high_confidence_count} ä¸ªåŒ–åˆç‰©")
                        print(f"   æ¨è: ä½œä¸ºäºŒçº¿å€™é€‰åŒ–åˆç‰©")
                        print(f"   æ–‡ä»¶: high_confidence_positive_summary.csv")

                        print(f"ğŸ¥‰ å¤‡é€‰è€ƒè™‘ - å¤§å¤šæ•°æ¨¡å‹åŒæ„: {majority_positive_count} ä¸ªåŒ–åˆç‰©")
                        print(f"   æ¨è: ç”¨äºè¿›ä¸€æ­¥çš„è®¡ç®—ç­›é€‰")
                        print(f"   æ–‡ä»¶: majority_positive_summary.csv")

                        # ç»™å‡ºå®é™…çš„æ–‡ä»¶è·¯å¾„å»ºè®®
                        print(f"\nğŸ“ é‡è¦æ–‡ä»¶ä½ç½®:")
                        print(f"   å…±è¯†åˆ†æç›®å½•: {consensus_dir}")
                        print(f"   æ€»ç»“æŠ¥å‘Š: {os.path.join(consensus_dir, 'consensus_summary_report.txt')}")

                        # å¦‚æœæœ‰é«˜ä¼˜å…ˆçº§åŒ–åˆç‰©ï¼Œç»™å‡ºå…·ä½“å»ºè®®
                        if all_positive_count > 0:
                            print(f"\nğŸ¯ å…³é”®å‘ç°:")
                            print(f"   å‘ç° {all_positive_count} ä¸ªæ‰€æœ‰æ¨¡å‹éƒ½è®¤ä¸ºä¼šç›¸äº’ä½œç”¨çš„åŒ–åˆç‰©ï¼")
                            print(f"   è¿™äº›åŒ–åˆç‰©å…·æœ‰æœ€é«˜çš„å®éªŒéªŒè¯ä»·å€¼")
                            print(f"   å»ºè®®ç«‹å³æŸ¥çœ‹: {os.path.join(consensus_dir, 'all_positive_summary.csv')}")

                        elif high_confidence_count > 0:
                            print(f"\nğŸ¯ å…³é”®å‘ç°:")
                            print(f"   å‘ç° {high_confidence_count} ä¸ªé«˜ç½®ä¿¡åº¦ç›¸äº’ä½œç”¨çš„åŒ–åˆç‰©")
                            print(f"   è¿™äº›åŒ–åˆç‰©å€¼å¾—ä¼˜å…ˆè€ƒè™‘")
                            print(f"   å»ºè®®æŸ¥çœ‹: {os.path.join(consensus_dir, 'high_confidence_positive_summary.csv')}")

                        elif majority_positive_count > 0:
                            print(f"\nğŸ¯ å…³é”®å‘ç°:")
                            print(f"   å‘ç° {majority_positive_count} ä¸ªå¤§å¤šæ•°æ¨¡å‹è®¤å¯çš„åŒ–åˆç‰©")
                            print(f"   å»ºè®®è¿›ä¸€æ­¥ç­›é€‰åè€ƒè™‘å®éªŒéªŒè¯")
                            print(f"   å»ºè®®æŸ¥çœ‹: {os.path.join(consensus_dir, 'majority_positive_summary.csv')}")

                        else:
                            print(f"\nâš ï¸  æ³¨æ„:")
                            print(f"   æœªå‘ç°ç¬¦åˆå½“å‰å…±è¯†æ ‡å‡†çš„åŒ–åˆç‰©")
                            print(f"   å»ºè®®é™ä½å…±è¯†è¦æ±‚æˆ–æ£€æŸ¥æ¨¡å‹é¢„æµ‹ç»“æœ")

                    else:
                        print(f"æ— æ³•è¯»å–å…±è¯†åˆ†æç»“æœ")
                else:
                    print(f"å…±è¯†åˆ†æç›®å½•ä¸å­˜åœ¨: {consensus_dir}")

            except Exception as e:
                print(f"æ˜¾ç¤ºå…±è¯†åˆ†æäº®ç‚¹æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()

        print(f"\nğŸ‰ é¢„æµ‹å®Œæˆï¼")
        print(f"æ‰€æœ‰ç»“æœå·²ä¿å­˜è‡³: {output_dir}")
        print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # ç”Ÿæˆæœ€ç»ˆæ€»ç»“
        print(f"\n" + "ğŸ“‹" + "=" * 70)
        print("æœ€ç»ˆæ€»ç»“")
        print("=" * 70 + "ğŸ“‹")

        total_models = sum(len(models) for models in model_summary.values())
        total_predictions = sum(
            stats['total_predictions']
            for model_type_stats in model_summary.values()
            for stats in model_type_stats.values()
        )

        print(f"âœ… æˆåŠŸä½¿ç”¨ {total_models} ä¸ªæ¨¡å‹")
        print(f"âœ… ç”Ÿæˆ {total_predictions:,} ä¸ªé¢„æµ‹ç»“æœ")
        print(f"âœ… æ•°æ®ä¿å­˜åœ¨ {len(model_summary)} ä¸ªæ¨¡å‹ç±»å‹ç›®å½•ä¸­")

        if ENABLE_CONSENSUS_ANALYSIS:
            print(f"âœ… å®Œæˆå…±è¯†åˆ†æï¼Œè¯†åˆ«å‡ºæœ€æœ‰å¸Œæœ›çš„åŒ–åˆç‰©å€™é€‰")

        print(f"\nğŸ”¬ ä¸‹ä¸€æ­¥å»ºè®®:")
        print(f"1. æŸ¥çœ‹å…±è¯†åˆ†æç»“æœï¼Œä¼˜å…ˆè€ƒè™‘ 'all_positive' ç±»å‹çš„åŒ–åˆç‰©")
        print(f"2. æŸ¥çœ‹è¯¦ç»†çš„é¢„æµ‹æ¦‚ç‡ï¼Œç­›é€‰é«˜ç½®ä¿¡åº¦çš„é¢„æµ‹")
        print(f"3. ç»“åˆé¢†åŸŸçŸ¥è¯†ï¼Œè¿›ä¸€æ­¥ç­›é€‰æœ‰ç”Ÿç‰©å­¦æ„ä¹‰çš„åŒ–åˆç‰©")
        print(f"4. è§„åˆ’å®éªŒéªŒè¯ï¼Œä»æœ€é«˜ç½®ä¿¡åº¦çš„åŒ–åˆç‰©å¼€å§‹")

        print(f"\nğŸ“Š è¾“å‡ºæ–‡ä»¶è¯´æ˜:")
        print(f"   individual predictions: æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†é¢„æµ‹ç»“æœ")
        print(f"   model_comparison.csv: æ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½å¯¹æ¯”")
        print(f"   consensus_analysis/: å…±è¯†åˆ†æç»“æœï¼ˆé‡ç‚¹å…³æ³¨ï¼‰")
        print(f"   prediction_summary.json: å®Œæ•´çš„é¢„æµ‹æ‘˜è¦")

        # æ˜¾ç¤ºå†…å­˜ä½¿ç”¨æƒ…å†µ
        final_memory = get_memory_usage()
        if final_memory > 0:
            print(f"\nğŸ’¾ å†…å­˜ä½¿ç”¨ç»Ÿè®¡:")
            print(f"   æœ€ç»ˆå†…å­˜ä½¿ç”¨: {final_memory:.0f} MB")
            if final_memory > MAX_MEMORY_GB * 1024:
                print(f"   âš ï¸  å†…å­˜ä½¿ç”¨è¶…è¿‡è®¾å®šé™åˆ¶ï¼Œå»ºè®®ä¸‹æ¬¡å‡å°æ‰¹å¤„ç†å¤§å°")
            else:
                print(f"   âœ… å†…å­˜ä½¿ç”¨åœ¨åˆç†èŒƒå›´å†…")

        return output_dir

    except KeyboardInterrupt:
        print(f"\nâ›” ç”¨æˆ·ä¸­æ–­äº†é¢„æµ‹è¿‡ç¨‹")
        print(f"   å¦‚æœéœ€è¦ç»§ç»­ï¼Œè¯·é‡æ–°è¿è¡Œç¨‹åº")
        return None

    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨é”™è¯¯: {e}")
        print(f"   è¯·æ£€æŸ¥é…ç½®å‚æ•°ä¸­çš„æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
        return None

    except Exception as e:
        print(f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        print(f"   è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    print(f"ğŸš€ å¯åŠ¨è›‹ç™½è´¨-åŒ–åˆç‰©ç›¸äº’ä½œç”¨é¢„æµ‹å™¨")
    print(f"ğŸ“… å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ‘¤ å½“å‰ç”¨æˆ·: {os.getenv('USERNAME', 'Unknown')}")
    print("=" * 80)

    result_dir = main()

    if result_dir:
        print(f"\nğŸŒŸ é¢„æµ‹æˆåŠŸå®Œæˆï¼")
        print(f"ğŸŒŸ ç»“æœç›®å½•: {result_dir}")

        # å¦‚æœå¯ç”¨äº†å…±è¯†åˆ†æï¼Œç»™å‡ºå¿«é€Ÿè®¿é—®å»ºè®®
        if ENABLE_CONSENSUS_ANALYSIS:
            consensus_dir = os.path.join(result_dir, "consensus_analysis")
            if os.path.exists(consensus_dir):
                print(f"\nâ­ å¿«é€ŸæŸ¥çœ‹å…±è¯†ç»“æœ:")

                # æ£€æŸ¥å„ä¸ªå…±è¯†æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                priority_files = [
                    ("all_positive_summary.csv", "ğŸ¥‡ æœ€é«˜ä¼˜å…ˆçº§åŒ–åˆç‰©"),
                    ("high_confidence_positive_summary.csv", "ğŸ¥ˆ é«˜ç½®ä¿¡åº¦åŒ–åˆç‰©"),
                    ("majority_positive_summary.csv", "ğŸ¥‰ å¤§å¤šæ•°æ¨¡å‹åŒæ„çš„åŒ–åˆç‰©")
                ]

                for filename, description in priority_files:
                    filepath = os.path.join(consensus_dir, filename)
                    if os.path.exists(filepath):
                        try:
                            df = pd.read_csv(filepath)
                            print(f"   {description}: {len(df)} ä¸ª ({filepath})")
                        except Exception as e:
                            print(f"   {description}: æ–‡ä»¶å­˜åœ¨ä½†è¯»å–å¤±è´¥ ({filepath})")

                print(f"\nğŸ’¡ æç¤º: å»ºè®®ä» 'ğŸ¥‡ æœ€é«˜ä¼˜å…ˆçº§åŒ–åˆç‰©' å¼€å§‹æŸ¥çœ‹ï¼")

                # å°è¯•æä¾›Windowsä¸‹çš„å¿«é€Ÿæ‰“å¼€å‘½ä»¤
                try:
                    print(f"\nğŸ–±ï¸  å¿«é€Ÿæ‰“å¼€æ–‡ä»¶å¤¹:")
                    print(f"   Windows: explorer \"{consensus_dir}\"")
                    print(f"   æˆ–ç›´æ¥å¤åˆ¶è·¯å¾„åˆ°æ–‡ä»¶ç®¡ç†å™¨: {consensus_dir}")
                except:
                    pass

        print(f"\nğŸŠ æ„Ÿè°¢ä½¿ç”¨ï¼é¢„æµ‹å·²å®Œæˆï¼Œç¥ä½ çš„ç ”ç©¶é¡ºåˆ©ï¼")

    else:
        print(f"\nâŒ é¢„æµ‹è¿‡ç¨‹å¤±è´¥æˆ–è¢«ä¸­æ–­")
        print(f"âŒ è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶é‡è¯•")
        print(f"\nğŸ”§ å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ:")
        print(f"   1. æ£€æŸ¥è¾“å…¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print(f"   2. ç¡®ä¿æ¨¡å‹ç›®å½•å­˜åœ¨ä¸”åŒ…å«å¿…è¦æ–‡ä»¶")
        print(f"   3. æ£€æŸ¥å†…å­˜æ˜¯å¦è¶³å¤Ÿï¼ˆå½“å‰è®¾ç½®: {MAX_MEMORY_GB}GBï¼‰")
        print(f"   4. å°è¯•å‡å° BATCH_SIZE å‚æ•°")
        print(f"   5. ç¡®ä¿Pythonç¯å¢ƒå®‰è£…äº†æ‰€æœ‰å¿…è¦çš„åŒ…")

    print(f"\nâ° ç¨‹åºç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
