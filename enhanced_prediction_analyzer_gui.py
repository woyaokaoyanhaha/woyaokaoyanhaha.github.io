# =============================================================================
# å¢å¼ºç‰ˆé¢„æµ‹ç»“æœåˆ†æå™¨ GUI - æ”¯æŒç›´æ¥è¾“å…¥å’Œè¯¦ç»†å¯¼å‡º
# =============================================================================

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.figure import Figure
import pandas as pd
import numpy as np
import json
import os
from datetime import datetime
import threading
from collections import defaultdict, Counter
import warnings
import platform

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# =============================================================================
# å­—ä½“é…ç½®
# =============================================================================

def configure_chinese_fonts():
    """é…ç½®ä¸­æ–‡å­—ä½“"""
    try:
        import matplotlib.font_manager as fm
        
        system = platform.system()
        
        # å°è¯•ä¸åŒçš„ä¸­æ–‡å­—ä½“
        chinese_fonts = []
        
        if system == "Windows":
            chinese_fonts = [
                'Microsoft YaHei',
                'SimHei', 
                'KaiTi',
                'SimSun',
                'FangSong'
            ]
        elif system == "Darwin":  # macOS
            chinese_fonts = [
                'PingFang SC',
                'Heiti SC',
                'STSong',
                'Arial Unicode MS'
            ]
        else:  # Linux
            chinese_fonts = [
                'WenQuanYi Micro Hei',
                'WenQuanYi Zen Hei',
                'Noto Sans CJK SC',
                'Source Han Sans CN'
            ]
        
        # æŸ¥æ‰¾å¯ç”¨çš„ä¸­æ–‡å­—ä½“
        available_fonts = [f.name for f in fm.fontManager.ttflist]
        
        for font in chinese_fonts:
            if font in available_fonts:
                plt.rcParams['font.sans-serif'] = [font, 'DejaVu Sans']
                plt.rcParams['axes.unicode_minus'] = False
                print(f"âœ“ å·²é…ç½®ä¸­æ–‡å­—ä½“: {font}")
                return font
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'sans-serif']
        plt.rcParams['axes.unicode_minus'] = False
        print("âš ï¸  ä½¿ç”¨é»˜è®¤å­—ä½“è®¾ç½®")
        return "DejaVu Sans"
    
    except Exception as e:
        print(f"å­—ä½“é…ç½®å‡ºé”™: {e}")
        return "DejaVu Sans"

# é…ç½®å­—ä½“
configure_chinese_fonts()

# =============================================================================
# æ ¸å¿ƒåˆ†æå™¨ç±»
# =============================================================================

class PredictionAnalyzer:
    """å†…ç½®çš„é¢„æµ‹ç»“æœåˆ†æå™¨"""
    
    def __init__(self):
        self.raw_predictions = {}
        self.model_summary = {}
        self.available_models = []
        self.compound_stats = {}
        self.result_dir = None
        
        # å½“å‰åˆ†æå‚æ•°
        self.current_min_consensus = 2
        self.current_prob_threshold = 0.6
        self.current_conf_threshold = 0.7
    
    def find_latest_result_dir(self, base_dir="prediction_results_batch"):
        """æŸ¥æ‰¾æœ€æ–°çš„é¢„æµ‹ç»“æœç›®å½•"""
        if not os.path.exists(base_dir):
            return None
        
        # æŸ¥æ‰¾æ‰€æœ‰batch_prediction_å¼€å¤´çš„ç›®å½•
        result_dirs = [d for d in os.listdir(base_dir) 
                      if d.startswith('batch_prediction_') and 
                      os.path.isdir(os.path.join(base_dir, d))]
        
        if not result_dirs:
            return None
        
        # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œè·å–æœ€æ–°çš„
        result_dirs.sort(reverse=True)
        latest_dir = os.path.join(base_dir, result_dirs[0])
        return latest_dir
    
    def load_prediction_results(self, result_dir=None):
        """åŠ è½½é¢„æµ‹ç»“æœ"""
        if not result_dir:
            result_dir = self.find_latest_result_dir()
            if not result_dir:
                return False
        
        if not os.path.exists(result_dir):
            return False
        
        self.result_dir = result_dir
        
        # åŠ è½½æ¨¡å‹æ‘˜è¦
        summary_file = os.path.join(result_dir, "prediction_summary.json")
        if os.path.exists(summary_file):
            try:
                with open(summary_file, 'r', encoding='utf-8') as f:
                    self.model_summary = json.load(f)
            except:
                pass
        
        # åŠ è½½åŸå§‹é¢„æµ‹ç»“æœ
        self._load_individual_predictions()
        
        # åˆ†æåŒ–åˆç‰©ç»Ÿè®¡
        self._analyze_compound_statistics()
        
        return len(self.compound_stats) > 0
    
    def _load_individual_predictions(self):
        """åŠ è½½å„ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ"""
        self.raw_predictions = {}
        self.available_models = []
        
        # å¦‚æœæœ‰æ¨¡å‹æ‘˜è¦ï¼Œä½¿ç”¨æ‘˜è¦ä¿¡æ¯
        if self.model_summary:
            for model_type, models in self.model_summary.items():
                self.raw_predictions[model_type] = {}
                
                model_type_dir = os.path.join(self.result_dir, model_type.replace('/', '_'))
                if not os.path.exists(model_type_dir):
                    continue
                
                for model_name in models.keys():
                    prediction_file = os.path.join(model_type_dir, f"{model_name}_prediction.csv")
                    
                    if os.path.exists(prediction_file):
                        try:
                            df = pd.read_csv(prediction_file)
                            self.raw_predictions[model_type][model_name] = df
                            self.available_models.append(f"{model_type}_{model_name}")
                        except Exception as e:
                            print(f"åŠ è½½å¤±è´¥ {model_type}/{model_name}: {e}")
        else:
            # å¦‚æœæ²¡æœ‰æ‘˜è¦ï¼Œå°è¯•è‡ªåŠ¨å‘ç°
            self._auto_discover_predictions()
    
    def _auto_discover_predictions(self):
        """è‡ªåŠ¨å‘ç°é¢„æµ‹ç»“æœæ–‡ä»¶"""
        for item in os.listdir(self.result_dir):
            item_path = os.path.join(self.result_dir, item)
            if os.path.isdir(item_path) and not item.startswith('.'):
                model_type = item
                self.raw_predictions[model_type] = {}
                
                for file in os.listdir(item_path):
                    if file.endswith('_prediction.csv'):
                        model_name = file.replace('_prediction.csv', '')
                        file_path = os.path.join(item_path, file)
                        
                        try:
                            df = pd.read_csv(file_path)
                            self.raw_predictions[model_type][model_name] = df
                            self.available_models.append(f"{model_type}_{model_name}")
                        except Exception as e:
                            print(f"åŠ è½½å¤±è´¥ {model_type}/{model_name}: {e}")
    
    def _analyze_compound_statistics(self):
        """åˆ†æåŒ–åˆç‰©ç»Ÿè®¡ä¿¡æ¯"""
        self.compound_stats = {}
        
        # æŒ‰åŒ–åˆç‰©èšåˆæ‰€æœ‰é¢„æµ‹
        compound_predictions = defaultdict(list)
        
        for model_type, models in self.raw_predictions.items():
            for model_name, df in models.items():
                for _, row in df.iterrows():
                    key = f"{row['protein_id']}_{row['compound_id']}"
                    compound_predictions[key].append({
                        'model_type': model_type,
                        'model_name': model_name,
                        'protein_id': row['protein_id'],
                        'compound_id': row['compound_id'],
                        'prediction': row['prediction'],
                        'probability_0': row.get('probability_0', 0.5),
                        'probability_1': row.get('probability_1', 0.5),
                        'confidence': row.get('confidence', 0.5)
                    })
        
        # è®¡ç®—æ¯ä¸ªåŒ–åˆç‰©çš„ç»Ÿè®¡ä¿¡æ¯
        for compound_key, predictions in compound_predictions.items():
            protein_id, compound_id = compound_key.split('_', 1)
            
            total_models = len(predictions)
            positive_predictions = sum(1 for p in predictions if p['prediction'] == 1)
            negative_predictions = total_models - positive_predictions
            
            avg_prob_1 = np.mean([p['probability_1'] for p in predictions])
            avg_confidence = np.mean([p['confidence'] for p in predictions])
            
            self.compound_stats[compound_key] = {
                'protein_id': protein_id,
                'compound_id': compound_id,
                'total_models': total_models,
                'positive_predictions': positive_predictions,
                'negative_predictions': negative_predictions,
                'positive_ratio': positive_predictions / total_models,
                'avg_probability_1': avg_prob_1,
                'avg_confidence': avg_confidence,
                'predictions': predictions
            }
    
    def _find_all_positive(self):
        """æ‰¾åˆ°æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹çš„åŒ–åˆç‰©"""
        all_positive = []
        
        for compound_key, stats in self.compound_stats.items():
            if (stats['total_models'] >= self.current_min_consensus and 
                stats['positive_predictions'] == stats['total_models']):
                all_positive.append(stats)
        
        return sorted(all_positive, key=lambda x: x['avg_confidence'], reverse=True)
    
    def _find_majority_positive(self):
        """æ‰¾åˆ°å¤§å¤šæ•°æ¨¡å‹é¢„æµ‹ä¸ºæ­£ä¾‹çš„åŒ–åˆç‰©"""
        majority_positive = []
        
        for compound_key, stats in self.compound_stats.items():
            if (stats['total_models'] >= self.current_min_consensus and 
                stats['positive_ratio'] > 0.5 and
                stats['positive_predictions'] >= self.current_min_consensus):
                majority_positive.append(stats)
        
        return sorted(majority_positive, key=lambda x: x['avg_confidence'], reverse=True)
    
    def _find_high_confidence(self):
        """æ‰¾åˆ°é«˜ç½®ä¿¡åº¦çš„åŒ–åˆç‰©"""
        high_confidence = []
        
        for compound_key, stats in self.compound_stats.items():
            if (stats['total_models'] >= self.current_min_consensus and 
                stats['avg_confidence'] >= self.current_conf_threshold and
                stats['positive_predictions'] >= self.current_min_consensus):
                high_confidence.append(stats)
        
        return sorted(high_confidence, key=lambda x: x['avg_confidence'], reverse=True)
    
    def _find_high_probability(self):
        """æ‰¾åˆ°é«˜æ¦‚ç‡çš„åŒ–åˆç‰©"""
        high_probability = []
        
        for compound_key, stats in self.compound_stats.items():
            if (stats['total_models'] >= self.current_min_consensus and 
                stats['avg_probability_1'] >= self.current_prob_threshold and
                stats['positive_predictions'] >= self.current_min_consensus):
                high_probability.append(stats)
        
        return sorted(high_probability, key=lambda x: x['avg_probability_1'], reverse=True)
    
    def _find_custom_consensus(self):
        """è‡ªå®šä¹‰å…±è¯†åˆ†æ"""
        custom_consensus = []
        
        for compound_key, stats in self.compound_stats.items():
            if (stats['total_models'] >= self.current_min_consensus and 
                stats['positive_predictions'] >= self.current_min_consensus and
                stats['avg_confidence'] >= self.current_conf_threshold and
                stats['avg_probability_1'] >= self.current_prob_threshold):
                custom_consensus.append(stats)
        
        return sorted(custom_consensus, key=lambda x: (x['avg_confidence'] + x['avg_probability_1'])/2, reverse=True)

# =============================================================================
# å¢å¼ºç‰ˆGUIä¸»ç±»
# =============================================================================

class EnhancedPredictionAnalyzerGUI:
    """å¢å¼ºç‰ˆé¢„æµ‹ç»“æœåˆ†æå™¨GUI"""
    
    def __init__(self, root):
        self.root = root
        self.analyzer = PredictionAnalyzer()
        self.current_figure = None
        
        # åˆå§‹åŒ–çŠ¶æ€å˜é‡ï¼ˆå¿…é¡»åœ¨create_widgetsä¹‹å‰ï¼‰
        self.status_var = tk.StringVar(value="å‡†å¤‡å°±ç»ª")
        self.progress_var = tk.DoubleVar()
        self.data_info_var = tk.StringVar(value="æœªåŠ è½½æ•°æ®")
        self.result_dir_var = tk.StringVar()
        
        # åˆå§‹åŒ–å‚æ•°å˜é‡
        self.min_consensus_var = tk.IntVar(value=2)
        self.prob_threshold_var = tk.DoubleVar(value=0.6)
        self.conf_threshold_var = tk.DoubleVar(value=0.7)
        
        # æ–°å¢ï¼šç›´æ¥è¾“å…¥çš„å˜é‡
        self.prob_entry_var = tk.StringVar(value="0.60")
        self.conf_entry_var = tk.StringVar(value="0.70")
        
        # é…ç½®ä¸»çª—å£
        self.setup_main_window()
        
        # é…ç½®æ ·å¼
        self.setup_styles()
        
        # åˆ›å»ºç•Œé¢
        self.create_widgets()
    
    def setup_main_window(self):
        """é…ç½®ä¸»çª—å£"""
        self.root.title("ğŸ”¬ é¢„æµ‹ç»“æœåˆ†æå™¨ v2.1 - å¢å¼ºç‰ˆ")
        self.root.geometry("1400x900")
        self.root.minsize(1200, 800)
        
        # é…ç½®ç½‘æ ¼æƒé‡
        self.root.grid_rowconfigure(0, weight=1)
        self.root.grid_columnconfigure(0, weight=1)
    
    def setup_styles(self):
        """é…ç½®æ ·å¼"""
        style = ttk.Style()
        
        # é…ç½®ç°ä»£åŒ–ä¸»é¢˜
        available_themes = style.theme_names()
        if 'clam' in available_themes:
            style.theme_use('clam')
        elif 'alt' in available_themes:
            style.theme_use('alt')
        
        # è‡ªå®šä¹‰æ ·å¼
        style.configure('Title.TLabel', font=('Arial', 16, 'bold'))
        style.configure('Heading.TLabel', font=('Arial', 12, 'bold'))
        style.configure('Success.TLabel', foreground='green')
        style.configure('Error.TLabel', foreground='red')
        style.configure('Warning.TLabel', foreground='orange')
    
    def create_widgets(self):
        """åˆ›å»ºä¸»ç•Œé¢ç»„ä»¶"""
        # åˆ›å»ºä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        main_frame.grid_rowconfigure(1, weight=1)
        main_frame.grid_columnconfigure(1, weight=1)
        
        # é¡¶éƒ¨æ ‡é¢˜æ 
        self.create_header(main_frame)
        
        # åˆ›å»ºå·¦ä¾§æ§åˆ¶é¢æ¿å’Œå³ä¾§æ˜¾ç¤ºåŒºåŸŸ
        self.create_main_content(main_frame)
        
        # åº•éƒ¨çŠ¶æ€æ 
        self.create_status_bar(main_frame)
    
    def create_header(self, parent):
        """åˆ›å»ºé¡¶éƒ¨æ ‡é¢˜æ """
        header_frame = ttk.Frame(parent)
        header_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        header_frame.grid_columnconfigure(1, weight=1)
        
        # æ ‡é¢˜
        title_label = ttk.Label(header_frame, text="ğŸ”¬ é¢„æµ‹ç»“æœåˆ†æå™¨ v2.1", style='Title.TLabel')
        title_label.grid(row=0, column=0, sticky=tk.W)
        
        # ç”¨æˆ·ä¿¡æ¯
        user_info = f"ç”¨æˆ·: woyaokaoyanhaha | æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        user_label = ttk.Label(header_frame, text=user_info)
        user_label.grid(row=0, column=1, sticky=tk.E)
        
        # åˆ†éš”çº¿
        separator = ttk.Separator(header_frame, orient='horizontal')
        separator.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(5, 0))
    
    def create_main_content(self, parent):
        """åˆ›å»ºä¸»è¦å†…å®¹åŒºåŸŸ"""
        # å·¦ä¾§æ§åˆ¶é¢æ¿
        self.create_control_panel(parent)
        
        # å³ä¾§æ˜¾ç¤ºåŒºåŸŸ
        self.create_display_area(parent)
    
    def create_control_panel(self, parent):
        """åˆ›å»ºå·¦ä¾§æ§åˆ¶é¢æ¿"""
        # æ§åˆ¶é¢æ¿æ¡†æ¶
        control_frame = ttk.LabelFrame(parent, text="ğŸ“Š æ§åˆ¶é¢æ¿", padding="10")
        control_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), padx=(0, 10))
        control_frame.grid_columnconfigure(0, weight=1)
        
        # æ–‡ä»¶åŠ è½½åŒºåŸŸ
        self.create_file_section(control_frame)
        
        # å¢å¼ºç‰ˆå‚æ•°è®¾ç½®åŒºåŸŸ
        self.create_enhanced_parameter_section(control_frame)
        
        # åˆ†æåŠŸèƒ½åŒºåŸŸ
        self.create_analysis_section(control_frame)
        
        # å¢å¼ºç‰ˆå¯¼å‡ºåŠŸèƒ½åŒºåŸŸ
        self.create_enhanced_export_section(control_frame)
    
    def create_file_section(self, parent):
        """åˆ›å»ºæ–‡ä»¶åŠ è½½åŒºåŸŸ"""
        file_frame = ttk.LabelFrame(parent, text="ğŸ“ æ•°æ®åŠ è½½")
        file_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        file_frame.grid_columnconfigure(1, weight=1)
        
        # ç»“æœç›®å½•é€‰æ‹©
        ttk.Label(file_frame, text="é¢„æµ‹ç»“æœç›®å½•:").grid(row=0, column=0, sticky=tk.W, padx=(5, 5))
        
        result_dir_entry = ttk.Entry(file_frame, textvariable=self.result_dir_var, width=30)
        result_dir_entry.grid(row=0, column=1, sticky=(tk.W, tk.E), padx=(0, 5))
        
        browse_btn = ttk.Button(file_frame, text="æµè§ˆ", command=self.browse_result_dir)
        browse_btn.grid(row=0, column=2, padx=(0, 5))
        
        # å¿«é€ŸåŠ è½½æŒ‰é’®
        quick_load_btn = ttk.Button(file_frame, text="ğŸ” è‡ªåŠ¨æŸ¥æ‰¾", command=self.auto_load_latest)
        quick_load_btn.grid(row=1, column=0, pady=(5, 0), sticky=(tk.W, tk.E))
        
        # åŠ è½½æŒ‰é’®
        load_btn = ttk.Button(file_frame, text="ğŸ”„ åŠ è½½æ•°æ®", command=self.load_data)
        load_btn.grid(row=1, column=1, columnspan=2, pady=(5, 0), sticky=(tk.W, tk.E))
        
        # æ•°æ®ä¿¡æ¯æ˜¾ç¤º
        info_label = ttk.Label(file_frame, textvariable=self.data_info_var, style='Success.TLabel')
        info_label.grid(row=2, column=0, columnspan=3, pady=(5, 0))
    
    def create_enhanced_parameter_section(self, parent):
        """åˆ›å»ºå¢å¼ºç‰ˆå‚æ•°è®¾ç½®åŒºåŸŸï¼ˆæ”¯æŒæ»‘å—å’Œç›´æ¥è¾“å…¥ï¼‰"""
        param_frame = ttk.LabelFrame(parent, text="âš™ï¸ ç­›é€‰å‚æ•°ï¼ˆæ»‘å—+ç›´æ¥è¾“å…¥ï¼‰")
        param_frame.grid(row=1, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        param_frame.grid_columnconfigure(2, weight=1)
        
        # æœ€å°å…±è¯†æ¨¡å‹æ•°
        ttk.Label(param_frame, text="æœ€å°å…±è¯†æ¨¡å‹æ•°:").grid(row=0, column=0, sticky=tk.W, padx=(5, 5))
        consensus_spin = ttk.Spinbox(param_frame, from_=1, to=10, textvariable=self.min_consensus_var, width=10)
        consensus_spin.grid(row=0, column=1, sticky=tk.W, padx=(0, 5))
        
        # æ¦‚ç‡é˜ˆå€¼ - æ»‘å—+è¾“å…¥æ¡†ç»„åˆ
        ttk.Label(param_frame, text="æ¦‚ç‡é˜ˆå€¼:").grid(row=1, column=0, sticky=tk.W, padx=(5, 5))
        
        # æ¦‚ç‡æ»‘å—
        prob_scale = ttk.Scale(param_frame, from_=0.0, to=1.0, variable=self.prob_threshold_var, 
                              orient=tk.HORIZONTAL, length=120)
        prob_scale.grid(row=1, column=1, sticky=(tk.W, tk.E), padx=(0, 5))
        
        # æ¦‚ç‡ç›´æ¥è¾“å…¥æ¡†
        prob_entry = ttk.Entry(param_frame, textvariable=self.prob_entry_var, width=8)
        prob_entry.grid(row=1, column=2, padx=(5, 5))
        
        # æ¦‚ç‡åŒæ­¥æŒ‰é’®
        prob_sync_btn = ttk.Button(param_frame, text="â†”", width=3, 
                                  command=self.sync_prob_from_entry)
        prob_sync_btn.grid(row=1, column=3, padx=(0, 5))
        
        # ç½®ä¿¡åº¦é˜ˆå€¼ - æ»‘å—+è¾“å…¥æ¡†ç»„åˆ
        ttk.Label(param_frame, text="ç½®ä¿¡åº¦é˜ˆå€¼:").grid(row=2, column=0, sticky=tk.W, padx=(5, 5))
        
        # ç½®ä¿¡åº¦æ»‘å—
        conf_scale = ttk.Scale(param_frame, from_=0.0, to=1.0, variable=self.conf_threshold_var, 
                              orient=tk.HORIZONTAL, length=120)
        conf_scale.grid(row=2, column=1, sticky=(tk.W, tk.E), padx=(0, 5))
        
        # ç½®ä¿¡åº¦ç›´æ¥è¾“å…¥æ¡†
        conf_entry = ttk.Entry(param_frame, textvariable=self.conf_entry_var, width=8)
        conf_entry.grid(row=2, column=2, padx=(5, 5))
        
        # ç½®ä¿¡åº¦åŒæ­¥æŒ‰é’®
        conf_sync_btn = ttk.Button(param_frame, text="â†”", width=3, 
                                  command=self.sync_conf_from_entry)
        conf_sync_btn.grid(row=2, column=3, padx=(0, 5))
        
        # ç»‘å®šæ»‘å—æ›´æ–°äº‹ä»¶ï¼ˆæ»‘å—â†’è¾“å…¥æ¡†ï¼‰
        def update_prob_entry(*args):
            self.prob_entry_var.set(f"{self.prob_threshold_var.get():.3f}")
        self.prob_threshold_var.trace('w', update_prob_entry)
        
        def update_conf_entry(*args):
            self.conf_entry_var.set(f"{self.conf_threshold_var.get():.3f}")
        self.conf_threshold_var.trace('w', update_conf_entry)
        
        # ç»‘å®šè¾“å…¥æ¡†å›è½¦äº‹ä»¶ï¼ˆè¾“å…¥æ¡†â†’æ»‘å—ï¼‰
        prob_entry.bind('<Return>', lambda e: self.sync_prob_from_entry())
        conf_entry.bind('<Return>', lambda e: self.sync_conf_from_entry())
        
        # å¿«é€Ÿè®¾ç½®æŒ‰é’®
        quick_frame = ttk.Frame(param_frame)
        quick_frame.grid(row=3, column=0, columnspan=4, pady=(10, 0), sticky=(tk.W, tk.E))
        
        ttk.Label(quick_frame, text="å¿«é€Ÿè®¾ç½®:").pack(side=tk.LEFT, padx=(0, 5))
        
        quick_buttons = [
            ("ä¸¥æ ¼ (0.8/0.9)", lambda: self.set_quick_params(0.8, 0.9)),
            ("ä¸­ç­‰ (0.6/0.7)", lambda: self.set_quick_params(0.6, 0.7)),
            ("å®½æ¾ (0.5/0.6)", lambda: self.set_quick_params(0.5, 0.6))
        ]
        
        for text, command in quick_buttons:
            btn = ttk.Button(quick_frame, text=text, command=command)
            btn.pack(side=tk.LEFT, padx=2)
        
        # åº”ç”¨å‚æ•°æŒ‰é’®
        apply_btn = ttk.Button(param_frame, text="âœ… åº”ç”¨å‚æ•°", command=self.apply_parameters)
        apply_btn.grid(row=4, column=0, columnspan=4, pady=(10, 5), sticky=(tk.W, tk.E))
    
    def sync_prob_from_entry(self):
        """ä»è¾“å…¥æ¡†åŒæ­¥æ¦‚ç‡é˜ˆå€¼åˆ°æ»‘å—"""
        try:
            value = float(self.prob_entry_var.get())
            if 0.0 <= value <= 1.0:
                self.prob_threshold_var.set(value)
            else:
                messagebox.showwarning("è¾“å…¥é”™è¯¯", "æ¦‚ç‡é˜ˆå€¼å¿…é¡»åœ¨0.0-1.0ä¹‹é—´")
                self.prob_entry_var.set(f"{self.prob_threshold_var.get():.3f}")
        except ValueError:
            messagebox.showwarning("è¾“å…¥é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å€¼")
            self.prob_entry_var.set(f"{self.prob_threshold_var.get():.3f}")
    
    def sync_conf_from_entry(self):
        """ä»è¾“å…¥æ¡†åŒæ­¥ç½®ä¿¡åº¦é˜ˆå€¼åˆ°æ»‘å—"""
        try:
            value = float(self.conf_entry_var.get())
            if 0.0 <= value <= 1.0:
                self.conf_threshold_var.set(value)
            else:
                messagebox.showwarning("è¾“å…¥é”™è¯¯", "ç½®ä¿¡åº¦é˜ˆå€¼å¿…é¡»åœ¨0.0-1.0ä¹‹é—´")
                self.conf_entry_var.set(f"{self.conf_threshold_var.get():.3f}")
        except ValueError:
            messagebox.showwarning("è¾“å…¥é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å€¼")
            self.conf_entry_var.set(f"{self.conf_threshold_var.get():.3f}")
    
    def set_quick_params(self, prob, conf):
        """å¿«é€Ÿè®¾ç½®å‚æ•°"""
        self.prob_threshold_var.set(prob)
        self.conf_threshold_var.set(conf)
        self.prob_entry_var.set(f"{prob:.3f}")
        self.conf_entry_var.set(f"{conf:.3f}")
        messagebox.showinfo("å‚æ•°è®¾ç½®", f"å·²è®¾ç½®æ¦‚ç‡é˜ˆå€¼={prob}, ç½®ä¿¡åº¦é˜ˆå€¼={conf}")
    
    def create_analysis_section(self, parent):
        """åˆ›å»ºåˆ†æåŠŸèƒ½åŒºåŸŸ"""
        analysis_frame = ttk.LabelFrame(parent, text="ğŸ” åˆ†æåŠŸèƒ½")
        analysis_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        analysis_frame.grid_columnconfigure(0, weight=1)
        
        # åˆ†ææŒ‰é’®
        buttons = [
            ("ğŸ“Š åŸºç¡€ç»Ÿè®¡", self.show_basic_stats),
            ("ğŸ¯ å…±è¯†åˆ†æ", self.show_consensus_analysis),
            ("ğŸ“ˆ é˜ˆå€¼æ•æ„Ÿæ€§", self.show_threshold_sensitivity),
            ("ğŸ”¥ æ¨¡å‹ä¸€è‡´æ€§", self.show_model_consistency),
            ("ğŸ¨ åˆ†å¸ƒå¯è§†åŒ–", self.show_distribution_plots),
            ("ğŸ¯ ç­›é€‰æ¼æ–—", self.show_funnel_analysis)
        ]
        
        for i, (text, command) in enumerate(buttons):
            btn = ttk.Button(analysis_frame, text=text, command=command)
            btn.grid(row=i, column=0, sticky=(tk.W, tk.E), pady=2)
    
    def create_enhanced_export_section(self, parent):
        """åˆ›å»ºå¢å¼ºç‰ˆå¯¼å‡ºåŠŸèƒ½åŒºåŸŸ"""
        export_frame = ttk.LabelFrame(parent, text="ğŸ’¾ å¯¼å‡ºåŠŸèƒ½ï¼ˆå¢å¼ºç‰ˆï¼‰")
        export_frame.grid(row=3, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        export_frame.grid_columnconfigure(0, weight=1)
        
        # å¯¼å‡ºæŒ‰é’®
        export_buttons = [
            ("ğŸ“‹ ç”Ÿæˆåˆ†ææŠ¥å‘Š", self.generate_report),
            ("ğŸ“ å¯¼å‡ºç­›é€‰ç»“æœï¼ˆåŸºç¡€ï¼‰", self.export_filtered_results_basic),
            ("ğŸ” å¯¼å‡ºç­›é€‰ç»“æœï¼ˆè¯¦ç»†ï¼‰", self.export_filtered_results_detailed),
            ("ğŸ“Š å¯¼å‡ºæ‰€æœ‰æ¨¡å‹æ•°æ®", self.export_all_model_data),
            ("ğŸ–¼ï¸ ä¿å­˜å½“å‰å›¾è¡¨", self.save_current_plot)
        ]
        
        for i, (text, command) in enumerate(export_buttons):
            btn = ttk.Button(export_frame, text=text, command=command)
            btn.grid(row=i, column=0, sticky=(tk.W, tk.E), pady=2)
    
    def create_display_area(self, parent):
        """åˆ›å»ºå³ä¾§æ˜¾ç¤ºåŒºåŸŸ"""
        # æ˜¾ç¤ºåŒºåŸŸæ¡†æ¶
        display_frame = ttk.Frame(parent)
        display_frame.grid(row=1, column=1, sticky=(tk.W, tk.E, tk.N, tk.S))
        display_frame.grid_rowconfigure(0, weight=1)
        display_frame.grid_columnconfigure(0, weight=1)
        
        # åˆ›å»ºç¬”è®°æœ¬æ§ä»¶ï¼ˆæ ‡ç­¾é¡µï¼‰
        self.notebook = ttk.Notebook(display_frame)
        self.notebook.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # å›¾è¡¨æ˜¾ç¤ºæ ‡ç­¾é¡µ
        self.create_plot_tab()
        
        # æ•°æ®è¡¨æ ¼æ ‡ç­¾é¡µ
        self.create_table_tab()
        
        # è¯¦ç»†ä¿¡æ¯æ ‡ç­¾é¡µ
        self.create_info_tab()
    
    def create_plot_tab(self):
        """åˆ›å»ºå›¾è¡¨æ˜¾ç¤ºæ ‡ç­¾é¡µ"""
        plot_frame = ttk.Frame(self.notebook)
        self.notebook.add(plot_frame, text="ğŸ“Š å›¾è¡¨")
        
        # åˆ›å»ºmatplotlibå›¾è¡¨
        self.figure = Figure(figsize=(10, 6), dpi=100)
        self.canvas = FigureCanvasTkAgg(self.figure, plot_frame)
        self.canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        # æ·»åŠ å·¥å…·æ 
        toolbar_frame = ttk.Frame(plot_frame)
        toolbar_frame.pack(fill=tk.X)
        
        self.toolbar = NavigationToolbar2Tk(self.canvas, toolbar_frame)
        self.toolbar.update()
        
        # åˆå§‹åŒ–ç©ºå›¾è¡¨
        self.show_welcome_plot()
    
    def create_table_tab(self):
        """åˆ›å»ºæ•°æ®è¡¨æ ¼æ ‡ç­¾é¡µ"""
        table_frame = ttk.Frame(self.notebook)
        self.notebook.add(table_frame, text="ğŸ“‹ æ•°æ®è¡¨æ ¼")
        
        # åˆ›å»ºæ ‘å½¢è§†å›¾
        self.tree = ttk.Treeview(table_frame, show='headings')
        
        # æ»šåŠ¨æ¡
        v_scrollbar = ttk.Scrollbar(table_frame, orient=tk.VERTICAL, command=self.tree.yview)
        h_scrollbar = ttk.Scrollbar(table_frame, orient=tk.HORIZONTAL, command=self.tree.xview)
        
        self.tree.configure(yscrollcommand=v_scrollbar.set, xscrollcommand=h_scrollbar.set)
        
        # å¸ƒå±€
        self.tree.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        v_scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))
        h_scrollbar.grid(row=1, column=0, sticky=(tk.W, tk.E))
        
        table_frame.grid_rowconfigure(0, weight=1)
        table_frame.grid_columnconfigure(0, weight=1)
    
    def create_info_tab(self):
        """åˆ›å»ºè¯¦ç»†ä¿¡æ¯æ ‡ç­¾é¡µ"""
        info_frame = ttk.Frame(self.notebook)
        self.notebook.add(info_frame, text="â„¹ï¸ è¯¦ç»†ä¿¡æ¯")
        
        # åˆ›å»ºæ»šåŠ¨æ–‡æœ¬æ¡†
        self.info_text = scrolledtext.ScrolledText(info_frame, wrap=tk.WORD, 
                                                  font=('Consolas', 10))
        self.info_text.pack(fill=tk.BOTH, expand=True)
        
        # åˆå§‹åŒ–æ¬¢è¿ä¿¡æ¯
        self.show_welcome_info()
    
    def create_status_bar(self, parent):
        """åˆ›å»ºåº•éƒ¨çŠ¶æ€æ """
        status_frame = ttk.Frame(parent)
        status_frame.grid(row=2, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(10, 0))
        status_frame.grid_columnconfigure(1, weight=1)
        
        # çŠ¶æ€æ ‡ç­¾
        ttk.Label(status_frame, text="çŠ¶æ€:").grid(row=0, column=0, padx=(0, 5))
        status_label = ttk.Label(status_frame, textvariable=self.status_var)
        status_label.grid(row=0, column=1, sticky=tk.W)
        
        # è¿›åº¦æ¡
        self.progress_bar = ttk.Progressbar(status_frame, variable=self.progress_var, 
                                           mode='determinate', length=200)
        self.progress_bar.grid(row=0, column=2, padx=(10, 0))
    
    def show_welcome_plot(self):
        """æ˜¾ç¤ºæ¬¢è¿å›¾è¡¨"""
        self.figure.clear()
        ax = self.figure.add_subplot(111)
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¬¢è¿å›¾è¡¨
        x = np.linspace(0, 10, 100)
        y = np.sin(x) * np.exp(-x/5)
        
        ax.plot(x, y, 'b-', linewidth=2, alpha=0.7)
        ax.set_title('æ¬¢è¿ä½¿ç”¨é¢„æµ‹ç»“æœåˆ†æå™¨ v2.1', fontsize=16, fontweight='bold')
        ax.set_xlabel('è¯·å…ˆåŠ è½½é¢„æµ‹æ•°æ®', fontsize=12)
        ax.set_ylabel('ç„¶åé€‰æ‹©åˆ†æåŠŸèƒ½', fontsize=12)
        ax.grid(True, alpha=0.3)
        
        self.canvas.draw()
    
    def show_welcome_info(self):
        """æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯"""
        welcome_text = """
ğŸ”¬ é¢„æµ‹ç»“æœåˆ†æå™¨ GUI v2.1 - å¢å¼ºç‰ˆ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ‰ æ–°åŠŸèƒ½äº®ç‚¹:
âœ¨ å‚æ•°è°ƒæ•´ï¼šæ”¯æŒæ»‘å—è°ƒæ•´ + ç›´æ¥æ•°å€¼è¾“å…¥
âœ¨ å¯¼å‡ºå¢å¼ºï¼šåŸºç¡€ç»Ÿè®¡ + è¯¦ç»†æ¨¡å‹æ•°æ®å¯¼å‡º
âœ¨ å¿«é€Ÿè®¾ç½®ï¼šé¢„è®¾å‚æ•°ç»„åˆï¼Œä¸€é”®åº”ç”¨

ğŸ“‹ ä½¿ç”¨æ­¥éª¤:
1. ç‚¹å‡»"æµè§ˆ"é€‰æ‹©é¢„æµ‹ç»“æœç›®å½•ï¼Œæˆ–ç‚¹å‡»"ğŸ” è‡ªåŠ¨æŸ¥æ‰¾"
2. ç‚¹å‡»"ğŸ”„ åŠ è½½æ•°æ®"å¯¼å…¥åˆ†ææ•°æ®
3. è°ƒæ•´ç­›é€‰å‚æ•°ï¼š
   â€¢ ä½¿ç”¨æ»‘å—æ‹–æ‹½è°ƒæ•´
   â€¢ ç›´æ¥åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥ç²¾ç¡®æ•°å€¼
   â€¢ ç‚¹å‡»"â†”"æŒ‰é’®åŒæ­¥è¾“å…¥æ¡†åˆ°æ»‘å—
   â€¢ ä½¿ç”¨å¿«é€Ÿè®¾ç½®æŒ‰é’®åº”ç”¨é¢„è®¾ç»„åˆ
4. ç‚¹å‡»"âœ… åº”ç”¨å‚æ•°"ç¡®è®¤è®¾ç½®
5. é€‰æ‹©åˆ†æåŠŸèƒ½æŸ¥çœ‹ç»“æœ
6. ä½¿ç”¨å¢å¼ºç‰ˆå¯¼å‡ºåŠŸèƒ½ï¼š
   â€¢ ğŸ“ åŸºç¡€å¯¼å‡ºï¼šå¹³å‡ç»Ÿè®¡æ•°æ®
   â€¢ ğŸ” è¯¦ç»†å¯¼å‡ºï¼šåŒ…å«æ¯ä¸ªæ¨¡å‹çš„é¢„æµ‹æ•°æ®
   â€¢ ğŸ“Š å…¨é‡å¯¼å‡ºï¼šæ‰€æœ‰æ¨¡å‹çš„å®Œæ•´æ•°æ®

ğŸ¯ ä¸»è¦åŠŸèƒ½:
â€¢ ğŸ“Š åŸºç¡€ç»Ÿè®¡ - æŸ¥çœ‹æ•°æ®æ¦‚å†µ
â€¢ ğŸ¯ å…±è¯†åˆ†æ - ä¸åŒç­›é€‰ç­–ç•¥çš„ç»“æœ
â€¢ ğŸ“ˆ é˜ˆå€¼æ•æ„Ÿæ€§ - å‚æ•°å¯¹ç»“æœçš„å½±å“
â€¢ ğŸ”¥ æ¨¡å‹ä¸€è‡´æ€§ - æ¨¡å‹é—´é¢„æµ‹ä¸€è‡´æ€§
â€¢ ğŸ¨ åˆ†å¸ƒå¯è§†åŒ– - æ¦‚ç‡å’Œç½®ä¿¡åº¦åˆ†å¸ƒ
â€¢ ğŸ¯ ç­›é€‰æ¼æ–— - é€å±‚ç­›é€‰å¯è§†åŒ–

ğŸ’¾ å¢å¼ºç‰ˆå¯¼å‡ºåŠŸèƒ½:
â€¢ ğŸ“‹ è‡ªåŠ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š
â€¢ ğŸ“ åŸºç¡€ç­›é€‰ç»“æœï¼ˆæ‘˜è¦æ•°æ®ï¼‰
â€¢ ğŸ” è¯¦ç»†ç­›é€‰ç»“æœï¼ˆå«æ¯ä¸ªæ¨¡å‹é¢„æµ‹ï¼‰
â€¢ ğŸ“Š å…¨é‡æ¨¡å‹æ•°æ®ï¼ˆå®Œæ•´åŸå§‹æ•°æ®ï¼‰
â€¢ ğŸ–¼ï¸ é«˜è´¨é‡å›¾è¡¨ä¿å­˜

ğŸ’¡ ä½¿ç”¨æç¤º:
â€¢ å‚æ•°è¾“å…¥æ”¯æŒå›è½¦é”®å¿«é€Ÿç¡®è®¤
â€¢ å¿«é€Ÿè®¾ç½®å¯ä»¥ä¸€é”®åº”ç”¨å¸¸ç”¨å‚æ•°ç»„åˆ
â€¢ è¯¦ç»†å¯¼å‡ºåŒ…å«æ¯ä¸ªæ¨¡å‹çš„å•ç‹¬é¢„æµ‹ç»“æœ
â€¢ æ‰€æœ‰å›¾è¡¨æ”¯æŒç¼©æ”¾ã€å¹³ç§»å’Œä¿å­˜

å¼€å‘è€…: woyaokaoyanhaha
ç‰ˆæœ¬: 2.1.0 (å¢å¼ºç‰ˆ)
æ—¶é—´: """ + datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        self.info_text.delete(1.0, tk.END)
        self.info_text.insert(tk.END, welcome_text)
    
    # ===============================
    # äº‹ä»¶å¤„ç†å‡½æ•°
    # ===============================
    
    def browse_result_dir(self):
        """æµè§ˆé€‰æ‹©ç»“æœç›®å½•"""
        directory = filedialog.askdirectory(
            title="é€‰æ‹©é¢„æµ‹ç»“æœç›®å½•",
            initialdir=os.getcwd()
        )
        if directory:
            self.result_dir_var.set(directory)
    
    def auto_load_latest(self):
        """è‡ªåŠ¨æŸ¥æ‰¾å¹¶åŠ è½½æœ€æ–°çš„é¢„æµ‹ç»“æœ"""
        self.status_var.set("æ­£åœ¨æŸ¥æ‰¾æœ€æ–°é¢„æµ‹ç»“æœ...")
        
        latest_dir = self.analyzer.find_latest_result_dir()
        if latest_dir:
            self.result_dir_var.set(latest_dir)
            self.status_var.set(f"æ‰¾åˆ°æœ€æ–°ç»“æœ: {os.path.basename(latest_dir)}")
            messagebox.showinfo("æ‰¾åˆ°ç»“æœ", f"æ‰¾åˆ°æœ€æ–°é¢„æµ‹ç»“æœ:\n{latest_dir}")
        else:
            self.status_var.set("æœªæ‰¾åˆ°é¢„æµ‹ç»“æœ")
            messagebox.showwarning("æœªæ‰¾åˆ°", "æœªæ‰¾åˆ°é¢„æµ‹ç»“æœç›®å½•\nè¯·æ‰‹åŠ¨é€‰æ‹©æˆ–æ£€æŸ¥ prediction_results_batch ç›®å½•")
    
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        result_dir = self.result_dir_var.get().strip()
        
        if not result_dir:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©é¢„æµ‹ç»“æœç›®å½•æˆ–ç‚¹å‡»'ğŸ” è‡ªåŠ¨æŸ¥æ‰¾'")
            return
        
        if not os.path.exists(result_dir):
            messagebox.showerror("é”™è¯¯", f"ç›®å½•ä¸å­˜åœ¨: {result_dir}")
            return
        
        # æ˜¾ç¤ºåŠ è½½è¿›åº¦
        self.status_var.set("æ­£åœ¨åŠ è½½æ•°æ®...")
        self.progress_var.set(0)
        self.root.update()
        
        try:
            # åœ¨åå°çº¿ç¨‹ä¸­åŠ è½½æ•°æ®
            def load_thread():
                try:
                    success = self.analyzer.load_prediction_results(result_dir)
                    
                    # æ›´æ–°UIï¼ˆéœ€è¦åœ¨ä¸»çº¿ç¨‹ä¸­æ‰§è¡Œï¼‰
                    self.root.after(0, self.on_data_loaded, success)
                    
                except Exception as e:
                    self.root.after(0, self.on_data_load_error, str(e))
            
            thread = threading.Thread(target=load_thread)
            thread.daemon = True
            thread.start()
            
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
            self.status_var.set("åŠ è½½å¤±è´¥")
    
    def on_data_loaded(self, success):
        """æ•°æ®åŠ è½½å®Œæˆå›è°ƒ"""
        if success:
            compound_count = len(self.analyzer.compound_stats)
            model_count = len(self.analyzer.available_models)
            
            info_text = f"âœ… æ•°æ®åŠ è½½æˆåŠŸ | åŒ–åˆç‰©: {compound_count} | æ¨¡å‹: {model_count}"
            self.data_info_var.set(info_text)
            self.status_var.set("æ•°æ®åŠ è½½æˆåŠŸ")
            
            # æ›´æ–°è¯¦ç»†ä¿¡æ¯
            self.update_info_display()
            
            # æ˜¾ç¤ºåŸºç¡€ç»Ÿè®¡å›¾è¡¨
            self.show_basic_stats()
            
        else:
            self.data_info_var.set("âŒ æ•°æ®åŠ è½½å¤±è´¥")
            self.status_var.set("åŠ è½½å¤±è´¥")
            messagebox.showerror("é”™è¯¯", "æ•°æ®åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›®å½•ç»“æ„")
        
        self.progress_var.set(100)
    
    def on_data_load_error(self, error_msg):
        """æ•°æ®åŠ è½½é”™è¯¯å›è°ƒ"""
        self.data_info_var.set("âŒ æ•°æ®åŠ è½½å¤±è´¥")
        self.status_var.set("åŠ è½½å¤±è´¥")
        messagebox.showerror("é”™è¯¯", f"æ•°æ®åŠ è½½å¤±è´¥: {error_msg}")
        self.progress_var.set(0)
    
    def apply_parameters(self):
        """åº”ç”¨å‚æ•°è®¾ç½®"""
        if len(self.analyzer.compound_stats) == 0:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½æ•°æ®")
            return
        
        # æ›´æ–°åˆ†æå™¨å‚æ•°
        self.analyzer.current_min_consensus = self.min_consensus_var.get()
        self.analyzer.current_prob_threshold = self.prob_threshold_var.get()
        self.analyzer.current_conf_threshold = self.conf_threshold_var.get()
        
        self.status_var.set("å‚æ•°å·²æ›´æ–°")
        messagebox.showinfo("æˆåŠŸ", f"ç­›é€‰å‚æ•°å·²åº”ç”¨:\n"
                                   f"æœ€å°å…±è¯†æ¨¡å‹æ•°: {self.analyzer.current_min_consensus}\n"
                                   f"æ¦‚ç‡é˜ˆå€¼: {self.analyzer.current_prob_threshold:.3f}\n"
                                   f"ç½®ä¿¡åº¦é˜ˆå€¼: {self.analyzer.current_conf_threshold:.3f}")
    
    def check_analyzer(self):
        """æ£€æŸ¥åˆ†æå™¨æ˜¯å¦å·²åŠ è½½"""
        if len(self.analyzer.compound_stats) == 0:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½é¢„æµ‹æ•°æ®")
            return False
        return True
    
    # ===============================
    # å¢å¼ºç‰ˆå¯¼å‡ºåŠŸèƒ½
    # ===============================
    
    def export_filtered_results_basic(self):
        """å¯¼å‡ºåŸºç¡€ç­›é€‰ç»“æœï¼ˆå¹³å‡æ•°æ®ï¼‰"""
        if not self.check_analyzer():
            return
        
        # é€‰æ‹©ä¿å­˜ç›®å½•
        directory = filedialog.askdirectory(title="é€‰æ‹©å¯¼å‡ºç›®å½• - åŸºç¡€ç»“æœ")
        if not directory:
            return
        
        self.status_var.set("æ­£åœ¨å¯¼å‡ºåŸºç¡€ç­›é€‰ç»“æœ...")
        
        try:
            # æ‰§è¡Œå„ç§åˆ†æ
            results = {
                'all_positive': self.analyzer._find_all_positive(),
                'majority_positive': self.analyzer._find_majority_positive(),
                'high_confidence': self.analyzer._find_high_confidence(),
                'high_probability': self.analyzer._find_high_probability(),
                'custom_consensus': self.analyzer._find_custom_consensus()
            }
            
            # åˆ›å»ºæ—¶é—´æˆ³ç›®å½•
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            export_dir = os.path.join(directory, f"basic_results_{timestamp}")
            os.makedirs(export_dir, exist_ok=True)
            
            exported_files = []
            
            # ä¿å­˜å„ç±»ç­›é€‰ç»“æœï¼ˆåŸºç¡€ç‰ˆ - åªæœ‰å¹³å‡æ•°æ®ï¼‰
            for result_type, compounds in results.items():
                if compounds:
                    df_data = []
                    for compound in compounds:
                        row = {
                            'protein_id': compound['protein_id'],
                            'compound_id': compound['compound_id'],
                            'total_models': compound['total_models'],
                            'positive_predictions': compound['positive_predictions'],
                            'negative_predictions': compound['negative_predictions'],
                            'positive_ratio': f"{compound['positive_ratio']:.4f}",
                            'avg_probability_0': f"{1 - compound['avg_probability_1']:.4f}",
                            'avg_probability_1': f"{compound['avg_probability_1']:.4f}",
                            'avg_confidence': f"{compound['avg_confidence']:.4f}"
                        }
                        df_data.append(row)
                    
                    df = pd.DataFrame(df_data)
                    output_file = os.path.join(export_dir, f"{result_type}_basic.csv")
                    df.to_csv(output_file, index=False, encoding='utf-8-sig')
                    exported_files.append(output_file)
            
            self._save_export_parameters(export_dir, "basic")
            
            # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
            files_list = '\n'.join([os.path.basename(f) for f in exported_files])
            messagebox.showinfo("å¯¼å‡ºæˆåŠŸ", 
                              f"åŸºç¡€ç­›é€‰ç»“æœå·²å¯¼å‡ºåˆ°:\n{export_dir}\n\nå¯¼å‡ºæ–‡ä»¶:\n{files_list}")
            
            self.status_var.set("åŸºç¡€ç»“æœå¯¼å‡ºå®Œæˆ")
            
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {e}")
            self.status_var.set("å¯¼å‡ºå¤±è´¥")
    
    def export_filtered_results_detailed(self):
        """å¯¼å‡ºè¯¦ç»†ç­›é€‰ç»“æœï¼ˆåŒ…å«æ¯ä¸ªæ¨¡å‹çš„é¢„æµ‹æ•°æ®ï¼‰"""
        if not self.check_analyzer():
            return
        
        # é€‰æ‹©ä¿å­˜ç›®å½•
        directory = filedialog.askdirectory(title="é€‰æ‹©å¯¼å‡ºç›®å½• - è¯¦ç»†ç»“æœ")
        if not directory:
            return
        
        self.status_var.set("æ­£åœ¨å¯¼å‡ºè¯¦ç»†ç­›é€‰ç»“æœ...")
        
        try:
            # æ‰§è¡Œå„ç§åˆ†æ
            results = {
                'all_positive': self.analyzer._find_all_positive(),
                'majority_positive': self.analyzer._find_majority_positive(),
                'high_confidence': self.analyzer._find_high_confidence(),
                'high_probability': self.analyzer._find_high_probability(),
                'custom_consensus': self.analyzer._find_custom_consensus()
            }
            
            # åˆ›å»ºæ—¶é—´æˆ³ç›®å½•
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            export_dir = os.path.join(directory, f"detailed_results_{timestamp}")
            os.makedirs(export_dir, exist_ok=True)
            
            exported_files = []
            
            # ä¿å­˜å„ç±»ç­›é€‰ç»“æœï¼ˆè¯¦ç»†ç‰ˆ - åŒ…å«æ¯ä¸ªæ¨¡å‹çš„æ•°æ®ï¼‰
            for result_type, compounds in results.items():
                if compounds:
                    # åˆ›å»ºåŸºç¡€æ‘˜è¦æ–‡ä»¶
                    summary_data = []
                    detailed_data = []
                    
                    for compound in compounds:
                        # åŸºç¡€æ‘˜è¦è¡Œ
                        summary_row = {
                            'protein_id': compound['protein_id'],
                            'compound_id': compound['compound_id'],
                            'total_models': compound['total_models'],
                            'positive_predictions': compound['positive_predictions'],
                            'negative_predictions': compound['negative_predictions'],
                            'positive_ratio': f"{compound['positive_ratio']:.4f}",
                            'avg_probability_0': f"{1 - compound['avg_probability_1']:.4f}",
                            'avg_probability_1': f"{compound['avg_probability_1']:.4f}",
                            'avg_confidence': f"{compound['avg_confidence']:.4f}"
                        }
                        summary_data.append(summary_row)
                        
                        # è¯¦ç»†çš„æ¯ä¸ªæ¨¡å‹æ•°æ®
                        for pred in compound['predictions']:
                            detailed_row = {
                                'protein_id': compound['protein_id'],
                                'compound_id': compound['compound_id'],
                                'model_type': pred['model_type'],
                                'model_name': pred['model_name'],
                                'prediction': pred['prediction'],
                                'prediction_label': 'ç›¸äº’ä½œç”¨' if pred['prediction'] == 1 else 'æ— ç›¸äº’ä½œç”¨',
                                'probability_0': f"{pred['probability_0']:.4f}",
                                'probability_1': f"{pred['probability_1']:.4f}",
                                'confidence': f"{pred['confidence']:.4f}",
                                # æ·»åŠ å¹³å‡ä¿¡æ¯ä½œä¸ºå‚è€ƒ
                                'avg_probability_1': f"{compound['avg_probability_1']:.4f}",
                                'avg_confidence': f"{compound['avg_confidence']:.4f}",
                                'positive_ratio': f"{compound['positive_ratio']:.4f}"
                            }
                            detailed_data.append(detailed_row)
                    
                    # ä¿å­˜æ‘˜è¦æ–‡ä»¶
                    summary_df = pd.DataFrame(summary_data)
                    summary_file = os.path.join(export_dir, f"{result_type}_summary.csv")
                    summary_df.to_csv(summary_file, index=False, encoding='utf-8-sig')
                    exported_files.append(summary_file)
                    
                    # ä¿å­˜è¯¦ç»†æ–‡ä»¶
                    detailed_df = pd.DataFrame(detailed_data)
                    detailed_file = os.path.join(export_dir, f"{result_type}_detailed.csv")
                    detailed_df.to_csv(detailed_file, index=False, encoding='utf-8-sig')
                    exported_files.append(detailed_file)
            
            self._save_export_parameters(export_dir, "detailed")
            
            # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
            files_list = '\n'.join([os.path.basename(f) for f in exported_files])
            messagebox.showinfo("å¯¼å‡ºæˆåŠŸ", 
                              f"è¯¦ç»†ç­›é€‰ç»“æœå·²å¯¼å‡ºåˆ°:\n{export_dir}\n\nå¯¼å‡ºæ–‡ä»¶:\n{files_list}\n\n"
                              f"æ¯ä¸ªç­›é€‰ç±»å‹åŒ…å«ä¸¤ä¸ªæ–‡ä»¶:\n"
                              f"â€¢ *_summary.csv: åŸºç¡€æ‘˜è¦æ•°æ®\n"
                              f"â€¢ *_detailed.csv: æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†é¢„æµ‹")
            
            self.status_var.set("è¯¦ç»†ç»“æœå¯¼å‡ºå®Œæˆ")
            
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {e}")
            self.status_var.set("å¯¼å‡ºå¤±è´¥")
    
    def export_all_model_data(self):
        """å¯¼å‡ºæ‰€æœ‰æ¨¡å‹çš„å®Œæ•´åŸå§‹æ•°æ®"""
        if not self.check_analyzer():
            return
        
        # é€‰æ‹©ä¿å­˜ç›®å½•
        directory = filedialog.askdirectory(title="é€‰æ‹©å¯¼å‡ºç›®å½• - å®Œæ•´æ¨¡å‹æ•°æ®")
        if not directory:
            return
        
        self.status_var.set("æ­£åœ¨å¯¼å‡ºæ‰€æœ‰æ¨¡å‹æ•°æ®...")
        
        try:
            # åˆ›å»ºæ—¶é—´æˆ³ç›®å½•
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            export_dir = os.path.join(directory, f"all_model_data_{timestamp}")
            os.makedirs(export_dir, exist_ok=True)
            
            exported_files = []
            
            # å¯¼å‡ºæ¯ä¸ªæ¨¡å‹ç±»å‹çš„æ•°æ®
            for model_type, models in self.analyzer.raw_predictions.items():
                model_type_dir = os.path.join(export_dir, model_type.replace('/', '_'))
                os.makedirs(model_type_dir, exist_ok=True)
                
                for model_name, df in models.items():
                    output_file = os.path.join(model_type_dir, f"{model_name}_complete.csv")
                    df.to_csv(output_file, index=False, encoding='utf-8-sig')
                    exported_files.append(output_file)
            
            # åˆ›å»ºåˆå¹¶çš„å…¨é‡æ•°æ®æ–‡ä»¶
            all_predictions = []
            for model_type, models in self.analyzer.raw_predictions.items():
                for model_name, df in models.items():
                    df_copy = df.copy()
                    df_copy['model_type'] = model_type
                    df_copy['model_name'] = model_name
                    all_predictions.append(df_copy)
            
            if all_predictions:
                combined_df = pd.concat(all_predictions, ignore_index=True)
                combined_file = os.path.join(export_dir, "all_predictions_combined.csv")
                combined_df.to_csv(combined_file, index=False, encoding='utf-8-sig')
                exported_files.append(combined_file)
            
            self._save_export_parameters(export_dir, "complete")
            
            # åˆ›å»ºæ•°æ®è¯´æ˜æ–‡ä»¶
            readme_file = os.path.join(export_dir, "README.txt")
            with open(readme_file, 'w', encoding='utf-8') as f:
                f.write("å®Œæ•´æ¨¡å‹æ•°æ®å¯¼å‡ºè¯´æ˜\n")
                f.write("=" * 40 + "\n")
                f.write(f"å¯¼å‡ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ•°æ®æ¥æº: {self.analyzer.result_dir}\n\n")
                
                f.write("æ–‡ä»¶ç»“æ„:\n")
                f.write("- å„æ¨¡å‹ç±»å‹ç›®å½•: åŒ…å«è¯¥ç±»å‹ä¸‹æ‰€æœ‰æ¨¡å‹çš„å®Œæ•´é¢„æµ‹æ•°æ®\n")
                f.write("- all_predictions_combined.csv: æ‰€æœ‰æ¨¡å‹é¢„æµ‹æ•°æ®çš„åˆå¹¶æ–‡ä»¶\n")
                f.write("- export_parameters.json: å¯¼å‡ºæ—¶çš„å‚æ•°è®¾ç½®\n\n")
                
                f.write("æ•°æ®åˆ—è¯´æ˜:\n")
                f.write("- protein_id: è›‹ç™½è´¨ID\n")
                f.write("- compound_id: åŒ–åˆç‰©ID\n")
                f.write("- prediction: é¢„æµ‹ç»“æœ (0=æ— ç›¸äº’ä½œç”¨, 1=ç›¸äº’ä½œç”¨)\n")
                f.write("- probability_0: é¢„æµ‹ä¸ºæ— ç›¸äº’ä½œç”¨çš„æ¦‚ç‡\n")
                f.write("- probability_1: é¢„æµ‹ä¸ºç›¸äº’ä½œç”¨çš„æ¦‚ç‡\n")
                f.write("- confidence: é¢„æµ‹ç½®ä¿¡åº¦\n")
                f.write("- model_type: æ¨¡å‹ç±»å‹\n")
                f.write("- model_name: æ¨¡å‹åç§°\n")
            
            # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
            model_count = sum(len(models) for models in self.analyzer.raw_predictions.values())
            total_predictions = sum(len(df) for models in self.analyzer.raw_predictions.values() 
                                  for df in models.values())
            
            messagebox.showinfo("å¯¼å‡ºæˆåŠŸ", 
                              f"å®Œæ•´æ¨¡å‹æ•°æ®å·²å¯¼å‡ºåˆ°:\n{export_dir}\n\n"
                              f"å¯¼å‡ºç»Ÿè®¡:\n"
                              f"â€¢ æ¨¡å‹æ•°é‡: {model_count}\n"
                              f"â€¢ é¢„æµ‹è®°å½•æ€»æ•°: {total_predictions:,}\n"
                              f"â€¢ æ–‡ä»¶æ•°é‡: {len(exported_files)}\n\n"
                              f"åŒ…å«:\n"
                              f"â€¢ å„æ¨¡å‹ç±»å‹çš„å•ç‹¬æ•°æ®æ–‡ä»¶\n"
                              f"â€¢ åˆå¹¶çš„å®Œæ•´æ•°æ®æ–‡ä»¶\n"
                              f"â€¢ æ•°æ®è¯´æ˜æ–‡ä»¶")
            
            self.status_var.set("å®Œæ•´æ•°æ®å¯¼å‡ºå®Œæˆ")
            
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {e}")
            self.status_var.set("å¯¼å‡ºå¤±è´¥")
    
    def _save_export_parameters(self, export_dir, export_type):
        """ä¿å­˜å¯¼å‡ºå‚æ•°"""
        params = {
            'export_type': export_type,
            'min_consensus_models': self.analyzer.current_min_consensus,
            'probability_threshold': self.analyzer.current_prob_threshold,
            'confidence_threshold': self.analyzer.current_conf_threshold,
            'export_time': datetime.now().isoformat(),
            'total_compounds_analyzed': len(self.analyzer.compound_stats),
            'total_models': len(self.analyzer.available_models),
            'data_source': self.analyzer.result_dir,
            'version': '2.1.0'
        }
        
        params_file = os.path.join(export_dir, "export_parameters.json")
        with open(params_file, 'w', encoding='utf-8') as f:
            json.dump(params, f, indent=2, ensure_ascii=False)
    
    # ===============================
    # å…¶ä»–åŠŸèƒ½å‡½æ•°ï¼ˆç»§æ‰¿åŸæœ‰åŠŸèƒ½ï¼‰
    # ===============================
    
    def show_basic_stats(self):
        """æ˜¾ç¤ºåŸºç¡€ç»Ÿè®¡"""
        if not self.check_analyzer():
            return
        
        self.status_var.set("ç”ŸæˆåŸºç¡€ç»Ÿè®¡å›¾è¡¨...")
        
        # æ¸…é™¤ä¹‹å‰çš„å›¾è¡¨
        self.figure.clear()
        
        # åˆ›å»º2x2å­å›¾
        fig = self.figure
        
        # è·å–æ•°æ®
        all_probs = [stats['avg_probability_1'] for stats in self.analyzer.compound_stats.values()]
        all_confs = [stats['avg_confidence'] for stats in self.analyzer.compound_stats.values()]
        all_ratios = [stats['positive_ratio'] for stats in self.analyzer.compound_stats.values()]
        
        # å­å›¾1: æ¦‚ç‡åˆ†å¸ƒç›´æ–¹å›¾
        ax1 = fig.add_subplot(221)
        ax1.hist(all_probs, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        ax1.axvline(self.analyzer.current_prob_threshold, color='red', linestyle='--',
                    label=f'å½“å‰é˜ˆå€¼ ({self.analyzer.current_prob_threshold:.3f})')
        ax1.set_title('æ¦‚ç‡åˆ†å¸ƒ', fontsize=12)
        ax1.set_xlabel('å¹³å‡æ­£ä¾‹æ¦‚ç‡')
        ax1.set_ylabel('åŒ–åˆç‰©æ•°é‡')
        ax1.legend()
        ax1.grid(True, alpha=0.3)

        # å­å›¾2: ç½®ä¿¡åº¦åˆ†å¸ƒç›´æ–¹å›¾
        ax2 = fig.add_subplot(222)
        ax2.hist(all_confs, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
        ax2.axvline(self.analyzer.current_conf_threshold, color='red', linestyle='--',
                    label=f'å½“å‰é˜ˆå€¼ ({self.analyzer.current_conf_threshold:.3f})')
        ax2.set_title('ç½®ä¿¡åº¦åˆ†å¸ƒ', fontsize=12)
        ax2.set_xlabel('å¹³å‡ç½®ä¿¡åº¦')
        ax2.set_ylabel('åŒ–åˆç‰©æ•°é‡')
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        # å­å›¾3: æ­£ä¾‹æ¯”ä¾‹åˆ†å¸ƒ
        ax3 = fig.add_subplot(223)
        ax3.hist(all_ratios, bins=20, alpha=0.7, color='lightcoral', edgecolor='black')
        ax3.set_title('æ­£ä¾‹æ¯”ä¾‹åˆ†å¸ƒ', fontsize=12)
        ax3.set_xlabel('æ­£ä¾‹é¢„æµ‹æ¯”ä¾‹')
        ax3.set_ylabel('åŒ–åˆç‰©æ•°é‡')
        ax3.grid(True, alpha=0.3)

        # å­å›¾4: æ¦‚ç‡vsç½®ä¿¡åº¦æ•£ç‚¹å›¾
        ax4 = fig.add_subplot(224)
        scatter = ax4.scatter(all_probs, all_confs, c=all_ratios, cmap='RdYlBu_r',
                              alpha=0.6, s=30)
        ax4.axhline(self.analyzer.current_conf_threshold, color='red', linestyle='--', alpha=0.7)
        ax4.axvline(self.analyzer.current_prob_threshold, color='red', linestyle='--', alpha=0.7)
        ax4.set_title('æ¦‚ç‡ vs ç½®ä¿¡åº¦', fontsize=12)
        ax4.set_xlabel('å¹³å‡æ­£ä¾‹æ¦‚ç‡')
        ax4.set_ylabel('å¹³å‡ç½®ä¿¡åº¦')
        ax4.grid(True, alpha=0.3)

        # æ·»åŠ é¢œè‰²æ¡
        cbar = fig.colorbar(scatter, ax=ax4)
        cbar.set_label('æ­£ä¾‹æ¯”ä¾‹')

        fig.tight_layout()
        self.canvas.draw()

        # æ›´æ–°è¯¦ç»†ä¿¡æ¯
        self.update_basic_stats_info()

        self.status_var.set("åŸºç¡€ç»Ÿè®¡å›¾è¡¨å·²ç”Ÿæˆ")

    def show_consensus_analysis(self):
        """æ˜¾ç¤ºå…±è¯†åˆ†æ"""
        if not self.check_analyzer():
            return

        self.status_var.set("è¿›è¡Œå…±è¯†åˆ†æ...")

        # æ‰§è¡Œå…±è¯†åˆ†æ
        all_positive = self.analyzer._find_all_positive()
        majority_positive = self.analyzer._find_majority_positive()
        high_confidence = self.analyzer._find_high_confidence()
        high_probability = self.analyzer._find_high_probability()
        custom_consensus = self.analyzer._find_custom_consensus()

        # æ¸…é™¤ä¹‹å‰çš„å›¾è¡¨
        self.figure.clear()
        ax = self.figure.add_subplot(111)

        # å‡†å¤‡æ•°æ®
        categories = ['æ‰€æœ‰æ¨¡å‹\nä¸€è‡´', 'å¤§å¤šæ•°\nåŒæ„', 'é«˜ç½®ä¿¡åº¦', 'é«˜æ¦‚ç‡', 'ç»¼åˆ\nç­›é€‰']
        counts = [len(all_positive), len(majority_positive), len(high_confidence),
                  len(high_probability), len(custom_consensus)]
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']

        # åˆ›å»ºæŸ±çŠ¶å›¾
        bars = ax.bar(categories, counts, color=colors, alpha=0.8, edgecolor='black')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, count in zip(bars, counts):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width() / 2., height + max(counts) * 0.01,
                    f'{count}', ha='center', va='bottom', fontweight='bold')

        ax.set_title('ä¸åŒç­›é€‰ç­–ç•¥çš„åŒ–åˆç‰©æ•°é‡', fontsize=14, fontweight='bold')
        ax.set_ylabel('åŒ–åˆç‰©æ•°é‡')
        ax.grid(True, alpha=0.3, axis='y')

        self.figure.tight_layout()
        self.canvas.draw()

        # æ›´æ–°è¡¨æ ¼æ•°æ®
        self.update_consensus_table(all_positive, majority_positive, high_confidence,
                                    high_probability, custom_consensus)

        # æ›´æ–°è¯¦ç»†ä¿¡æ¯
        self.update_consensus_info(all_positive, majority_positive, high_confidence,
                                   high_probability, custom_consensus)

        self.status_var.set("å…±è¯†åˆ†æå®Œæˆ")

    def show_threshold_sensitivity(self):
        """æ˜¾ç¤ºé˜ˆå€¼æ•æ„Ÿæ€§åˆ†æ"""
        if not self.check_analyzer():
            return

        self.status_var.set("åˆ†æé˜ˆå€¼æ•æ„Ÿæ€§...")

        # æ¸…é™¤ä¹‹å‰çš„å›¾è¡¨
        self.figure.clear()

        # åˆ›å»ºå­å›¾
        fig = self.figure
        ax1 = fig.add_subplot(121)
        ax2 = fig.add_subplot(122)

        # æ¦‚ç‡é˜ˆå€¼æ•æ„Ÿæ€§
        prob_thresholds = np.arange(0.5, 1.0, 0.05)
        prob_counts = []

        for threshold in prob_thresholds:
            count = sum(1 for stats in self.analyzer.compound_stats.values()
                        if stats['avg_probability_1'] >= threshold and
                        stats['positive_predictions'] >= self.analyzer.current_min_consensus)
            prob_counts.append(count)

        ax1.plot(prob_thresholds, prob_counts, 'b-o', linewidth=2, markersize=6)
        ax1.axvline(self.analyzer.current_prob_threshold, color='red', linestyle='--',
                    label=f'å½“å‰é˜ˆå€¼ ({self.analyzer.current_prob_threshold:.2f})')
        ax1.set_xlabel('æ¦‚ç‡é˜ˆå€¼')
        ax1.set_ylabel('ç¬¦åˆæ¡ä»¶çš„åŒ–åˆç‰©æ•°é‡')
        ax1.set_title('æ¦‚ç‡é˜ˆå€¼æ•æ„Ÿæ€§', fontsize=12)
        ax1.grid(True, alpha=0.3)
        ax1.legend()

        # ç½®ä¿¡åº¦é˜ˆå€¼æ•æ„Ÿæ€§
        conf_thresholds = np.arange(0.5, 1.0, 0.05)
        conf_counts = []

        for threshold in conf_thresholds:
            count = sum(1 for stats in self.analyzer.compound_stats.values()
                        if stats['avg_confidence'] >= threshold and
                        stats['positive_predictions'] >= self.analyzer.current_min_consensus)
            conf_counts.append(count)

        ax2.plot(conf_thresholds, conf_counts, 'g-o', linewidth=2, markersize=6)
        ax2.axvline(self.analyzer.current_conf_threshold, color='red', linestyle='--',
                    label=f'å½“å‰é˜ˆå€¼ ({self.analyzer.current_conf_threshold:.2f})')
        ax2.set_xlabel('ç½®ä¿¡åº¦é˜ˆå€¼')
        ax2.set_ylabel('ç¬¦åˆæ¡ä»¶çš„åŒ–åˆç‰©æ•°é‡')
        ax2.set_title('ç½®ä¿¡åº¦é˜ˆå€¼æ•æ„Ÿæ€§', fontsize=12)
        ax2.grid(True, alpha=0.3)
        ax2.legend()

        fig.tight_layout()
        self.canvas.draw()

        self.status_var.set("é˜ˆå€¼æ•æ„Ÿæ€§åˆ†æå®Œæˆ")

    def show_model_consistency(self):
        """æ˜¾ç¤ºæ¨¡å‹æ­£ä¾‹é¢„æµ‹ä¸€è‡´æ€§çƒ­å›¾"""
        if not self.check_analyzer():
            return

        self.status_var.set("åˆ†ææ¨¡å‹æ­£ä¾‹é¢„æµ‹ä¸€è‡´æ€§...")

        # æ¸…é™¤ä¹‹å‰çš„å›¾è¡¨
        self.figure.clear()
        ax = self.figure.add_subplot(111)

        # è·å–æ¨¡å‹åç§°
        model_names = []
        for model_type, models in self.analyzer.raw_predictions.items():
            for model_name in models.keys():
                type_short = model_type.split('_')[-1][:3] if '_' in model_type else model_type[:3]
                model_short = model_name[:3]
                short_name = f"{type_short}_{model_short}"
                model_names.append(short_name)

        n_models = len(model_names)

        if n_models < 2:
            ax.text(0.5, 0.5, 'éœ€è¦è‡³å°‘2ä¸ªæ¨¡å‹æ‰èƒ½åˆ†æä¸€è‡´æ€§',
                    ha='center', va='center', transform=ax.transAxes, fontsize=14)
            self.canvas.draw()
            return

        # è®¡ç®—æ­£ä¾‹é¢„æµ‹ä¸€è‡´æ€§
        consistency_matrix = self._calculate_model_consistency(model_names)

        # åˆ›å»ºçƒ­å›¾
        im = ax.imshow(consistency_matrix, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=1)

        # è®¾ç½®æ ‡ç­¾
        ax.set_xticks(range(n_models))
        ax.set_yticks(range(n_models))
        ax.set_xticklabels(model_names, rotation=45, ha='right')
        ax.set_yticklabels(model_names)

        # æ·»åŠ æ•°å€¼æ ‡æ³¨
        for i in range(n_models):
            for j in range(n_models):
                color = 'white' if consistency_matrix[i, j] < 0.5 else 'black'
                text = ax.text(j, i, f'{consistency_matrix[i, j]:.2f}',
                               ha="center", va="center", color=color, fontsize=8)

        ax.set_title('æ¨¡å‹æ­£ä¾‹é¢„æµ‹ä¸€è‡´æ€§çƒ­å›¾ (Jaccardç›¸ä¼¼åº¦)', fontsize=14, fontweight='bold')

        # æ·»åŠ é¢œè‰²æ¡
        cbar = self.figure.colorbar(im, ax=ax)
        cbar.set_label('Jaccardç›¸ä¼¼åº¦ (0=æ— é‡å , 1=å®Œå…¨é‡å )')

        self.figure.tight_layout()
        self.canvas.draw()

        self.status_var.set("æ­£ä¾‹é¢„æµ‹ä¸€è‡´æ€§åˆ†æå®Œæˆ")

    def _calculate_model_consistency(self, model_names):
        """è®¡ç®—æ¨¡å‹æ­£ä¾‹é¢„æµ‹ä¸€è‡´æ€§ï¼ˆä½¿ç”¨Jaccardç›¸ä¼¼åº¦ï¼‰"""
        n_models = len(model_names)
        consistency_matrix = np.zeros((n_models, n_models))

        print("å¼€å§‹è®¡ç®—æ¨¡å‹æ­£ä¾‹é¢„æµ‹ä¸€è‡´æ€§...")

        # é‡æ–°ç”Ÿæˆæ­£ç¡®çš„æ˜ å°„å…³ç³»
        full_model_mapping = {}
        for model_type, models in self.analyzer.raw_predictions.items():
            for model_name in models.keys():
                type_short = model_type.split('_')[-1][:3] if '_' in model_type else model_type[:3]
                model_short = model_name[:3]
                short_name = f"{type_short}_{model_short}"
                full_model_mapping[short_name] = (model_type, model_name)

        # è·å–æ‰€æœ‰æ¨¡å‹çš„æ­£ä¾‹é¢„æµ‹
        model_positive_predictions = {}

        for short_name in model_names:
            if short_name in full_model_mapping:
                model_type, model_name = full_model_mapping[short_name]

                if model_type in self.analyzer.raw_predictions and model_name in self.analyzer.raw_predictions[
                    model_type]:
                    df = self.analyzer.raw_predictions[model_type][model_name]

                    # åªä¿å­˜æ­£ä¾‹é¢„æµ‹
                    positive_predictions = set()
                    total_predictions = 0

                    for _, row in df.iterrows():
                        key = f"{row['protein_id']}_{row['compound_id']}"
                        prediction = int(row['prediction'])
                        total_predictions += 1

                        # å¦‚æœæ˜¯æ­£ä¾‹ï¼ŒåŠ å…¥æ­£ä¾‹é›†åˆ
                        if prediction == 1:
                            positive_predictions.add(key)

                    model_positive_predictions[short_name] = positive_predictions

                    positive_rate = len(positive_predictions) / total_predictions * 100
                    print(
                        f"âœ“ æ¨¡å‹ {short_name}: æ€»é¢„æµ‹={total_predictions}, æ­£ä¾‹={len(positive_predictions)} ({positive_rate:.1f}%)")

        print(f"æˆåŠŸåŠ è½½ {len(model_positive_predictions)} ä¸ªæ¨¡å‹çš„æ­£ä¾‹é¢„æµ‹æ•°æ®")

        # è®¡ç®—æ­£ä¾‹é¢„æµ‹çš„Jaccardç›¸ä¼¼åº¦
        for i, model1 in enumerate(model_names):
            for j, model2 in enumerate(model_names):
                if i == j:
                    consistency_matrix[i][j] = 1.0
                elif model1 in model_positive_predictions and model2 in model_positive_predictions:
                    pos1 = model_positive_predictions[model1]
                    pos2 = model_positive_predictions[model2]

                    # è®¡ç®—Jaccardç›¸ä¼¼åº¦ï¼šäº¤é›† / å¹¶é›†
                    intersection = pos1 & pos2
                    union = pos1 | pos2

                    if len(union) > 0:
                        jaccard_similarity = len(intersection) / len(union)
                        consistency_matrix[i][j] = jaccard_similarity

                        # è®¡ç®—å…¶ä»–æœ‰ç”¨æŒ‡æ ‡
                        if len(pos1) > 0:
                            recall_1_to_2 = len(intersection) / len(pos1)
                        else:
                            recall_1_to_2 = 0

                        if len(pos2) > 0:
                            recall_2_to_1 = len(intersection) / len(pos2)
                        else:
                            recall_2_to_1 = 0

                        print(f"  {model1} vs {model2}:")
                        print(f"    æ¨¡å‹1æ­£ä¾‹: {len(pos1)}, æ¨¡å‹2æ­£ä¾‹: {len(pos2)}")
                        print(f"    å…±åŒæ­£ä¾‹: {len(intersection)}, æ€»æ­£ä¾‹: {len(union)}")
                        print(f"    Jaccardç›¸ä¼¼åº¦: {jaccard_similarity:.3f}")
                        print(f"    æ¨¡å‹1â†’æ¨¡å‹2è¦†ç›–ç‡: {recall_1_to_2:.3f}")
                        print(f"    æ¨¡å‹2â†’æ¨¡å‹1è¦†ç›–ç‡: {recall_2_to_1:.3f}")
                    else:
                        consistency_matrix[i][j] = 0.0
                        print(f"  {model1} vs {model2}: éƒ½æ— æ­£ä¾‹é¢„æµ‹")
                else:
                    consistency_matrix[i][j] = 0.0
                    print(f"  {model1} vs {model2}: æ•°æ®ç¼ºå¤±")

        # è¾“å‡ºç»Ÿè®¡æ‘˜è¦
        off_diagonal = [consistency_matrix[i][j] for i in range(n_models) for j in range(n_models) if i != j]

        if off_diagonal and any(x > 0 for x in off_diagonal):
            print(f"\nğŸ“Š æ­£ä¾‹é¢„æµ‹Jaccardç›¸ä¼¼åº¦ç»Ÿè®¡:")
            print(f"  å¹³å‡ç›¸ä¼¼åº¦: {np.mean(off_diagonal):.3f}")
            print(f"  æœ€å°ç›¸ä¼¼åº¦: {np.min(off_diagonal):.3f}")
            print(f"  æœ€å¤§ç›¸ä¼¼åº¦: {np.max(off_diagonal):.3f}")

            # æ‰¾å‡ºæœ€ç›¸ä¼¼å’Œæœ€ä¸ç›¸ä¼¼çš„æ¨¡å‹å¯¹
            max_idx = np.unravel_index(np.argmax(consistency_matrix - np.eye(n_models)), consistency_matrix.shape)
            min_idx = np.unravel_index(np.argmin(consistency_matrix + np.eye(n_models) * 2), consistency_matrix.shape)

            print(f"\nğŸ¯ æ­£ä¾‹é¢„æµ‹åˆ†æ:")
            print(
                f"  æœ€ç›¸ä¼¼æ¨¡å‹å¯¹: {model_names[max_idx[0]]} vs {model_names[max_idx[1]]} (ç›¸ä¼¼åº¦: {consistency_matrix[max_idx]:.3f})")
            print(
                f"  æœ€ä¸ç›¸ä¼¼æ¨¡å‹å¯¹: {model_names[min_idx[0]]} vs {model_names[min_idx[1]]} (ç›¸ä¼¼åº¦: {consistency_matrix[min_idx]:.3f})")

            # æ¨¡å‹äº’è¡¥æ€§åˆ†æ
            print(f"\nğŸ’¡ æ¨¡å‹äº’è¡¥æ€§å»ºè®®:")
            for i, model1 in enumerate(model_names):
                other_similarities = [consistency_matrix[i][j] for j in range(n_models) if i != j]
                avg_similarity = np.mean(other_similarities)
                if avg_similarity < 0.5:
                    print(f"  {model1}: ä¸å…¶ä»–æ¨¡å‹å·®å¼‚è¾ƒå¤§ï¼Œå»ºè®®ä¿ç•™ç”¨äºé›†æˆ")
                elif avg_similarity > 0.8:
                    print(f"  {model1}: ä¸å…¶ä»–æ¨¡å‹é«˜åº¦ç›¸ä¼¼ï¼Œå¯è€ƒè™‘æ›¿æ¢")
                else:
                    print(f"  {model1}: ä¸å…¶ä»–æ¨¡å‹ä¸­ç­‰ç›¸ä¼¼ï¼Œé€‚åˆé›†æˆä½¿ç”¨")
        else:
            print(f"\nâŒ æ— æ³•è®¡ç®—æ­£ä¾‹é¢„æµ‹ç›¸ä¼¼åº¦")

        return consistency_matrix

    def show_distribution_plots(self):
        """æ˜¾ç¤ºåˆ†å¸ƒå¯è§†åŒ–"""
        if not self.check_analyzer():
            return

        self.status_var.set("ç”Ÿæˆåˆ†å¸ƒå›¾...")

        # æ¸…é™¤ä¹‹å‰çš„å›¾è¡¨
        self.figure.clear()

        # è·å–æ•°æ®
        all_probs = [stats['avg_probability_1'] for stats in self.analyzer.compound_stats.values()]
        all_confs = [stats['avg_confidence'] for stats in self.analyzer.compound_stats.values()]
        all_ratios = [stats['positive_ratio'] for stats in self.analyzer.compound_stats.values()]

        # åˆ›å»ºå­å›¾
        fig = self.figure

        # å­å›¾1: æ¦‚ç‡åˆ†å¸ƒï¼ˆå¯†åº¦å›¾ï¼‰
        ax1 = fig.add_subplot(221)
        ax1.hist(all_probs, bins=30, density=True, alpha=0.7, color='skyblue')
        ax1.axvline(self.analyzer.current_prob_threshold, color='red', linestyle='--',
                    label=f'é˜ˆå€¼ ({self.analyzer.current_prob_threshold:.2f})')
        ax1.set_title('æ¦‚ç‡å¯†åº¦åˆ†å¸ƒ')
        ax1.set_xlabel('å¹³å‡æ­£ä¾‹æ¦‚ç‡')
        ax1.set_ylabel('å¯†åº¦')
        ax1.legend()
        ax1.grid(True, alpha=0.3)

        # å­å›¾2: ç½®ä¿¡åº¦åˆ†å¸ƒï¼ˆå¯†åº¦å›¾ï¼‰
        ax2 = fig.add_subplot(222)
        ax2.hist(all_confs, bins=30, density=True, alpha=0.7, color='lightgreen')
        ax2.axvline(self.analyzer.current_conf_threshold, color='red', linestyle='--',
                    label=f'é˜ˆå€¼ ({self.analyzer.current_conf_threshold:.2f})')
        ax2.set_title('ç½®ä¿¡åº¦å¯†åº¦åˆ†å¸ƒ')
        ax2.set_xlabel('å¹³å‡ç½®ä¿¡åº¦')
        ax2.set_ylabel('å¯†åº¦')
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        # å­å›¾3: æ­£ä¾‹æ¯”ä¾‹é¥¼å›¾
        ax3 = fig.add_subplot(223)
        ratio_bins = [0, 0.25, 0.5, 0.75, 1.0]
        ratio_labels = ['0-25%', '25-50%', '50-75%', '75-100%']
        ratio_counts = []

        for i in range(len(ratio_bins) - 1):
            count = sum(1 for r in all_ratios if ratio_bins[i] <= r < ratio_bins[i + 1])
            ratio_counts.append(count)

        # æ·»åŠ 100%çš„åŒ–åˆç‰©
        ratio_counts[-1] += sum(1 for r in all_ratios if r == 1.0)

        colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFD700']
        wedges, texts, autotexts = ax3.pie(ratio_counts, labels=ratio_labels, colors=colors,
                                           autopct='%1.1f%%', startangle=90)
        ax3.set_title('æ­£ä¾‹æ¯”ä¾‹åˆ†å¸ƒ')

        # å­å›¾4: ç®±çº¿å›¾
        ax4 = fig.add_subplot(224)
        data_to_plot = [all_probs, all_confs, all_ratios]
        box_plot = ax4.boxplot(data_to_plot, labels=['æ¦‚ç‡', 'ç½®ä¿¡åº¦', 'æ­£ä¾‹æ¯”ä¾‹'])
        ax4.set_title('æ•°æ®åˆ†å¸ƒç®±çº¿å›¾')
        ax4.set_ylabel('æ•°å€¼')
        ax4.grid(True, alpha=0.3)

        fig.tight_layout()
        self.canvas.draw()

        self.status_var.set("åˆ†å¸ƒå›¾ç”Ÿæˆå®Œæˆ")

    def show_funnel_analysis(self):
        """æ˜¾ç¤ºç­›é€‰æ¼æ–—åˆ†æ"""
        if not self.check_analyzer():
            return

        self.status_var.set("ç”Ÿæˆç­›é€‰æ¼æ–—...")

        # è®¡ç®—ä¸åŒç­›é€‰æ¡ä»¶ä¸‹çš„åŒ–åˆç‰©æ•°é‡
        stages = [
            ('æ€»åŒ–åˆç‰©', len(self.analyzer.compound_stats)),
            ('è‡³å°‘1ä¸ªæ­£ä¾‹', sum(1 for s in self.analyzer.compound_stats.values() if s['positive_predictions'] > 0)),
            ('è‡³å°‘2ä¸ªæ­£ä¾‹', sum(1 for s in self.analyzer.compound_stats.values() if s['positive_predictions'] >= 2)),
            ('å¤§å¤šæ•°æ­£ä¾‹', len(self.analyzer._find_majority_positive())),
            ('é«˜æ¦‚ç‡', len(self.analyzer._find_high_probability())),
            ('é«˜ç½®ä¿¡åº¦', len(self.analyzer._find_high_confidence())),
            ('æ‰€æœ‰æ¨¡å‹ä¸€è‡´', len(self.analyzer._find_all_positive())),
            ('ç»¼åˆç­›é€‰', len(self.analyzer._find_custom_consensus()))
        ]

        # æ¸…é™¤ä¹‹å‰çš„å›¾è¡¨
        self.figure.clear()
        ax = self.figure.add_subplot(111)

        stage_names = [s[0] for s in stages]
        counts = [s[1] for s in stages]

        # åˆ›å»ºæ°´å¹³æ¡å½¢å›¾
        y_pos = np.arange(len(stages))
        colors = plt.cm.RdYlBu_r(np.linspace(0.2, 0.8, len(stages)))

        bars = ax.barh(y_pos, counts, color=colors)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, count) in enumerate(zip(bars, counts)):
            ax.text(bar.get_width() + max(counts) * 0.01, bar.get_y() + bar.get_height() / 2,
                    f'{count:,}', ha='left', va='center', fontweight='bold')

        ax.set_yticks(y_pos)
        ax.set_yticklabels(stage_names)
        ax.set_xlabel('åŒ–åˆç‰©æ•°é‡')
        ax.set_title('åŒ–åˆç‰©ç­›é€‰æ¼æ–—å›¾', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3, axis='x')

        # åè½¬yè½´ä½¿å…¶å‘ˆç°æ¼æ–—æ•ˆæœ
        ax.invert_yaxis()

        self.figure.tight_layout()
        self.canvas.draw()

        self.status_var.set("ç­›é€‰æ¼æ–—åˆ†æå®Œæˆ")

    # ===============================
    # ä¿¡æ¯æ›´æ–°å‡½æ•°
    # ===============================

    def update_info_display(self):
        """æ›´æ–°è¯¦ç»†ä¿¡æ¯æ˜¾ç¤º"""
        if len(self.analyzer.compound_stats) == 0:
            return

        info_text = f"""
ğŸ“Š æ•°æ®æ¦‚å†µ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
åŒ–åˆç‰©æ€»æ•°: {len(self.analyzer.compound_stats):,}
æ¨¡å‹æ€»æ•°: {len(self.analyzer.available_models)}
æ•°æ®ç›®å½•: {self.analyzer.result_dir}

âš™ï¸ å½“å‰ç­›é€‰å‚æ•°
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
æœ€å°å…±è¯†æ¨¡å‹æ•°: {self.analyzer.current_min_consensus}
æ¦‚ç‡é˜ˆå€¼: {self.analyzer.current_prob_threshold:.3f}
ç½®ä¿¡åº¦é˜ˆå€¼: {self.analyzer.current_conf_threshold:.3f}

ğŸ¤– å¯ç”¨æ¨¡å‹åˆ—è¡¨
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

        for model_type, models in self.analyzer.raw_predictions.items():
            info_text += f"\n{model_type}:\n"
            for model_name in models.keys():
                info_text += f"  â€¢ {model_name}\n"

        info_text += f"""

ğŸ’¡ ä½¿ç”¨æç¤º (v2.1å¢å¼ºç‰ˆ)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ å‚æ•°è°ƒæ•´: æ”¯æŒæ»‘å—æ‹–æ‹½ + ç›´æ¥è¾“å…¥æ•°å€¼
â€¢ è¾“å…¥æ¡†æ”¯æŒå›è½¦é”®å¿«é€Ÿç¡®è®¤
â€¢ å¿«é€Ÿè®¾ç½®æŒ‰é’®å¯ä¸€é”®åº”ç”¨é¢„è®¾å‚æ•°
â€¢ å¯¼å‡ºåŠŸèƒ½åŒ…å«è¯¦ç»†çš„æ¨¡å‹é¢„æµ‹æ•°æ®
â€¢ ä½¿ç”¨"è¯¦ç»†å¯¼å‡º"è·å–æ¯ä¸ªæ¨¡å‹çš„å•ç‹¬é¢„æµ‹
"""

        self.info_text.delete(1.0, tk.END)
        self.info_text.insert(tk.END, info_text)

    def update_basic_stats_info(self):
        """æ›´æ–°åŸºç¡€ç»Ÿè®¡ä¿¡æ¯"""
        if len(self.analyzer.compound_stats) == 0:
            return

        all_probs = [stats['avg_probability_1'] for stats in self.analyzer.compound_stats.values()]
        all_confs = [stats['avg_confidence'] for stats in self.analyzer.compound_stats.values()]
        all_ratios = [stats['positive_ratio'] for stats in self.analyzer.compound_stats.values()]

        # è®¡ç®—åœ¨å½“å‰é˜ˆå€¼ä¸‹ç¬¦åˆæ¡ä»¶çš„åŒ–åˆç‰©æ•°é‡
        prob_filtered = sum(1 for p in all_probs if p >= self.analyzer.current_prob_threshold)
        conf_filtered = sum(1 for c in all_confs if c >= self.analyzer.current_conf_threshold)
        both_filtered = sum(1 for stats in self.analyzer.compound_stats.values()
                            if stats['avg_probability_1'] >= self.analyzer.current_prob_threshold and
                            stats['avg_confidence'] >= self.analyzer.current_conf_threshold)

        stats_text = f"""
ğŸ“Š åŸºç¡€ç»Ÿè®¡åˆ†æç»“æœ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ˆ æ¦‚ç‡ç»Ÿè®¡
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
å¹³å‡å€¼: {np.mean(all_probs):.4f}
ä¸­ä½æ•°: {np.median(all_probs):.4f}
æ ‡å‡†å·®: {np.std(all_probs):.4f}
æœ€å°å€¼: {np.min(all_probs):.4f}
æœ€å¤§å€¼: {np.max(all_probs):.4f}
â‰¥ å½“å‰é˜ˆå€¼({self.analyzer.current_prob_threshold:.3f}): {prob_filtered} ä¸ª

ğŸ¯ ç½®ä¿¡åº¦ç»Ÿè®¡
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
å¹³å‡å€¼: {np.mean(all_confs):.4f}
ä¸­ä½æ•°: {np.median(all_confs):.4f}
æ ‡å‡†å·®: {np.std(all_confs):.4f}
æœ€å°å€¼: {np.min(all_confs):.4f}
æœ€å¤§å€¼: {np.max(all_confs):.4f}
â‰¥ å½“å‰é˜ˆå€¼({self.analyzer.current_conf_threshold:.3f}): {conf_filtered} ä¸ª

ğŸ“Š æ­£ä¾‹æ¯”ä¾‹ç»Ÿè®¡
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
å¹³å‡å€¼: {np.mean(all_ratios):.4f}
ä¸­ä½æ•°: {np.median(all_ratios):.4f}
æ ‡å‡†å·®: {np.std(all_ratios):.4f}

ğŸ¯ å½“å‰é˜ˆå€¼ç­›é€‰
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
åŒæ—¶æ»¡è¶³æ¦‚ç‡å’Œç½®ä¿¡åº¦é˜ˆå€¼: {both_filtered} ä¸ª

ğŸ“‹ åˆ†å¸ƒæƒ…å†µ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

        # æ­£ä¾‹æ¯”ä¾‹åˆ†ç»„ç»Ÿè®¡
        ratio_groups = {
            'æ— æ­£ä¾‹ (0%)': sum(1 for r in all_ratios if r == 0),
            'å°‘æ•°æ­£ä¾‹ (0-25%)': sum(1 for r in all_ratios if 0 < r <= 0.25),
            'éƒ¨åˆ†æ­£ä¾‹ (25-50%)': sum(1 for r in all_ratios if 0.25 < r <= 0.5),
            'å¤šæ•°æ­£ä¾‹ (50-75%)': sum(1 for r in all_ratios if 0.5 < r <= 0.75),
            'å¤§å¤šæ•°æ­£ä¾‹ (75-100%)': sum(1 for r in all_ratios if 0.75 < r < 1),
            'å…¨éƒ¨æ­£ä¾‹ (100%)': sum(1 for r in all_ratios if r == 1)
        }

        for group, count in ratio_groups.items():
            percentage = (count / len(all_ratios)) * 100 if len(all_ratios) > 0 else 0
            stats_text += f"{group}: {count:,} ä¸ª ({percentage:.1f}%)\n"

        self.info_text.delete(1.0, tk.END)
        self.info_text.insert(tk.END, stats_text)

    def update_consensus_table(self, all_positive, majority_positive, high_confidence,
                               high_probability, custom_consensus):
        """æ›´æ–°å…±è¯†åˆ†æè¡¨æ ¼"""
        # æ¸…é™¤ç°æœ‰æ•°æ®
        for item in self.tree.get_children():
            self.tree.delete(item)

        # è®¾ç½®åˆ—
        columns = ('ç±»å‹', 'åŒ–åˆç‰©ID', 'è›‹ç™½è´¨ID', 'æ­£ä¾‹/æ€»æ•°', 'æ¦‚ç‡', 'ç½®ä¿¡åº¦')
        self.tree['columns'] = columns

        for col in columns:
            self.tree.heading(col, text=col)
            self.tree.column(col, width=100)

        # æ·»åŠ æ•°æ®
        def add_compounds(compounds, category):
            for compound in compounds[:20]:  # é™åˆ¶æ˜¾ç¤ºå‰20ä¸ª
                self.tree.insert('', 'end', values=(
                    category,
                    compound['compound_id'],
                    compound['protein_id'],
                    f"{compound['positive_predictions']}/{compound['total_models']}",
                    f"{compound['avg_probability_1']:.3f}",
                    f"{compound['avg_confidence']:.3f}"
                ))

        add_compounds(all_positive, "æ‰€æœ‰æ¨¡å‹ä¸€è‡´")
        add_compounds(majority_positive, "å¤§å¤šæ•°åŒæ„")
        add_compounds(high_confidence, "é«˜ç½®ä¿¡åº¦")
        add_compounds(high_probability, "é«˜æ¦‚ç‡")
        add_compounds(custom_consensus, "ç»¼åˆç­›é€‰")

    def update_consensus_info(self, all_positive, majority_positive, high_confidence,
                              high_probability, custom_consensus):
        """æ›´æ–°å…±è¯†åˆ†æä¿¡æ¯"""
        info_text = f"""
ğŸ¯ å…±è¯†åˆ†æç»“æœ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š ç­›é€‰ç»“æœç»Ÿè®¡
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹: {len(all_positive):,} ä¸ªåŒ–åˆç‰©
å¤§å¤šæ•°æ¨¡å‹é¢„æµ‹ä¸ºæ­£ä¾‹: {len(majority_positive):,} ä¸ªåŒ–åˆç‰©
é«˜ç½®ä¿¡åº¦é¢„æµ‹: {len(high_confidence):,} ä¸ªåŒ–åˆç‰©
é«˜æ¦‚ç‡é¢„æµ‹: {len(high_probability):,} ä¸ªåŒ–åˆç‰©
ç»¼åˆç­›é€‰ç»“æœ: {len(custom_consensus):,} ä¸ªåŒ–åˆç‰©

ğŸ¥‡ æœ€é«˜ä¼˜å…ˆçº§åŒ–åˆç‰© (æ‰€æœ‰æ¨¡å‹ä¸€è‡´)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

        if all_positive:
            for i, compound in enumerate(all_positive[:10], 1):
                info_text += f"{i:2d}. {compound['compound_id']} (è›‹ç™½è´¨: {compound['protein_id']}) "
                info_text += f"æ¦‚ç‡: {compound['avg_probability_1']:.3f}, ç½®ä¿¡åº¦: {compound['avg_confidence']:.3f}\n"
        else:
            info_text += "æš‚æ— ç¬¦åˆæ¡ä»¶çš„åŒ–åˆç‰©\n"

        info_text += f"""
ğŸ¥ˆ é«˜ç½®ä¿¡åº¦åŒ–åˆç‰©
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

        if high_confidence:
            for i, compound in enumerate(high_confidence[:10], 1):
                info_text += f"{i:2d}. {compound['compound_id']} (è›‹ç™½è´¨: {compound['protein_id']}) "
                info_text += f"æ¦‚ç‡: {compound['avg_probability_1']:.3f}, ç½®ä¿¡åº¦: {compound['avg_confidence']:.3f}\n"
        else:
            info_text += "æš‚æ— ç¬¦åˆæ¡ä»¶çš„åŒ–åˆç‰©\n"

        info_text += f"""
ğŸ’¡ åˆ†æå»ºè®®
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

        if len(all_positive) > 0:
            info_text += "â€¢ ä¼˜å…ˆéªŒè¯æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹çš„åŒ–åˆç‰©ï¼ŒæˆåŠŸç‡æœ€é«˜\n"
        if len(high_confidence) > len(all_positive):
            info_text += "â€¢ è€ƒè™‘é«˜ç½®ä¿¡åº¦åŒ–åˆç‰©ä½œä¸ºäºŒçº¿é€‰æ‹©\n"
        if len(majority_positive) > 50:
            info_text += "â€¢ å¤§å¤šæ•°æ¨¡å‹é¢„æµ‹ä¸ºæ­£ä¾‹çš„åŒ–åˆç‰©æ•°é‡è¾ƒå¤šï¼Œå»ºè®®è¿›ä¸€æ­¥ç­›é€‰\n"

        info_text += "â€¢ å»ºè®®ç»“åˆç”Ÿç‰©å­¦çŸ¥è¯†å’ŒåŒ–åˆç‰©ç‰¹æ€§è¿›è¡Œæœ€ç»ˆç­›é€‰\n"
        info_text += "â€¢ è€ƒè™‘åˆ†æ‰¹è¿›è¡Œå®éªŒéªŒè¯ï¼Œä»æœ€é«˜ç½®ä¿¡åº¦å¼€å§‹\n"
        info_text += "â€¢ ä½¿ç”¨'è¯¦ç»†å¯¼å‡º'åŠŸèƒ½è·å–æ¯ä¸ªæ¨¡å‹çš„å…·ä½“é¢„æµ‹æ•°æ®\n"

        self.info_text.delete(1.0, tk.END)
        self.info_text.insert(tk.END, info_text)

    # ===============================
    # å…¶ä»–å¯¼å‡ºåŠŸèƒ½
    # ===============================

    def generate_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        if not self.check_analyzer():
            return

        # é€‰æ‹©ä¿å­˜ä½ç½®
        file_path = filedialog.asksaveasfilename(
            title="ä¿å­˜åˆ†ææŠ¥å‘Š",
            defaultextension=".txt",
            filetypes=[("æ–‡æœ¬æ–‡ä»¶", "*.txt"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )

        if not file_path:
            return

        self.status_var.set("æ­£åœ¨ç”ŸæˆæŠ¥å‘Š...")

        try:
            # æ‰§è¡Œå„ç§åˆ†æ
            all_positive = self.analyzer._find_all_positive()
            majority_positive = self.analyzer._find_majority_positive()
            high_confidence = self.analyzer._find_high_confidence()
            high_probability = self.analyzer._find_high_probability()
            custom_consensus = self.analyzer._find_custom_consensus()

            # ç”ŸæˆæŠ¥å‘Šå†…å®¹
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write("é¢„æµ‹ç»“æœåˆ†ææŠ¥å‘Š (å¢å¼ºç‰ˆ)\n")
                f.write("=" * 80 + "\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"åˆ†æç”¨æˆ·: {os.getenv('USERNAME', 'woyaokaoyanhaha')}\n")
                f.write(f"æ•°æ®æ¥æº: {self.analyzer.result_dir}\n")
                f.write(f"åˆ†æå·¥å…·: é¢„æµ‹ç»“æœåˆ†æå™¨ GUI v2.1 (å¢å¼ºç‰ˆ)\n\n")

                f.write("æ•°æ®æ¦‚å†µ\n")
                f.write("-" * 40 + "\n")
                f.write(f"åŒ–åˆç‰©æ€»æ•°: {len(self.analyzer.compound_stats):,}\n")
                f.write(f"æ¨¡å‹æ€»æ•°: {len(self.analyzer.available_models)}\n")
                f.write(f"åˆ†æå‚æ•°:\n")
                f.write(f"  æœ€å°å…±è¯†æ¨¡å‹æ•°: {self.analyzer.current_min_consensus}\n")
                f.write(f"  æ¦‚ç‡é˜ˆå€¼: {self.analyzer.current_prob_threshold:.3f}\n")
                f.write(f"  ç½®ä¿¡åº¦é˜ˆå€¼: {self.analyzer.current_conf_threshold:.3f}\n\n")

                f.write("ç­›é€‰ç»“æœç»Ÿè®¡\n")
                f.write("-" * 40 + "\n")
                f.write(f"æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹: {len(all_positive):,} ä¸ªåŒ–åˆç‰©\n")
                f.write(f"å¤§å¤šæ•°æ¨¡å‹é¢„æµ‹ä¸ºæ­£ä¾‹: {len(majority_positive):,} ä¸ªåŒ–åˆç‰©\n")
                f.write(f"é«˜ç½®ä¿¡åº¦é¢„æµ‹: {len(high_confidence):,} ä¸ªåŒ–åˆç‰©\n")
                f.write(f"é«˜æ¦‚ç‡é¢„æµ‹: {len(high_probability):,} ä¸ªåŒ–åˆç‰©\n")
                f.write(f"ç»¼åˆç­›é€‰ç»“æœ: {len(custom_consensus):,} ä¸ªåŒ–åˆç‰©\n\n")

                # é‡ç‚¹åŒ–åˆç‰©æ¨è
                f.write("é‡ç‚¹åŒ–åˆç‰©æ¨è\n")
                f.write("-" * 40 + "\n")

                if all_positive:
                    f.write("ğŸ¥‡ æœ€é«˜ä¼˜å…ˆçº§åŒ–åˆç‰© (æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹):\n")
                    for i, compound in enumerate(all_positive[:20], 1):
                        f.write(f"  {i:2d}. {compound['compound_id']} (è›‹ç™½è´¨: {compound['protein_id']}) - "
                                f"æ¦‚ç‡: {compound['avg_probability_1']:.3f}, ç½®ä¿¡åº¦: {compound['avg_confidence']:.3f}\n")
                    f.write("\n")

                if high_confidence:
                    f.write("ğŸ¥ˆ é«˜ç½®ä¿¡åº¦åŒ–åˆç‰©:\n")
                    for i, compound in enumerate(high_confidence[:20], 1):
                        f.write(f"  {i:2d}. {compound['compound_id']} (è›‹ç™½è´¨: {compound['protein_id']}) - "
                                f"æ¦‚ç‡: {compound['avg_probability_1']:.3f}, ç½®ä¿¡åº¦: {compound['avg_confidence']:.3f}\n")
                    f.write("\n")

                # ç»Ÿè®¡åˆ†æ
                all_probs = [stats['avg_probability_1'] for stats in self.analyzer.compound_stats.values()]
                all_confs = [stats['avg_confidence'] for stats in self.analyzer.compound_stats.values()]

                f.write("ç»Ÿè®¡åˆ†æ\n")
                f.write("-" * 40 + "\n")
                f.write(f"æ¦‚ç‡åˆ†å¸ƒ:\n")
                f.write(f"  å¹³å‡å€¼: {np.mean(all_probs):.4f}\n")
                f.write(f"  ä¸­ä½æ•°: {np.median(all_probs):.4f}\n")
                f.write(f"  æ ‡å‡†å·®: {np.std(all_probs):.4f}\n")
                f.write(f"  æœ€å°å€¼: {np.min(all_probs):.4f}\n")
                f.write(f"  æœ€å¤§å€¼: {np.max(all_probs):.4f}\n\n")

                f.write(f"ç½®ä¿¡åº¦åˆ†å¸ƒ:\n")
                f.write(f"  å¹³å‡å€¼: {np.mean(all_confs):.4f}\n")
                f.write(f"  ä¸­ä½æ•°: {np.median(all_confs):.4f}\n")
                f.write(f"  æ ‡å‡†å·®: {np.std(all_confs):.4f}\n")
                f.write(f"  æœ€å°å€¼: {np.min(all_confs):.4f}\n")
                f.write(f"  æœ€å¤§å€¼: {np.max(all_confs):.4f}\n\n")

                # å¢å¼ºç‰ˆåˆ†æå»ºè®®
                f.write("åˆ†æå»ºè®® (å¢å¼ºç‰ˆ)\n")
                f.write("-" * 40 + "\n")
                if len(all_positive) > 0:
                    f.write("1. ä¼˜å…ˆéªŒè¯æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹çš„åŒ–åˆç‰©ï¼ŒæˆåŠŸç‡æœ€é«˜\n")
                if len(high_confidence) > len(all_positive):
                    f.write("2. è€ƒè™‘é«˜ç½®ä¿¡åº¦åŒ–åˆç‰©ä½œä¸ºäºŒçº¿é€‰æ‹©\n")
                if len(majority_positive) > 50:
                    f.write("3. å¤§å¤šæ•°æ¨¡å‹é¢„æµ‹ä¸ºæ­£ä¾‹çš„åŒ–åˆç‰©æ•°é‡è¾ƒå¤šï¼Œå»ºè®®è¿›ä¸€æ­¥ç­›é€‰\n")

                f.write("4. å»ºè®®ç»“åˆç”Ÿç‰©å­¦çŸ¥è¯†å’ŒåŒ–åˆç‰©ç‰¹æ€§è¿›è¡Œæœ€ç»ˆç­›é€‰\n")
                f.write("5. è€ƒè™‘åˆ†æ‰¹è¿›è¡Œå®éªŒéªŒè¯ï¼Œä»æœ€é«˜ç½®ä¿¡åº¦å¼€å§‹\n")
                f.write("6. ä½¿ç”¨è¯¦ç»†å¯¼å‡ºåŠŸèƒ½è·å–æ¯ä¸ªæ¨¡å‹çš„å…·ä½“é¢„æµ‹æ•°æ®\n")
                f.write("7. å¯ä»¥è°ƒæ•´å‚æ•°é˜ˆå€¼è¿›è¡Œæ•æ„Ÿæ€§åˆ†æ\n")
                f.write("8. å®šæœŸæ›´æ–°æ¨¡å‹å’Œé‡æ–°è¯„ä¼°é¢„æµ‹ç»“æœ\n")

                f.write("\nå¯¼å‡ºåŠŸèƒ½è¯´æ˜\n")
                f.write("-" * 40 + "\n")
                f.write("â€¢ åŸºç¡€å¯¼å‡º: åŒ…å«å¹³å‡ç»Ÿè®¡æ•°æ®ï¼Œé€‚åˆå¿«é€Ÿç­›é€‰\n")
                f.write("â€¢ è¯¦ç»†å¯¼å‡º: åŒ…å«æ¯ä¸ªæ¨¡å‹çš„é¢„æµ‹æ•°æ®ï¼Œé€‚åˆæ·±å…¥åˆ†æ\n")
                f.write("â€¢ å®Œæ•´å¯¼å‡º: åŒ…å«æ‰€æœ‰åŸå§‹æ¨¡å‹æ•°æ®ï¼Œé€‚åˆæ•°æ®æŒ–æ˜\n")

                f.write("\n" + "=" * 80 + "\n")
                f.write("æŠ¥å‘Šç»“æŸ\n")
                f.write("=" * 80 + "\n")

            messagebox.showinfo("æˆåŠŸ", f"å¢å¼ºç‰ˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°:\n{file_path}")
            self.status_var.set("æŠ¥å‘Šç”Ÿæˆå®Œæˆ")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            self.status_var.set("æŠ¥å‘Šç”Ÿæˆå¤±è´¥")

    def save_current_plot(self):
        """ä¿å­˜å½“å‰å›¾è¡¨"""
        if not self.figure:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰å¯ä¿å­˜çš„å›¾è¡¨")
            return

        # é€‰æ‹©ä¿å­˜ä½ç½®
        file_path = filedialog.asksaveasfilename(
            title="ä¿å­˜å›¾è¡¨",
            defaultextension=".png",
            filetypes=[
                ("PNGå›¾ç‰‡", "*.png"),
                ("JPEGå›¾ç‰‡", "*.jpg"),
                ("PDFæ–‡ä»¶", "*.pdf"),
                ("SVGçŸ¢é‡å›¾", "*.svg"),
                ("æ‰€æœ‰æ–‡ä»¶", "*.*")
            ]
        )

        if not file_path:
            return

        try:
            self.figure.savefig(file_path, dpi=300, bbox_inches='tight')
            messagebox.showinfo("æˆåŠŸ", f"å›¾è¡¨å·²ä¿å­˜åˆ°:\n{file_path}")
            self.status_var.set("å›¾è¡¨ä¿å­˜æˆåŠŸ")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"ä¿å­˜å›¾è¡¨å¤±è´¥: {e}")
            self.status_var.set("ä¿å­˜å¤±è´¥")


def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºä¸»çª—å£
    root = tk.Tk()

    # åˆ›å»ºåº”ç”¨
    app = EnhancedPredictionAnalyzerGUI(root)

    # è®¾ç½®çª—å£å…³é—­äº‹ä»¶
    def on_closing():
        if messagebox.askokcancel("é€€å‡º", "ç¡®å®šè¦é€€å‡ºé¢„æµ‹ç»“æœåˆ†æå™¨å—ï¼Ÿ"):
            root.destroy()

    root.protocol("WM_DELETE_WINDOW", on_closing)

    # è¿è¡Œåº”ç”¨
    try:
        print("ğŸš€ å¯åŠ¨é¢„æµ‹ç»“æœåˆ†æå™¨ GUI v2.1 (å¢å¼ºç‰ˆ)...")
        print("âœ¨ æ–°åŠŸèƒ½: æ»‘å—+ç›´æ¥è¾“å…¥ + è¯¦ç»†å¯¼å‡º")
        print("âœ… ä¸­æ–‡å­—ä½“å·²é…ç½®")
        print("âœ… ç•Œé¢ç»„ä»¶å·²åŠ è½½")
        print("âœ… å‡†å¤‡å°±ç»ªï¼")

        root.mainloop()

    except KeyboardInterrupt:
        print("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()