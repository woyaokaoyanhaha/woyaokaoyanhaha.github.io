# =============================================================================
# å¢å¼ºæ¨¡å‹è¯¦æƒ…ç‰ˆé¢„æµ‹ç»“æœåˆ†æå™¨ GUI - åŒ…å«å•æ¨¡å‹ç­›é€‰ä¿¡æ¯
# =============================================================================

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.figure import Figure
import pandas as pd
import numpy as np
import json
import os
import glob
from datetime import datetime
import threading
from collections import defaultdict, Counter
import warnings
import platform
import time

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')


# =============================================================================
# å­—ä½“é…ç½®
# =============================================================================

def configure_chinese_fonts():
    """é…ç½®ä¸­æ–‡å­—ä½“"""
    try:
        import matplotlib.font_manager as fm

        system = platform.system()
        chinese_fonts = []

        if system == "Windows":
            chinese_fonts = ['Microsoft YaHei', 'SimHei', 'KaiTi']
        elif system == "Darwin":
            chinese_fonts = ['PingFang SC', 'Heiti SC', 'STSong']
        else:
            chinese_fonts = ['WenQuanYi Micro Hei', 'Noto Sans CJK SC']

        available_fonts = [f.name for f in fm.fontManager.ttflist]

        for font in chinese_fonts:
            if font in available_fonts:
                plt.rcParams['font.sans-serif'] = [font, 'DejaVu Sans']
                plt.rcParams['axes.unicode_minus'] = False
                return font

        plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'sans-serif']
        plt.rcParams['axes.unicode_minus'] = False
        return "DejaVu Sans"

    except Exception as e:
        print(f"å­—ä½“é…ç½®å‡ºé”™: {e}")
        return "DejaVu Sans"


configure_chinese_fonts()


# =============================================================================
# JSONåºåˆ—åŒ–è¾…åŠ©å‡½æ•°
# =============================================================================

def convert_numpy_types(obj):
    """è½¬æ¢NumPyæ•°æ®ç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj


def safe_json_dump(obj, file_path, **kwargs):
    """å®‰å…¨JSONä¿å­˜"""
    try:
        converted_obj = convert_numpy_types(obj)
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(converted_obj, f, **kwargs)
        return True
    except Exception as e:
        print(f"ä¿å­˜JSONæ–‡ä»¶å¤±è´¥: {e}")
        return False


# =============================================================================
# å¯æ»šåŠ¨æ¡†æ¶ç±»
# =============================================================================

class ScrollableFrame(ttk.Frame):
    """å¯æ»šåŠ¨çš„æ¡†æ¶"""

    def __init__(self, container, *args, **kwargs):
        super().__init__(container, *args, **kwargs)

        # åˆ›å»ºCanvaså’ŒScrollbar
        self.canvas = tk.Canvas(self, highlightthickness=0)
        self.scrollbar = ttk.Scrollbar(self, orient="vertical", command=self.canvas.yview)
        self.scrollable_frame = ttk.Frame(self.canvas)

        # é…ç½®æ»šåŠ¨
        self.scrollable_frame.bind(
            "<Configure>",
            lambda e: self.canvas.configure(scrollregion=self.canvas.bbox("all"))
        )

        # åˆ›å»ºCanvasçª—å£
        self.canvas_frame = self.canvas.create_window((0, 0), window=self.scrollable_frame, anchor="nw")

        # é…ç½®Canvasæ»šåŠ¨
        self.canvas.configure(yscrollcommand=self.scrollbar.set)

        # å¸ƒå±€
        self.canvas.pack(side="left", fill="both", expand=True)
        self.scrollbar.pack(side="right", fill="y")

        # ç»‘å®šé¼ æ ‡æ»šè½®äº‹ä»¶
        self.bind_mousewheel()

        # ç»‘å®šCanvaså¤§å°å˜åŒ–äº‹ä»¶
        self.canvas.bind('<Configure>', self._on_canvas_configure)

    def _on_canvas_configure(self, event):
        """Canvaså¤§å°å˜åŒ–æ—¶è°ƒæ•´scrollable_frameå®½åº¦"""
        canvas_width = event.width
        self.canvas.itemconfig(self.canvas_frame, width=canvas_width)

    def bind_mousewheel(self):
        """ç»‘å®šé¼ æ ‡æ»šè½®äº‹ä»¶"""

        def _on_mousewheel(event):
            self.canvas.yview_scroll(int(-1 * (event.delta / 120)), "units")

        def _bind_to_mousewheel(event):
            self.canvas.bind_all("<MouseWheel>", _on_mousewheel)

        def _unbind_from_mousewheel(event):
            self.canvas.unbind_all("<MouseWheel>")

        self.canvas.bind('<Enter>', _bind_to_mousewheel)
        self.canvas.bind('<Leave>', _unbind_from_mousewheel)


# =============================================================================
# å¿«é€Ÿæ–‡ä»¶æ‰«æå™¨
# =============================================================================

class FastFileScanner:
    """å¿«é€Ÿæ–‡ä»¶æ‰«æå™¨ - ä¼˜åŒ–æ€§èƒ½"""

    def __init__(self):
        self.cache = {}

    def quick_scan_directory(self, directory, max_depth=3):
        """å¿«é€Ÿæ‰«æç›®å½•"""
        print(f"ğŸš€ å¿«é€Ÿæ‰«æç›®å½•: {directory}")
        start_time = time.time()

        prediction_files = {}
        csv_files = []

        for root, dirs, files in os.walk(directory):
            depth = root[len(directory):].count(os.sep)
            if depth >= max_depth:
                dirs[:] = []
                continue

            for file in files:
                if file.endswith('.csv') and ('prediction' in file.lower() or 'result' in file.lower()):
                    full_path = os.path.join(root, file)
                    csv_files.append(full_path)

        print(f"   å‘ç° {len(csv_files)} ä¸ªæ½œåœ¨é¢„æµ‹æ–‡ä»¶")

        valid_files = []
        for file_path in csv_files:
            if self._quick_validate_file(file_path):
                valid_files.append(file_path)

        print(f"   éªŒè¯é€šè¿‡ {len(valid_files)} ä¸ªæ–‡ä»¶")

        for file_path in valid_files:
            self._quick_categorize_file(file_path, prediction_files)

        scan_time = time.time() - start_time
        print(f"   æ‰«æå®Œæˆï¼Œè€—æ—¶: {scan_time:.2f}ç§’")

        return prediction_files

    def _quick_validate_file(self, file_path):
        """å¿«é€ŸéªŒè¯æ–‡ä»¶"""
        try:
            if os.path.getsize(file_path) < 1024:
                return False

            if file_path in self.cache:
                return self.cache[file_path]

            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                header = f.readline().lower()

                has_protein = 'protein' in header
                has_compound = 'compound' in header
                has_prediction = 'prediction' in header or 'pred' in header

                result = has_protein and has_compound and has_prediction
                self.cache[file_path] = result
                return result

        except Exception:
            return False

    def _quick_categorize_file(self, file_path, prediction_files):
        """å¿«é€Ÿåˆ†ç±»æ–‡ä»¶"""
        try:
            rel_path = os.path.relpath(file_path)
            path_parts = rel_path.split(os.sep)

            model_type = 'unknown'
            model_name = os.path.basename(file_path).replace('.csv', '')

            for part in path_parts:
                if any(keyword in part.lower() for keyword in ['æ ‡å‡†', 'éšæœº', 'random', 'standard']):
                    model_type = part
                    break
                elif len(part) > 3 and part not in ['prediction_results_batch', 'reuse_chunks']:
                    model_type = part

            model_name = model_name.replace('_prediction', '').replace('_result', '')

            if model_type not in prediction_files:
                prediction_files[model_type] = {}

            prediction_files[model_type][model_name] = file_path

        except Exception as e:
            print(f"åˆ†ç±»æ–‡ä»¶å¤±è´¥ {file_path}: {e}")


# =============================================================================
# ä¼˜åŒ–çš„æ•°æ®åŠ è½½å™¨
# =============================================================================

class OptimizedDataLoader:
    """ä¼˜åŒ–çš„æ•°æ®åŠ è½½å™¨"""

    def __init__(self):
        self.chunk_size = 10000

    def load_file_efficiently(self, file_path, progress_callback=None):
        """é«˜æ•ˆåŠ è½½æ–‡ä»¶"""
        try:
            file_size = os.path.getsize(file_path)

            if progress_callback:
                progress_callback(f"åŠ è½½æ–‡ä»¶: {os.path.basename(file_path)} ({file_size / 1024 / 1024:.1f}MB)")

            if file_size > 100 * 1024 * 1024:
                return self._load_large_file(file_path, progress_callback)
            else:
                return self._load_normal_file(file_path)

        except Exception as e:
            print(f"åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None

    def _load_normal_file(self, file_path):
        """åŠ è½½æ™®é€šå¤§å°çš„æ–‡ä»¶"""
        try:
            df = pd.read_csv(file_path, low_memory=False)
            return self._standardize_dataframe_fast(df)
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None

    def _load_large_file(self, file_path, progress_callback=None):
        """åˆ†å—åŠ è½½å¤§æ–‡ä»¶"""
        try:
            chunks = []
            total_chunks = 0

            for chunk in pd.read_csv(file_path, chunksize=self.chunk_size, low_memory=False):
                chunks.append(self._standardize_dataframe_fast(chunk))
                total_chunks += 1

                if progress_callback and total_chunks % 10 == 0:
                    progress_callback(f"å·²å¤„ç† {total_chunks} ä¸ªæ•°æ®å—")

            if chunks:
                df = pd.concat(chunks, ignore_index=True)
                return df
            else:
                return None

        except Exception as e:
            print(f"åˆ†å—è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None

    def _standardize_dataframe_fast(self, df):
        """å¿«é€Ÿæ ‡å‡†åŒ–DataFrame"""
        if df is None or df.empty:
            return None

        try:
            column_map = {}
            columns_lower = {col.lower(): col for col in df.columns}

            # å¿…éœ€åˆ—æ˜ å°„
            for target, patterns in [
                ('protein_id', ['protein_id', 'protein', 'prot_id']),
                ('compound_id', ['compound_id', 'compound', 'comp_id']),
                ('prediction', ['prediction', 'pred', 'label'])
            ]:
                for pattern in patterns:
                    if pattern in columns_lower:
                        column_map[columns_lower[pattern]] = target
                        break

            # å¯é€‰åˆ—æ˜ å°„
            for target, patterns in [
                ('probability_0', ['probability_0', 'prob_0', 'p0']),
                ('probability_1', ['probability_1', 'prob_1', 'p1']),
                ('confidence', ['confidence', 'conf'])
            ]:
                for pattern in patterns:
                    if pattern in columns_lower:
                        column_map[columns_lower[pattern]] = target
                        break

            df = df.rename(columns=column_map)

            required_cols = ['protein_id', 'compound_id', 'prediction']
            missing_cols = [col for col in required_cols if col not in df.columns]

            if missing_cols:
                print(f"ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")
                return None

            if 'probability_0' not in df.columns:
                if 'probability_1' in df.columns:
                    df['probability_0'] = 1 - df['probability_1']
                else:
                    df['probability_0'] = 0.5
                    df['probability_1'] = 0.5

            if 'probability_1' not in df.columns:
                df['probability_1'] = 1 - df['probability_0']

            if 'confidence' not in df.columns:
                df['confidence'] = df[['probability_0', 'probability_1']].max(axis=1)

            df['prediction'] = df['prediction'].astype(int)

            keep_cols = ['protein_id', 'compound_id', 'prediction', 'probability_0', 'probability_1', 'confidence']
            df = df[keep_cols]

            return df

        except Exception as e:
            print(f"æ ‡å‡†åŒ–å¤±è´¥: {e}")
            return None


# =============================================================================
# å¢å¼ºé˜ˆå€¼åˆ†æå™¨ - åŒ…å«å•æ¨¡å‹ç­›é€‰ä¿¡æ¯
# =============================================================================

class EnhancedThresholdAnalyzer:
    """å¢å¼ºé˜ˆå€¼åˆ†æå™¨ - æ”¯æŒè‡ªå®šä¹‰æ­£ä¾‹é¢„æµ‹é˜ˆå€¼å’Œå•æ¨¡å‹ç­›é€‰"""

    def __init__(self):
        self.scanner = FastFileScanner()
        self.loader = OptimizedDataLoader()
        self.raw_predictions = {}
        self.compound_stats = {}
        self.available_models = []
        self.result_dir = None
        self.detected_format = None

        # æ–°å¢ï¼šå•æ¨¡å‹ç­›é€‰ç»“æœ
        self.individual_model_results = {}

        # åˆ†æå‚æ•°
        self.current_min_consensus = 2
        self.current_prob_threshold = 0.6
        self.current_conf_threshold = 0.7
        # è‡ªå®šä¹‰æ­£ä¾‹é¢„æµ‹é˜ˆå€¼
        self.current_positive_prediction_threshold = 0.5

    def quick_scan_directory(self, directory):
        """å¿«é€Ÿæ‰«æç›®å½•"""
        return self.scanner.quick_scan_directory(directory)

    def load_prediction_results(self, result_dir, progress_callback=None):
        """ä¼˜åŒ–çš„æ•°æ®åŠ è½½"""
        print(f"ğŸ“Š å¼€å§‹åŠ è½½é¢„æµ‹ç»“æœ...")
        start_time = time.time()

        self.result_dir = result_dir

        try:
            if progress_callback:
                progress_callback("æ­£åœ¨æ‰«ææ–‡ä»¶...")

            prediction_files = self.scanner.quick_scan_directory(result_dir)

            if not prediction_files:
                return False

            total_files = sum(len(models) for models in prediction_files.values())
            print(f"   éœ€è¦åŠ è½½ {total_files} ä¸ªæ–‡ä»¶")

            self.raw_predictions = {}
            self.available_models = []
            loaded_count = 0

            for model_type, models in prediction_files.items():
                if progress_callback:
                    progress_callback(f"åŠ è½½æ¨¡å‹ç±»å‹: {model_type}")

                self.raw_predictions[model_type] = {}

                for model_name, file_path in models.items():
                    try:
                        if progress_callback:
                            progress_callback(f"åŠ è½½: {model_name} ({loaded_count + 1}/{total_files})")

                        df = self.loader.load_file_efficiently(file_path, progress_callback)

                        if df is not None and len(df) > 0:
                            self.raw_predictions[model_type][model_name] = df
                            self.available_models.append(f"{model_type}_{model_name}")
                            loaded_count += 1
                            print(f"   âœ“ {model_name}: {len(df):,} è¡Œ")
                        else:
                            print(f"   âœ— {model_name}: åŠ è½½å¤±è´¥æˆ–æ•°æ®ä¸ºç©º")

                    except Exception as e:
                        print(f"   âœ— {model_name}: {e}")
                        continue

            if progress_callback:
                progress_callback("æ­£åœ¨åˆ†æåŒ–åˆç‰©ç»Ÿè®¡...")

            self._analyze_compound_statistics_fast()

            if progress_callback:
                progress_callback("æ­£åœ¨åˆ†æå•æ¨¡å‹ç­›é€‰ç»“æœ...")

            # æ–°å¢ï¼šåˆ†æå•æ¨¡å‹ç­›é€‰ç»“æœ
            self._analyze_individual_model_results()

            load_time = time.time() - start_time
            print(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f}ç§’")
            print(f"   æˆåŠŸåŠ è½½: {loaded_count}/{total_files} ä¸ªæ–‡ä»¶")
            print(f"   åŒ–åˆç‰©å¯¹: {len(self.compound_stats):,}")
            print(f"   å•æ¨¡å‹ç­›é€‰ç»“æœ: {len(self.individual_model_results)} ä¸ªæ¨¡å‹")

            return len(self.compound_stats) > 0

        except Exception as e:
            print(f"åŠ è½½å¤±è´¥: {e}")
            return False

    def _analyze_compound_statistics_fast(self):
        """å¿«é€Ÿåˆ†æåŒ–åˆç‰©ç»Ÿè®¡ - ä½¿ç”¨è‡ªå®šä¹‰æ­£ä¾‹é¢„æµ‹é˜ˆå€¼"""
        print("ğŸ”„ å¿«é€Ÿåˆ†æåŒ–åˆç‰©ç»Ÿè®¡...")
        start_time = time.time()

        self.compound_stats = {}
        compound_predictions = defaultdict(list)

        for model_type, models in self.raw_predictions.items():
            for model_name, df in models.items():
                for _, row in df.iterrows():
                    key = f"{row['protein_id']}_{row['compound_id']}"

                    # ä½¿ç”¨è‡ªå®šä¹‰é˜ˆå€¼é‡æ–°è®¡ç®—é¢„æµ‹ç»“æœ
                    custom_prediction = 1 if row['probability_1'] >= self.current_positive_prediction_threshold else 0

                    compound_predictions[key].append({
                        'model_type': model_type,
                        'model_name': model_name,
                        'protein_id': row['protein_id'],
                        'compound_id': row['compound_id'],
                        'original_prediction': row['prediction'],  # ä¿å­˜åŸå§‹é¢„æµ‹
                        'custom_prediction': custom_prediction,  # åŸºäºè‡ªå®šä¹‰é˜ˆå€¼çš„é¢„æµ‹
                        'probability_0': row['probability_0'],
                        'probability_1': row['probability_1'],
                        'confidence': row['confidence']
                    })

        for compound_key, predictions in compound_predictions.items():
            protein_id, compound_id = compound_key.split('_', 1)

            total_models = len(predictions)
            # ä½¿ç”¨è‡ªå®šä¹‰é˜ˆå€¼çš„é¢„æµ‹ç»“æœè®¡ç®—
            positive_predictions = sum(1 for p in predictions if p['custom_prediction'] == 1)

            prob_1_values = [p['probability_1'] for p in predictions]
            conf_values = [p['confidence'] for p in predictions]

            self.compound_stats[compound_key] = {
                'protein_id': protein_id,
                'compound_id': compound_id,
                'total_models': total_models,
                'positive_predictions': positive_predictions,
                'negative_predictions': total_models - positive_predictions,
                'positive_ratio': positive_predictions / total_models,
                'avg_probability_1': np.mean(prob_1_values),
                'avg_confidence': np.mean(conf_values),
                'predictions': predictions
            }

        analysis_time = time.time() - start_time
        print(f"   ç»Ÿè®¡åˆ†æå®Œæˆï¼Œè€—æ—¶: {analysis_time:.2f}ç§’")
        print(f"   ä½¿ç”¨æ­£ä¾‹é¢„æµ‹é˜ˆå€¼: {self.current_positive_prediction_threshold:.3f}")

    def _analyze_individual_model_results(self):
        """æ–°å¢ï¼šåˆ†ææ¯ä¸ªæ¨¡å‹çš„å•ç‹¬ç­›é€‰ç»“æœ"""
        print("ğŸ”„ åˆ†æå•æ¨¡å‹ç­›é€‰ç»“æœ...")
        start_time = time.time()

        self.individual_model_results = {}

        for model_type, models in self.raw_predictions.items():
            for model_name, df in models.items():
                model_key = f"{model_type}_{model_name}"

                # ç­›é€‰å¤§äºé˜ˆå€¼çš„åŒ–åˆç‰©
                filtered_df = df[df['probability_1'] >= self.current_positive_prediction_threshold].copy()

                if len(filtered_df) > 0:
                    # æ·»åŠ è‡ªå®šä¹‰é¢„æµ‹åˆ—
                    filtered_df['custom_prediction'] = 1

                    # æŒ‰ç½®ä¿¡åº¦æ’åº
                    filtered_df = filtered_df.sort_values(['confidence', 'probability_1'], ascending=[False, False])

                    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                    total_compounds = len(df)
                    filtered_compounds = len(filtered_df)
                    avg_prob_1 = filtered_df['probability_1'].mean()
                    avg_confidence = filtered_df['confidence'].mean()
                    max_prob_1 = filtered_df['probability_1'].max()
                    min_prob_1 = filtered_df['probability_1'].min()

                    self.individual_model_results[model_key] = {
                        'model_type': model_type,
                        'model_name': model_name,
                        'total_compounds': total_compounds,
                        'filtered_compounds': filtered_compounds,
                        'filtered_ratio': filtered_compounds / total_compounds,
                        'avg_probability_1': avg_prob_1,
                        'avg_confidence': avg_confidence,
                        'max_probability_1': max_prob_1,
                        'min_probability_1': min_prob_1,
                        'filtered_data': filtered_df.to_dict('records'),
                        'threshold_used': self.current_positive_prediction_threshold
                    }
                else:
                    self.individual_model_results[model_key] = {
                        'model_type': model_type,
                        'model_name': model_name,
                        'total_compounds': len(df),
                        'filtered_compounds': 0,
                        'filtered_ratio': 0.0,
                        'avg_probability_1': 0.0,
                        'avg_confidence': 0.0,
                        'max_probability_1': 0.0,
                        'min_probability_1': 0.0,
                        'filtered_data': [],
                        'threshold_used': self.current_positive_prediction_threshold
                    }

        analysis_time = time.time() - start_time
        print(f"   å•æ¨¡å‹åˆ†æå®Œæˆï¼Œè€—æ—¶: {analysis_time:.2f}ç§’")
        print(f"   å·²åˆ†æ {len(self.individual_model_results)} ä¸ªæ¨¡å‹")

    def reanalyze_with_new_threshold(self, new_threshold):
        """ä½¿ç”¨æ–°çš„æ­£ä¾‹é¢„æµ‹é˜ˆå€¼é‡æ–°åˆ†æ"""
        if len(self.compound_stats) == 0:
            return False

        print(f"ğŸ”„ é‡æ–°åˆ†æï¼Œæ–°çš„æ­£ä¾‹é¢„æµ‹é˜ˆå€¼: {new_threshold:.3f}")

        self.current_positive_prediction_threshold = new_threshold
        self._analyze_compound_statistics_fast()
        self._analyze_individual_model_results()  # é‡æ–°åˆ†æå•æ¨¡å‹ç»“æœ

        return True

    def get_summary_info(self):
        """è·å–æ‘˜è¦ä¿¡æ¯"""
        return {
            'total_compounds': len(self.compound_stats),
            'total_models': len(self.available_models),
            'directory': self.result_dir,
            'format': self.detected_format or 'auto_detected',
            'positive_prediction_threshold': self.current_positive_prediction_threshold,
            'individual_models_analyzed': len(self.individual_model_results)
        }

    def get_individual_model_summary(self):
        """æ–°å¢ï¼šè·å–å•æ¨¡å‹ç­›é€‰æ±‡æ€»ä¿¡æ¯"""
        if not self.individual_model_results:
            return {}

        summary = {}
        for model_key, result in self.individual_model_results.items():
            summary[model_key] = {
                'model_type': result['model_type'],
                'model_name': result['model_name'],
                'total_compounds': result['total_compounds'],
                'filtered_compounds': result['filtered_compounds'],
                'filtered_ratio': result['filtered_ratio'],
                'avg_probability_1': result['avg_probability_1'],
                'avg_confidence': result['avg_confidence']
            }

        return summary

    def get_top_compounds_by_model(self, model_key, top_n=20):
        """æ–°å¢ï¼šè·å–æŒ‡å®šæ¨¡å‹çš„Top NåŒ–åˆç‰©"""
        if model_key not in self.individual_model_results:
            return []

        filtered_data = self.individual_model_results[model_key]['filtered_data']
        return filtered_data[:top_n]

    # åˆ†ææ–¹æ³• - ä½¿ç”¨è‡ªå®šä¹‰é˜ˆå€¼
    def _find_all_positive(self):
        """æ‰¾åˆ°æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹çš„åŒ–åˆç‰©ï¼ˆåŸºäºè‡ªå®šä¹‰é˜ˆå€¼ï¼‰"""
        return [stats for stats in self.compound_stats.values()
                if (stats['total_models'] >= self.current_min_consensus and
                    stats['positive_predictions'] == stats['total_models'])]

    def _find_majority_positive(self):
        """æ‰¾åˆ°å¤§å¤šæ•°æ¨¡å‹é¢„æµ‹ä¸ºæ­£ä¾‹çš„åŒ–åˆç‰©ï¼ˆåŸºäºè‡ªå®šä¹‰é˜ˆå€¼ï¼‰"""
        return [stats for stats in self.compound_stats.values()
                if (stats['total_models'] >= self.current_min_consensus and
                    stats['positive_ratio'] > 0.5 and
                    stats['positive_predictions'] >= self.current_min_consensus)]

    def _find_high_confidence(self):
        """æ‰¾åˆ°é«˜ç½®ä¿¡åº¦çš„åŒ–åˆç‰©"""
        return [stats for stats in self.compound_stats.values()
                if (stats['total_models'] >= self.current_min_consensus and
                    stats['avg_confidence'] >= self.current_conf_threshold and
                    stats['positive_predictions'] >= self.current_min_consensus)]

    def _find_high_probability(self):
        """æ‰¾åˆ°é«˜æ¦‚ç‡çš„åŒ–åˆç‰©"""
        return [stats for stats in self.compound_stats.values()
                if (stats['total_models'] >= self.current_min_consensus and
                    stats['avg_probability_1'] >= self.current_prob_threshold and
                    stats['positive_predictions'] >= self.current_min_consensus)]

    def _find_custom_consensus(self):
        """è‡ªå®šä¹‰å…±è¯†åˆ†æï¼ˆåŸºäºè‡ªå®šä¹‰é˜ˆå€¼ï¼‰"""
        return [stats for stats in self.compound_stats.values()
                if (stats['total_models'] >= self.current_min_consensus and
                    stats['positive_predictions'] >= self.current_min_consensus and
                    stats['avg_confidence'] >= self.current_conf_threshold and
                    stats['avg_probability_1'] >= self.current_prob_threshold)]


# =============================================================================
# å¢å¼ºæ¨¡å‹è¯¦æƒ…GUI - åŒ…å«å•æ¨¡å‹ç­›é€‰åŠŸèƒ½
# =============================================================================

class EnhancedModelDetailsAnalyzerGUI:
    """å¢å¼ºæ¨¡å‹è¯¦æƒ…GUI - åŒ…å«å•æ¨¡å‹ç­›é€‰åŠŸèƒ½"""

    def __init__(self, root):
        self.root = root
        self.analyzer = EnhancedThresholdAnalyzer()
        self.current_figure = None

        # çŠ¶æ€å˜é‡
        self.status_var = tk.StringVar(value="å‡†å¤‡å°±ç»ª")
        self.progress_var = tk.DoubleVar()
        self.data_info_var = tk.StringVar(value="æœªåŠ è½½æ•°æ®")
        self.result_dir_var = tk.StringVar()

        # å‚æ•°å˜é‡
        self.min_consensus_var = tk.IntVar(value=2)
        self.prob_threshold_var = tk.DoubleVar(value=0.6)
        self.conf_threshold_var = tk.DoubleVar(value=0.7)

        # æ­£ä¾‹é¢„æµ‹é˜ˆå€¼å˜é‡
        self.positive_prediction_threshold_var = tk.DoubleVar(value=0.5)
        self.positive_prediction_entry_var = tk.StringVar(value="0.500")

        # ç›´æ¥è¾“å…¥çš„å˜é‡
        self.prob_entry_var = tk.StringVar(value="0.60")
        self.conf_entry_var = tk.StringVar(value="0.70")

        # æ–°å¢ï¼šæ¨¡å‹é€‰æ‹©å˜é‡
        self.selected_model_var = tk.StringVar()

        # é…ç½®çª—å£
        self.setup_main_window()
        self.setup_styles()
        self.create_widgets()

    def setup_main_window(self):
        """é…ç½®ä¸»çª—å£"""
        self.root.title("ğŸ¯ å¢å¼ºæ¨¡å‹è¯¦æƒ…é¢„æµ‹ç»“æœåˆ†æå™¨ v3.5 - åŒ…å«å•æ¨¡å‹ç­›é€‰")
        self.root.geometry("1600x1000")
        self.root.minsize(1400, 900)

        self.root.grid_rowconfigure(0, weight=1)
        self.root.grid_columnconfigure(0, weight=1)

    def setup_styles(self):
        """é…ç½®æ ·å¼"""
        style = ttk.Style()
        if 'clam' in style.theme_names():
            style.theme_use('clam')

        style.configure('Title.TLabel', font=('Arial', 16, 'bold'))
        style.configure('Success.TLabel', foreground='green')
        style.configure('Error.TLabel', foreground='red')
        style.configure('Warning.TLabel', foreground='orange')
        style.configure('Highlight.TLabel', foreground='blue', font=('Arial', 10, 'bold'))
        style.configure('Model.TLabel', foreground='purple', font=('Arial', 9, 'bold'))

    def create_widgets(self):
        """åˆ›å»ºç•Œé¢ç»„ä»¶"""
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        main_frame.grid_rowconfigure(1, weight=1)
        main_frame.grid_columnconfigure(1, weight=1)

        self.create_header(main_frame)
        self.create_main_content(main_frame)
        self.create_status_bar(main_frame)

    def create_header(self, parent):
        """åˆ›å»ºæ ‡é¢˜æ """
        header_frame = ttk.Frame(parent)
        header_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        header_frame.grid_columnconfigure(1, weight=1)

        title_label = ttk.Label(header_frame, text="ğŸ¯ å¢å¼ºæ¨¡å‹è¯¦æƒ…é¢„æµ‹ç»“æœåˆ†æå™¨ v3.5", style='Title.TLabel')
        title_label.grid(row=0, column=0, sticky=tk.W)

        info_label = ttk.Label(header_frame,
                               text=f"åŒ…å«å•æ¨¡å‹ç­›é€‰ | ç”¨æˆ·: woyaokaoyanhaha | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        info_label.grid(row=0, column=1, sticky=tk.E)

        separator = ttk.Separator(header_frame, orient='horizontal')
        separator.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(5, 0))

    def create_main_content(self, parent):
        """åˆ›å»ºä¸»è¦å†…å®¹"""
        self.create_scrollable_control_panel(parent)
        self.create_display_area(parent)

    def create_scrollable_control_panel(self, parent):
        """åˆ›å»ºå¯æ»šåŠ¨çš„æ§åˆ¶é¢æ¿"""
        # åˆ›å»ºæ§åˆ¶é¢æ¿å¤–æ¡†
        control_outer_frame = ttk.LabelFrame(parent, text="ğŸ“Š æ§åˆ¶é¢æ¿ (å¯æ»šåŠ¨)", padding="5")
        control_outer_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), padx=(0, 10))
        control_outer_frame.grid_rowconfigure(0, weight=1)
        control_outer_frame.grid_columnconfigure(0, weight=1)

        # è®¾ç½®å›ºå®šå®½åº¦
        control_outer_frame.configure(width=420)

        # åˆ›å»ºå¯æ»šåŠ¨æ¡†æ¶
        self.scrollable_control = ScrollableFrame(control_outer_frame)
        self.scrollable_control.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # åœ¨å¯æ»šåŠ¨æ¡†æ¶å†…åˆ›å»ºæ§åˆ¶å†…å®¹
        self.create_control_content(self.scrollable_control.scrollable_frame)

    def create_control_content(self, parent):
        """åœ¨å¯æ»šåŠ¨æ¡†æ¶å†…åˆ›å»ºæ§åˆ¶å†…å®¹"""
        # æ–‡ä»¶åŠ è½½åŒºåŸŸ
        self.create_file_section(parent)

        # æ­£ä¾‹é¢„æµ‹é˜ˆå€¼è®¾ç½®åŒºåŸŸï¼ˆé‡ç‚¹ï¼‰
        self.create_positive_threshold_section(parent)

        # å…¶ä»–å‚æ•°è®¾ç½®åŒºåŸŸ
        self.create_other_parameters_section(parent)

        # æ–°å¢ï¼šå•æ¨¡å‹é€‰æ‹©åŒºåŸŸ
        self.create_model_selection_section(parent)

        # åˆ†æåŠŸèƒ½åŒºåŸŸ
        self.create_analysis_section(parent)

        # å¯¼å‡ºåŠŸèƒ½åŒºåŸŸ
        self.create_export_section(parent)

    def create_file_section(self, parent):
        """åˆ›å»ºæ–‡ä»¶åŠ è½½åŒºåŸŸ"""
        file_frame = ttk.LabelFrame(parent, text="ğŸ“ å¿«é€Ÿæ•°æ®åŠ è½½")
        file_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        file_frame.grid_columnconfigure(1, weight=1)

        # ç›®å½•é€‰æ‹©
        ttk.Label(file_frame, text="é¢„æµ‹ç»“æœç›®å½•:").grid(row=0, column=0, sticky=tk.W, padx=(5, 5))

        result_dir_entry = ttk.Entry(file_frame, textvariable=self.result_dir_var, width=25)
        result_dir_entry.grid(row=0, column=1, sticky=(tk.W, tk.E), padx=(0, 5))

        browse_btn = ttk.Button(file_frame, text="æµè§ˆ", command=self.browse_result_dir)
        browse_btn.grid(row=0, column=2, padx=(0, 5))

        # å¿«é€Ÿæ“ä½œæŒ‰é’®
        quick_scan_btn = ttk.Button(file_frame, text="ğŸ” å¿«é€Ÿæ‰«æ", command=self.quick_scan)
        quick_scan_btn.grid(row=1, column=0, pady=(5, 0), sticky=(tk.W, tk.E))

        load_btn = ttk.Button(file_frame, text="âš¡ å¿«é€ŸåŠ è½½", command=self.fast_load_data)
        load_btn.grid(row=1, column=1, columnspan=2, pady=(5, 0), sticky=(tk.W, tk.E))

        # çŠ¶æ€æ˜¾ç¤º
        self.load_status_label = ttk.Label(file_frame, text="", style='Success.TLabel', font=('Arial', 8))
        self.load_status_label.grid(row=2, column=0, columnspan=3, pady=(5, 0))

        # æ•°æ®ä¿¡æ¯
        info_label = ttk.Label(file_frame, textvariable=self.data_info_var, font=('Arial', 8), wraplength=350)
        info_label.grid(row=3, column=0, columnspan=3, pady=(5, 0))

    def create_positive_threshold_section(self, parent):
        """åˆ›å»ºæ­£ä¾‹é¢„æµ‹é˜ˆå€¼è®¾ç½®åŒºåŸŸ"""
        threshold_frame = ttk.LabelFrame(parent, text="ğŸ¯ æ­£ä¾‹é¢„æµ‹é˜ˆå€¼ (æ ¸å¿ƒå‚æ•°)", padding="8")
        threshold_frame.grid(row=1, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        threshold_frame.grid_columnconfigure(1, weight=1)

        # è¯´æ˜æ ‡ç­¾
        explanation_label = ttk.Label(threshold_frame,
                                      text="è®¾ç½® probability_1 â‰¥ é˜ˆå€¼æ—¶è®¤ä¸ºé¢„æµ‹ä¸ºæ­£ä¾‹",
                                      font=('Arial', 9), style='Highlight.TLabel')
        explanation_label.grid(row=0, column=0, columnspan=3, pady=(0, 5), sticky=tk.W)

        # æ­£ä¾‹é¢„æµ‹é˜ˆå€¼è®¾ç½®
        ttk.Label(threshold_frame, text="æ­£ä¾‹é¢„æµ‹é˜ˆå€¼:", font=('Arial', 9, 'bold')).grid(row=1, column=0, sticky=tk.W,
                                                                                         padx=(5, 5))

        # æ»‘å—
        pos_pred_scale = ttk.Scale(threshold_frame, from_=0.1, to=0.9, variable=self.positive_prediction_threshold_var,
                                   orient=tk.HORIZONTAL, length=120)
        pos_pred_scale.grid(row=1, column=1, sticky=(tk.W, tk.E), padx=(0, 5))

        # ç›´æ¥è¾“å…¥æ¡†
        pos_pred_entry = ttk.Entry(threshold_frame, textvariable=self.positive_prediction_entry_var, width=8)
        pos_pred_entry.grid(row=1, column=2, padx=(5, 0))

        # åŒæ­¥æŒ‰é’®
        pos_pred_sync_btn = ttk.Button(threshold_frame, text="â†”", width=3,
                                       command=self.sync_positive_prediction_from_entry)
        pos_pred_sync_btn.grid(row=2, column=2, pady=(2, 0))

        # å¿«é€Ÿè®¾ç½®æŒ‰é’®æ¡†æ¶
        quick_frame = ttk.Frame(threshold_frame)
        quick_frame.grid(row=3, column=0, columnspan=3, pady=(8, 0), sticky=(tk.W, tk.E))

        ttk.Label(quick_frame, text="å¿«é€Ÿè®¾ç½®:", font=('Arial', 8)).pack(side=tk.LEFT, padx=(0, 5))

        threshold_buttons = [
            ("ä¸¥æ ¼(0.7)", lambda: self.set_quick_positive_threshold(0.7)),
            ("ä¸­ç­‰(0.5)", lambda: self.set_quick_positive_threshold(0.5)),
            ("å®½æ¾(0.3)", lambda: self.set_quick_positive_threshold(0.3))
        ]

        for text, command in threshold_buttons:
            btn = ttk.Button(quick_frame, text=text, command=command, width=8)
            btn.pack(side=tk.LEFT, padx=1)

        # é‡æ–°åˆ†ææŒ‰é’®
        reanalyze_btn = ttk.Button(threshold_frame, text="ğŸ”„ é‡æ–°åˆ†æ", command=self.reanalyze_with_threshold)
        reanalyze_btn.grid(row=4, column=0, columnspan=3, pady=(8, 0), sticky=(tk.W, tk.E))

        # ç»‘å®šæ»‘å—æ›´æ–°äº‹ä»¶
        def update_positive_prediction_entry(*args):
            self.positive_prediction_entry_var.set(f"{self.positive_prediction_threshold_var.get():.3f}")

        self.positive_prediction_threshold_var.trace('w', update_positive_prediction_entry)

        # ç»‘å®šè¾“å…¥æ¡†å›è½¦äº‹ä»¶
        pos_pred_entry.bind('<Return>', lambda e: self.sync_positive_prediction_from_entry())

    def create_other_parameters_section(self, parent):
        """åˆ›å»ºå…¶ä»–å‚æ•°è®¾ç½®åŒºåŸŸ"""
        param_frame = ttk.LabelFrame(parent, text="âš™ï¸ å…¶ä»–ç­›é€‰å‚æ•°", padding="8")
        param_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        param_frame.grid_columnconfigure(1, weight=1)

        # æœ€å°å…±è¯†æ¨¡å‹æ•°
        ttk.Label(param_frame, text="æœ€å°å…±è¯†æ¨¡å‹æ•°:", font=('Arial', 9)).grid(row=0, column=0, sticky=tk.W,
                                                                               padx=(5, 5))
        consensus_spin = ttk.Spinbox(param_frame, from_=1, to=10, textvariable=self.min_consensus_var, width=8)
        consensus_spin.grid(row=0, column=1, sticky=tk.W, padx=(0, 5))

        # æ¦‚ç‡é˜ˆå€¼
        ttk.Label(param_frame, text="æ¦‚ç‡é˜ˆå€¼:", font=('Arial', 9)).grid(row=1, column=0, sticky=tk.W, padx=(5, 5))

        prob_scale = ttk.Scale(param_frame, from_=0.0, to=1.0, variable=self.prob_threshold_var,
                               orient=tk.HORIZONTAL, length=100)
        prob_scale.grid(row=1, column=1, sticky=(tk.W, tk.E), padx=(0, 5))

        prob_entry = ttk.Entry(param_frame, textvariable=self.prob_entry_var, width=8)
        prob_entry.grid(row=1, column=2, padx=(5, 0))

        prob_sync_btn = ttk.Button(param_frame, text="â†”", width=3,
                                   command=self.sync_prob_from_entry)
        prob_sync_btn.grid(row=2, column=2, pady=(2, 0))

        # ç½®ä¿¡åº¦é˜ˆå€¼
        ttk.Label(param_frame, text="ç½®ä¿¡åº¦é˜ˆå€¼:", font=('Arial', 9)).grid(row=3, column=0, sticky=tk.W, padx=(5, 5))

        conf_scale = ttk.Scale(param_frame, from_=0.0, to=1.0, variable=self.conf_threshold_var,
                               orient=tk.HORIZONTAL, length=100)
        conf_scale.grid(row=3, column=1, sticky=(tk.W, tk.E), padx=(0, 5))

        conf_entry = ttk.Entry(param_frame, textvariable=self.conf_entry_var, width=8)
        conf_entry.grid(row=3, column=2, padx=(5, 0))

        conf_sync_btn = ttk.Button(param_frame, text="â†”", width=3,
                                   command=self.sync_conf_from_entry)
        conf_sync_btn.grid(row=4, column=2, pady=(2, 0))

        # ç»‘å®šæ»‘å—æ›´æ–°äº‹ä»¶
        def update_prob_entry(*args):
            self.prob_entry_var.set(f"{self.prob_threshold_var.get():.3f}")

        self.prob_threshold_var.trace('w', update_prob_entry)

        def update_conf_entry(*args):
            self.conf_entry_var.set(f"{self.conf_threshold_var.get():.3f}")

        self.conf_threshold_var.trace('w', update_conf_entry)

        # ç»‘å®šè¾“å…¥æ¡†å›è½¦äº‹ä»¶
        prob_entry.bind('<Return>', lambda e: self.sync_prob_from_entry())
        conf_entry.bind('<Return>', lambda e: self.sync_conf_from_entry())

        # åº”ç”¨æ‰€æœ‰å‚æ•°æŒ‰é’®
        apply_btn = ttk.Button(param_frame, text="âœ… åº”ç”¨æ‰€æœ‰å‚æ•°", command=self.apply_parameters)
        apply_btn.grid(row=5, column=0, columnspan=3, pady=(10, 0), sticky=(tk.W, tk.E))

    def create_model_selection_section(self, parent):
        """æ–°å¢ï¼šåˆ›å»ºå•æ¨¡å‹é€‰æ‹©åŒºåŸŸ"""
        model_frame = ttk.LabelFrame(parent, text="ğŸ¤– å•æ¨¡å‹ç­›é€‰åˆ†æ", padding="8")
        model_frame.grid(row=3, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        model_frame.grid_columnconfigure(1, weight=1)

        # è¯´æ˜æ ‡ç­¾
        explanation_label = ttk.Label(model_frame,
                                      text="æŸ¥çœ‹å•ä¸ªæ¨¡å‹ç­›é€‰å‡ºçš„å¤§äºé˜ˆå€¼çš„åŒ–åˆç‰©",
                                      font=('Arial', 9), style='Model.TLabel')
        explanation_label.grid(row=0, column=0, columnspan=3, pady=(0, 5), sticky=tk.W)

        # æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
        ttk.Label(model_frame, text="é€‰æ‹©æ¨¡å‹:", font=('Arial', 9)).grid(row=1, column=0, sticky=tk.W, padx=(5, 5))

        self.model_combobox = ttk.Combobox(model_frame, textvariable=self.selected_model_var,
                                           width=25, state="readonly")
        self.model_combobox.grid(row=1, column=1, columnspan=2, sticky=(tk.W, tk.E), padx=(0, 5))

        # å•æ¨¡å‹åˆ†ææŒ‰é’®
        model_analysis_buttons = [
            ("ğŸ“Š å•æ¨¡å‹ç»Ÿè®¡", self.show_individual_model_stats),
            ("ğŸ“‹ æ¨¡å‹ç­›é€‰æ±‡æ€»", self.show_model_filtering_summary),
            ("ğŸ¯ æŸ¥çœ‹ç­›é€‰ç»“æœ", self.show_model_filtered_compounds)
        ]

        for i, (text, command) in enumerate(model_analysis_buttons):
            btn = ttk.Button(model_frame, text=text, command=command)
            btn.grid(row=i + 2, column=0, columnspan=3, pady=2, sticky=(tk.W, tk.E))

    def create_analysis_section(self, parent):
        """åˆ›å»ºåˆ†æåŠŸèƒ½åŒºåŸŸ"""
        analysis_frame = ttk.LabelFrame(parent, text="ğŸ” ç»¼åˆåˆ†æåŠŸèƒ½", padding="8")
        analysis_frame.grid(row=4, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        analysis_frame.grid_columnconfigure(0, weight=1)

        buttons = [
            ("ğŸ“Š åŸºç¡€ç»Ÿè®¡", self.show_basic_stats),
            ("ğŸ¯ å…±è¯†åˆ†æ", self.show_consensus_analysis),
            ("ğŸ“ˆ é˜ˆå€¼æ•æ„Ÿæ€§", self.show_threshold_sensitivity),
            ("ğŸ¨ åˆ†å¸ƒå›¾", self.show_distribution_plots)
        ]

        for i, (text, command) in enumerate(buttons):
            btn = ttk.Button(analysis_frame, text=text, command=command)
            btn.grid(row=i, column=0, sticky=(tk.W, tk.E), pady=2)

    def create_export_section(self, parent):
        """åˆ›å»ºå¯¼å‡ºåŠŸèƒ½åŒºåŸŸ"""
        export_frame = ttk.LabelFrame(parent, text="ğŸ’¾ å¯¼å‡ºåŠŸèƒ½", padding="8")
        export_frame.grid(row=5, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        export_frame.grid_columnconfigure(0, weight=1)

        export_buttons = [
            ("ğŸ“‹ ç”Ÿæˆåˆ†ææŠ¥å‘Š", self.generate_enhanced_report),
            ("ğŸ“ ç®€å•ç»“æœå¯¼å‡º", self.export_simple_results),
            ("ğŸ” è¯¦ç»†ç»“æœå¯¼å‡º", self.export_detailed_results),
            ("ğŸ¤– å•æ¨¡å‹ç­›é€‰å¯¼å‡º", self.export_individual_model_results),  # æ–°å¢
            ("ğŸ–¼ï¸ ä¿å­˜å½“å‰å›¾è¡¨", self.save_current_plot)
        ]

        for i, (text, command) in enumerate(export_buttons):
            btn = ttk.Button(export_frame, text=text, command=command)
            btn.grid(row=i, column=0, sticky=(tk.W, tk.E), pady=2)

    def create_display_area(self, parent):
        """åˆ›å»ºæ˜¾ç¤ºåŒºåŸŸ"""
        display_frame = ttk.Frame(parent)
        display_frame.grid(row=1, column=1, sticky=(tk.W, tk.E, tk.N, tk.S))
        display_frame.grid_rowconfigure(0, weight=1)
        display_frame.grid_columnconfigure(0, weight=1)

        self.notebook = ttk.Notebook(display_frame)
        self.notebook.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # å›¾è¡¨æ ‡ç­¾é¡µ
        plot_frame = ttk.Frame(self.notebook)
        self.notebook.add(plot_frame, text="ğŸ“Š å›¾è¡¨")

        self.figure = Figure(figsize=(12, 8), dpi=100)
        self.canvas = FigureCanvasTkAgg(self.figure, plot_frame)
        self.canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)

        # æ·»åŠ å·¥å…·æ 
        toolbar_frame = ttk.Frame(plot_frame)
        toolbar_frame.pack(fill=tk.X)

        self.toolbar = NavigationToolbar2Tk(self.canvas, toolbar_frame)
        self.toolbar.update()

        # æ–°å¢ï¼šå•æ¨¡å‹æ•°æ®è¡¨æ ¼æ ‡ç­¾é¡µ
        model_table_frame = ttk.Frame(self.notebook)
        self.notebook.add(model_table_frame, text="ğŸ¤– å•æ¨¡å‹æ•°æ®")

        # åˆ›å»ºå•æ¨¡å‹æ ‘å½¢è§†å›¾
        self.model_tree = ttk.Treeview(model_table_frame, show='headings')

        # å•æ¨¡å‹æ»šåŠ¨æ¡
        model_v_scrollbar = ttk.Scrollbar(model_table_frame, orient=tk.VERTICAL, command=self.model_tree.yview)
        model_h_scrollbar = ttk.Scrollbar(model_table_frame, orient=tk.HORIZONTAL, command=self.model_tree.xview)

        self.model_tree.configure(yscrollcommand=model_v_scrollbar.set, xscrollcommand=model_h_scrollbar.set)

        # å¸ƒå±€
        self.model_tree.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        model_v_scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))
        model_h_scrollbar.grid(row=1, column=0, sticky=(tk.W, tk.E))

        model_table_frame.grid_rowconfigure(0, weight=1)
        model_table_frame.grid_columnconfigure(0, weight=1)

        # ä¿¡æ¯æ ‡ç­¾é¡µ
        info_frame = ttk.Frame(self.notebook)
        self.notebook.add(info_frame, text="â„¹ï¸ è¯¦ç»†ä¿¡æ¯")

        self.info_text = scrolledtext.ScrolledText(info_frame, wrap=tk.WORD, font=('Consolas', 10))
        self.info_text.pack(fill=tk.BOTH, expand=True)

        self.show_welcome_info()

    def create_status_bar(self, parent):
        """åˆ›å»ºçŠ¶æ€æ """
        status_frame = ttk.Frame(parent)
        status_frame.grid(row=2, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(10, 0))
        status_frame.grid_columnconfigure(1, weight=1)

        ttk.Label(status_frame, text="çŠ¶æ€:").grid(row=0, column=0, padx=(0, 5))
        status_label = ttk.Label(status_frame, textvariable=self.status_var)
        status_label.grid(row=0, column=1, sticky=tk.W)

        self.progress_bar = ttk.Progressbar(status_frame, variable=self.progress_var, mode='determinate', length=200)
        self.progress_bar.grid(row=0, column=2, padx=(10, 0))

    # ===============================
    # å‚æ•°åŒæ­¥å‡½æ•°
    # ===============================

    def sync_positive_prediction_from_entry(self):
        """ä»è¾“å…¥æ¡†åŒæ­¥æ­£ä¾‹é¢„æµ‹é˜ˆå€¼åˆ°æ»‘å—"""
        try:
            value = float(self.positive_prediction_entry_var.get())
            if 0.1 <= value <= 0.9:
                self.positive_prediction_threshold_var.set(value)
            else:
                messagebox.showwarning("è¾“å…¥é”™è¯¯", "æ­£ä¾‹é¢„æµ‹é˜ˆå€¼å¿…é¡»åœ¨0.1-0.9ä¹‹é—´")
                self.positive_prediction_entry_var.set(f"{self.positive_prediction_threshold_var.get():.3f}")
        except ValueError:
            messagebox.showwarning("è¾“å…¥é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å€¼")
            self.positive_prediction_entry_var.set(f"{self.positive_prediction_threshold_var.get():.3f}")

    def sync_prob_from_entry(self):
        """ä»è¾“å…¥æ¡†åŒæ­¥æ¦‚ç‡é˜ˆå€¼åˆ°æ»‘å—"""
        try:
            value = float(self.prob_entry_var.get())
            if 0.0 <= value <= 1.0:
                self.prob_threshold_var.set(value)
            else:
                messagebox.showwarning("è¾“å…¥é”™è¯¯", "æ¦‚ç‡é˜ˆå€¼å¿…é¡»åœ¨0.0-1.0ä¹‹é—´")
                self.prob_entry_var.set(f"{self.prob_threshold_var.get():.3f}")
        except ValueError:
            messagebox.showwarning("è¾“å…¥é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å€¼")
            self.prob_entry_var.set(f"{self.prob_threshold_var.get():.3f}")

    def sync_conf_from_entry(self):
        """ä»è¾“å…¥æ¡†åŒæ­¥ç½®ä¿¡åº¦é˜ˆå€¼åˆ°æ»‘å—"""
        try:
            value = float(self.conf_entry_var.get())
            if 0.0 <= value <= 1.0:
                self.conf_threshold_var.set(value)
            else:
                messagebox.showwarning("è¾“å…¥é”™è¯¯", "ç½®ä¿¡åº¦é˜ˆå€¼å¿…é¡»åœ¨0.0-1.0ä¹‹é—´")
                self.conf_entry_var.set(f"{self.conf_threshold_var.get():.3f}")
        except ValueError:
            messagebox.showwarning("è¾“å…¥é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å€¼")
            self.conf_entry_var.set(f"{self.conf_threshold_var.get():.3f}")

    def set_quick_positive_threshold(self, threshold):
        """å¿«é€Ÿè®¾ç½®æ­£ä¾‹é¢„æµ‹é˜ˆå€¼"""
        self.positive_prediction_threshold_var.set(threshold)
        self.positive_prediction_entry_var.set(f"{threshold:.3f}")
        messagebox.showinfo("é˜ˆå€¼è®¾ç½®", f"å·²è®¾ç½®æ­£ä¾‹é¢„æµ‹é˜ˆå€¼={threshold:.3f}\n\nç‚¹å‡»'ğŸ”„ é‡æ–°åˆ†æ'æŒ‰é’®åº”ç”¨æ–°é˜ˆå€¼")

    def reanalyze_with_threshold(self):
        """ä½¿ç”¨æ–°çš„æ­£ä¾‹é¢„æµ‹é˜ˆå€¼é‡æ–°åˆ†æ"""
        if len(self.analyzer.compound_stats) == 0:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½æ•°æ®")
            return

        new_threshold = self.positive_prediction_threshold_var.get()

        self.status_var.set(f"é‡æ–°åˆ†æä¸­ï¼Œæ­£ä¾‹é¢„æµ‹é˜ˆå€¼: {new_threshold:.3f}...")

        try:
            success = self.analyzer.reanalyze_with_new_threshold(new_threshold)

            if success:
                # æ›´æ–°æ˜¾ç¤ºä¿¡æ¯
                summary = self.analyzer.get_summary_info()
                info_text = f"âœ… é‡æ–°åˆ†æå®Œæˆ | åŒ–åˆç‰©: {summary['total_compounds']:,} | æ¨¡å‹: {summary['total_models']} | æ­£ä¾‹é˜ˆå€¼: {summary['positive_prediction_threshold']:.3f}"
                self.data_info_var.set(info_text)

                # æ›´æ–°æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
                self.update_model_combobox()

                # åˆ·æ–°å›¾è¡¨
                self.show_basic_stats()

                # æ›´æ–°ä¿¡æ¯æ˜¾ç¤º
                self.update_info_display()

                self.status_var.set("é‡æ–°åˆ†æå®Œæˆ")
                messagebox.showinfo("æˆåŠŸ",
                                    f"å·²ä½¿ç”¨æ–°çš„æ­£ä¾‹é¢„æµ‹é˜ˆå€¼ {new_threshold:.3f} é‡æ–°åˆ†ææ•°æ®\n\nå•æ¨¡å‹ç­›é€‰ç»“æœå·²æ›´æ–°")
            else:
                messagebox.showerror("é”™è¯¯", "é‡æ–°åˆ†æå¤±è´¥")
                self.status_var.set("é‡æ–°åˆ†æå¤±è´¥")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"é‡æ–°åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            self.status_var.set("é‡æ–°åˆ†æå¤±è´¥")

    def update_model_combobox(self):
        """æ›´æ–°æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†"""
        if hasattr(self, 'model_combobox') and self.analyzer.individual_model_results:
            model_list = list(self.analyzer.individual_model_results.keys())
            self.model_combobox['values'] = model_list
            if model_list and not self.selected_model_var.get():
                self.selected_model_var.set(model_list[0])

    # ===============================
    # äº‹ä»¶å¤„ç†å‡½æ•°
    # ===============================

    def browse_result_dir(self):
        """æµè§ˆç›®å½•"""
        directory = filedialog.askdirectory(title="é€‰æ‹©é¢„æµ‹ç»“æœç›®å½•", initialdir=os.getcwd())
        if directory:
            self.result_dir_var.set(directory)

    def quick_scan(self):
        """å¿«é€Ÿæ‰«æ"""
        result_dir = self.result_dir_var.get().strip()

        if not result_dir:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©ç›®å½•")
            return

        if not os.path.exists(result_dir):
            messagebox.showerror("é”™è¯¯", f"ç›®å½•ä¸å­˜åœ¨: {result_dir}")
            return

        self.status_var.set("æ­£åœ¨å¿«é€Ÿæ‰«æ...")

        try:
            prediction_files = self.analyzer.quick_scan_directory(result_dir)

            if prediction_files:
                total_files = sum(len(models) for models in prediction_files.values())
                info_msg = f"å¿«é€Ÿæ‰«æå®Œæˆï¼\n"
                info_msg += f"å‘ç° {len(prediction_files)} ä¸ªæ¨¡å‹ç±»å‹\n"
                info_msg += f"æ€»è®¡ {total_files} ä¸ªé¢„æµ‹æ–‡ä»¶\n\n"

                for model_type, models in prediction_files.items():
                    info_msg += f"â€¢ {model_type}: {len(models)} ä¸ªæ¨¡å‹\n"

                self.load_status_label.config(text=f"âœ… å‘ç° {total_files} ä¸ªæ–‡ä»¶")
                messagebox.showinfo("å¿«é€Ÿæ‰«æç»“æœ", info_msg)
            else:
                self.load_status_label.config(text="âŒ æœªå‘ç°é¢„æµ‹æ–‡ä»¶")
                messagebox.showwarning("æ‰«æç»“æœ", "æœªå‘ç°æœ‰æ•ˆçš„é¢„æµ‹æ–‡ä»¶")

            self.status_var.set("æ‰«æå®Œæˆ")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"æ‰«æå¤±è´¥: {e}")
            self.status_var.set("æ‰«æå¤±è´¥")

    def fast_load_data(self):
        """å¿«é€ŸåŠ è½½æ•°æ®"""
        result_dir = self.result_dir_var.get().strip()

        if not result_dir:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©ç›®å½•")
            return

        if not os.path.exists(result_dir):
            messagebox.showerror("é”™è¯¯", f"ç›®å½•ä¸å­˜åœ¨: {result_dir}")
            return

        # åœ¨åå°çº¿ç¨‹ä¸­åŠ è½½
        def load_thread():
            try:
                def progress_callback(message):
                    self.root.after(0, lambda: self.status_var.set(message))

                success = self.analyzer.load_prediction_results(result_dir, progress_callback)
                self.root.after(0, self.on_data_loaded, success)

            except Exception as e:
                self.root.after(0, self.on_data_load_error, str(e))

        self.status_var.set("æ­£åœ¨å¿«é€ŸåŠ è½½æ•°æ®...")
        self.progress_var.set(0)

        thread = threading.Thread(target=load_thread, daemon=True)
        thread.start()

    def on_data_loaded(self, success):
        """æ•°æ®åŠ è½½å®Œæˆ"""
        if success:
            summary = self.analyzer.get_summary_info()

            info_text = f"âœ… å¿«é€ŸåŠ è½½æˆåŠŸ | åŒ–åˆç‰©: {summary['total_compounds']:,} | æ¨¡å‹: {summary['total_models']} | æ­£ä¾‹é˜ˆå€¼: {summary['positive_prediction_threshold']:.3f}"
            self.data_info_var.set(info_text)
            self.load_status_label.config(text="âœ… æ•°æ®åŠ è½½æˆåŠŸ")
            self.status_var.set("åŠ è½½å®Œæˆ")

            # æ›´æ–°æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
            self.update_model_combobox()

            self.update_info_display()
            self.show_basic_stats()

        else:
            self.data_info_var.set("âŒ æ•°æ®åŠ è½½å¤±è´¥")
            self.load_status_label.config(text="âŒ åŠ è½½å¤±è´¥")
            self.status_var.set("åŠ è½½å¤±è´¥")
            messagebox.showerror("é”™è¯¯", "æ•°æ®åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›®å½•å’Œæ–‡ä»¶æ ¼å¼")

        self.progress_var.set(100)

    def on_data_load_error(self, error_msg):
        """åŠ è½½é”™è¯¯å¤„ç†"""
        self.data_info_var.set("âŒ æ•°æ®åŠ è½½å¤±è´¥")
        self.load_status_label.config(text="âŒ åŠ è½½é”™è¯¯")
        self.status_var.set("åŠ è½½å¤±è´¥")
        messagebox.showerror("é”™è¯¯", f"æ•°æ®åŠ è½½å¤±è´¥: {error_msg}")
        self.progress_var.set(0)

    def apply_parameters(self):
        """åº”ç”¨æ‰€æœ‰å‚æ•°"""
        if len(self.analyzer.compound_stats) == 0:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½æ•°æ®")
            return

        # åº”ç”¨æ‰€æœ‰å‚æ•°
        self.analyzer.current_min_consensus = self.min_consensus_var.get()
        self.analyzer.current_prob_threshold = self.prob_threshold_var.get()
        self.analyzer.current_conf_threshold = self.conf_threshold_var.get()

        # åº”ç”¨æ­£ä¾‹é¢„æµ‹é˜ˆå€¼å¹¶é‡æ–°åˆ†æ
        new_threshold = self.positive_prediction_threshold_var.get()
        self.analyzer.reanalyze_with_new_threshold(new_threshold)

        # æ›´æ–°æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
        self.update_model_combobox()

        # æ›´æ–°æ˜¾ç¤º
        summary = self.analyzer.get_summary_info()
        info_text = f"âœ… å‚æ•°å·²åº”ç”¨ | åŒ–åˆç‰©: {summary['total_compounds']:,} | æ¨¡å‹: {summary['total_models']} | æ­£ä¾‹é˜ˆå€¼: {summary['positive_prediction_threshold']:.3f}"
        self.data_info_var.set(info_text)

        self.status_var.set("æ‰€æœ‰å‚æ•°å·²æ›´æ–°")
        messagebox.showinfo("æˆåŠŸ", f"æ‰€æœ‰ç­›é€‰å‚æ•°å·²åº”ç”¨:\n"
                                    f"æ­£ä¾‹é¢„æµ‹é˜ˆå€¼: {new_threshold:.3f}\n"
                                    f"æœ€å°å…±è¯†æ¨¡å‹æ•°: {self.analyzer.current_min_consensus}\n"
                                    f"æ¦‚ç‡é˜ˆå€¼: {self.analyzer.current_prob_threshold:.3f}\n"
                                    f"ç½®ä¿¡åº¦é˜ˆå€¼: {self.analyzer.current_conf_threshold:.3f}\n\n"
                                    f"å•æ¨¡å‹ç­›é€‰ç»“æœå·²æ›´æ–°")

    def check_analyzer(self):
        """æ£€æŸ¥æ˜¯å¦å·²åŠ è½½æ•°æ®"""
        if len(self.analyzer.compound_stats) == 0:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½é¢„æµ‹æ•°æ®")
            return False
        return True

    # ===============================
    # åˆ†æåŠŸèƒ½
    # ===============================

    def show_basic_stats(self):
        """æ˜¾ç¤ºåŸºç¡€ç»Ÿè®¡"""
        if not self.check_analyzer():
            return

        self.status_var.set("ç”ŸæˆåŸºç¡€ç»Ÿè®¡...")

        self.figure.clear()

        # åˆ›å»º2x2å­å›¾
        fig = self.figure

        # è·å–æ•°æ®
        all_probs = [stats['avg_probability_1'] for stats in self.analyzer.compound_stats.values()]
        all_confs = [stats['avg_confidence'] for stats in self.analyzer.compound_stats.values()]
        all_ratios = [stats['positive_ratio'] for stats in self.analyzer.compound_stats.values()]

        # å­å›¾1: æ¦‚ç‡åˆ†å¸ƒç›´æ–¹å›¾
        ax1 = fig.add_subplot(221)
        ax1.hist(all_probs, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        ax1.axvline(self.analyzer.current_prob_threshold, color='red', linestyle='--',
                    label=f'æ¦‚ç‡é˜ˆå€¼ ({self.analyzer.current_prob_threshold:.3f})')
        ax1.axvline(self.analyzer.current_positive_prediction_threshold, color='blue', linestyle='-',
                    label=f'æ­£ä¾‹é¢„æµ‹é˜ˆå€¼ ({self.analyzer.current_positive_prediction_threshold:.3f})', linewidth=2)
        ax1.set_title('æ¦‚ç‡åˆ†å¸ƒ', fontsize=12)
        ax1.set_xlabel('å¹³å‡æ­£ä¾‹æ¦‚ç‡')
        ax1.set_ylabel('åŒ–åˆç‰©æ•°é‡')
        ax1.legend()
        ax1.grid(True, alpha=0.3)

        # å­å›¾2: ç½®ä¿¡åº¦åˆ†å¸ƒç›´æ–¹å›¾
        ax2 = fig.add_subplot(222)
        ax2.hist(all_confs, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
        ax2.axvline(self.analyzer.current_conf_threshold, color='red', linestyle='--',
                    label=f'ç½®ä¿¡åº¦é˜ˆå€¼ ({self.analyzer.current_conf_threshold:.3f})')
        ax2.set_title('ç½®ä¿¡åº¦åˆ†å¸ƒ', fontsize=12)
        ax2.set_xlabel('å¹³å‡ç½®ä¿¡åº¦')
        ax2.set_ylabel('åŒ–åˆç‰©æ•°é‡')
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        # å­å›¾3: æ­£ä¾‹æ¯”ä¾‹åˆ†å¸ƒ
        ax3 = fig.add_subplot(223)
        ax3.hist(all_ratios, bins=20, alpha=0.7, color='lightcoral', edgecolor='black')
        ax3.set_title(f'æ­£ä¾‹æ¯”ä¾‹åˆ†å¸ƒ (é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f})', fontsize=12)
        ax3.set_xlabel('æ­£ä¾‹é¢„æµ‹æ¯”ä¾‹')
        ax3.set_ylabel('åŒ–åˆç‰©æ•°é‡')
        ax3.grid(True, alpha=0.3)

        # å­å›¾4: æ¦‚ç‡vsç½®ä¿¡åº¦æ•£ç‚¹å›¾
        ax4 = fig.add_subplot(224)
        scatter = ax4.scatter(all_probs, all_confs, c=all_ratios, cmap='RdYlBu_r',
                              alpha=0.6, s=30)
        ax4.axhline(self.analyzer.current_conf_threshold, color='red', linestyle='--', alpha=0.7)
        ax4.axvline(self.analyzer.current_prob_threshold, color='red', linestyle='--', alpha=0.7)
        ax4.axvline(self.analyzer.current_positive_prediction_threshold, color='blue', linestyle='-', alpha=0.8,
                    linewidth=2)
        ax4.set_title('æ¦‚ç‡ vs ç½®ä¿¡åº¦', fontsize=12)
        ax4.set_xlabel('å¹³å‡æ­£ä¾‹æ¦‚ç‡')
        ax4.set_ylabel('å¹³å‡ç½®ä¿¡åº¦')
        ax4.grid(True, alpha=0.3)

        # æ·»åŠ é¢œè‰²æ¡
        cbar = fig.colorbar(scatter, ax=ax4)
        cbar.set_label('æ­£ä¾‹æ¯”ä¾‹')

        fig.tight_layout()
        self.canvas.draw()

        self.status_var.set("åŸºç¡€ç»Ÿè®¡å®Œæˆ")

    def show_consensus_analysis(self):
        """æ˜¾ç¤ºå…±è¯†åˆ†æ"""
        if not self.check_analyzer():
            return

        self.status_var.set("è¿›è¡Œå…±è¯†åˆ†æ...")

        # æ‰§è¡Œå…±è¯†åˆ†æ
        all_positive = self.analyzer._find_all_positive()
        majority_positive = self.analyzer._find_majority_positive()
        high_confidence = self.analyzer._find_high_confidence()
        high_probability = self.analyzer._find_high_probability()
        custom_consensus = self.analyzer._find_custom_consensus()

        self.figure.clear()
        ax = self.figure.add_subplot(111)

        categories = ['æ‰€æœ‰æ¨¡å‹\nä¸€è‡´', 'å¤§å¤šæ•°\nåŒæ„', 'é«˜ç½®ä¿¡åº¦', 'é«˜æ¦‚ç‡', 'ç»¼åˆ\nç­›é€‰']
        counts = [len(all_positive), len(majority_positive), len(high_confidence),
                  len(high_probability), len(custom_consensus)]
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']

        bars = ax.bar(categories, counts, color=colors, alpha=0.8, edgecolor='black')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, count in zip(bars, counts):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width() / 2., height + max(counts) * 0.01,
                    f'{count}', ha='center', va='bottom', fontweight='bold')

        ax.set_title(f'å…±è¯†åˆ†æç»“æœ (æ­£ä¾‹é¢„æµ‹é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f})',
                     fontsize=14, fontweight='bold')
        ax.set_ylabel('åŒ–åˆç‰©æ•°é‡')
        ax.grid(True, alpha=0.3, axis='y')

        self.figure.tight_layout()
        self.canvas.draw()

        # æ›´æ–°è¯¦ç»†ä¿¡æ¯
        self.update_consensus_info(all_positive, majority_positive, high_confidence,
                                   high_probability, custom_consensus)

        self.status_var.set("å…±è¯†åˆ†æå®Œæˆ")

    def show_threshold_sensitivity(self):
        """æ˜¾ç¤ºé˜ˆå€¼æ•æ„Ÿæ€§åˆ†æ"""
        if not self.check_analyzer():
            return

        self.status_var.set("åˆ†æé˜ˆå€¼æ•æ„Ÿæ€§...")

        self.figure.clear()

        # åˆ›å»ºå­å›¾
        fig = self.figure
        ax1 = fig.add_subplot(121)
        ax2 = fig.add_subplot(122)

        # æ¦‚ç‡é˜ˆå€¼æ•æ„Ÿæ€§
        prob_thresholds = np.arange(0.5, 1.0, 0.05)
        prob_counts = []

        for threshold in prob_thresholds:
            count = sum(1 for stats in self.analyzer.compound_stats.values()
                        if stats['avg_probability_1'] >= threshold and
                        stats['positive_predictions'] >= self.analyzer.current_min_consensus)
            prob_counts.append(count)

        ax1.plot(prob_thresholds, prob_counts, 'b-o', linewidth=2, markersize=6)
        ax1.axvline(self.analyzer.current_prob_threshold, color='red', linestyle='--',
                    label=f'å½“å‰é˜ˆå€¼ ({self.analyzer.current_prob_threshold:.2f})')
        ax1.axvline(self.analyzer.current_positive_prediction_threshold, color='blue', linestyle='-',
                    label=f'æ­£ä¾‹é¢„æµ‹é˜ˆå€¼ ({self.analyzer.current_positive_prediction_threshold:.2f})', linewidth=2)
        ax1.set_xlabel('æ¦‚ç‡é˜ˆå€¼')
        ax1.set_ylabel('ç¬¦åˆæ¡ä»¶çš„åŒ–åˆç‰©æ•°é‡')
        ax1.set_title('æ¦‚ç‡é˜ˆå€¼æ•æ„Ÿæ€§', fontsize=12)
        ax1.grid(True, alpha=0.3)
        ax1.legend()

        # ç½®ä¿¡åº¦é˜ˆå€¼æ•æ„Ÿæ€§
        conf_thresholds = np.arange(0.5, 1.0, 0.05)
        conf_counts = []

        for threshold in conf_thresholds:
            count = sum(1 for stats in self.analyzer.compound_stats.values()
                        if stats['avg_confidence'] >= threshold and
                        stats['positive_predictions'] >= self.analyzer.current_min_consensus)
            conf_counts.append(count)

        ax2.plot(conf_thresholds, conf_counts, 'g-o', linewidth=2, markersize=6)
        ax2.axvline(self.analyzer.current_conf_threshold, color='red', linestyle='--',
                    label=f'å½“å‰é˜ˆå€¼ ({self.analyzer.current_conf_threshold:.2f})')
        ax2.set_xlabel('ç½®ä¿¡åº¦é˜ˆå€¼')
        ax2.set_ylabel('ç¬¦åˆæ¡ä»¶çš„åŒ–åˆç‰©æ•°é‡')
        ax2.set_title('ç½®ä¿¡åº¦é˜ˆå€¼æ•æ„Ÿæ€§', fontsize=12)
        ax2.grid(True, alpha=0.3)
        ax2.legend()

        fig.tight_layout()
        self.canvas.draw()

        self.status_var.set("é˜ˆå€¼æ•æ„Ÿæ€§åˆ†æå®Œæˆ")

    def show_distribution_plots(self):
        """æ˜¾ç¤ºåˆ†å¸ƒå›¾"""
        if not self.check_analyzer():
            return

        self.status_var.set("ç”Ÿæˆåˆ†å¸ƒå›¾...")

        self.figure.clear()

        all_probs = [stats['avg_probability_1'] for stats in self.analyzer.compound_stats.values()]
        all_confs = [stats['avg_confidence'] for stats in self.analyzer.compound_stats.values()]
        all_ratios = [stats['positive_ratio'] for stats in self.analyzer.compound_stats.values()]

        # åˆ›å»ºå­å›¾
        fig = self.figure

        # å­å›¾1: æ¦‚ç‡åˆ†å¸ƒï¼ˆå¯†åº¦å›¾ï¼‰
        ax1 = fig.add_subplot(221)
        ax1.hist(all_probs, bins=30, density=True, alpha=0.7, color='skyblue')
        ax1.axvline(self.analyzer.current_prob_threshold, color='red', linestyle='--',
                    label=f'æ¦‚ç‡é˜ˆå€¼ ({self.analyzer.current_prob_threshold:.2f})')
        ax1.axvline(self.analyzer.current_positive_prediction_threshold, color='blue', linestyle='-',
                    label=f'æ­£ä¾‹é¢„æµ‹é˜ˆå€¼ ({self.analyzer.current_positive_prediction_threshold:.2f})', linewidth=2)
        ax1.set_title('æ¦‚ç‡å¯†åº¦åˆ†å¸ƒ')
        ax1.set_xlabel('å¹³å‡æ­£ä¾‹æ¦‚ç‡')
        ax1.set_ylabel('å¯†åº¦')
        ax1.legend()
        ax1.grid(True, alpha=0.3)

        # å­å›¾2: ç½®ä¿¡åº¦åˆ†å¸ƒï¼ˆå¯†åº¦å›¾ï¼‰
        ax2 = fig.add_subplot(222)
        ax2.hist(all_confs, bins=30, density=True, alpha=0.7, color='lightgreen')
        ax2.axvline(self.analyzer.current_conf_threshold, color='red', linestyle='--',
                    label=f'ç½®ä¿¡åº¦é˜ˆå€¼ ({self.analyzer.current_conf_threshold:.2f})')
        ax2.set_title('ç½®ä¿¡åº¦å¯†åº¦åˆ†å¸ƒ')
        ax2.set_xlabel('å¹³å‡ç½®ä¿¡åº¦')
        ax2.set_ylabel('å¯†åº¦')
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        # å­å›¾3: æ­£ä¾‹æ¯”ä¾‹é¥¼å›¾
        ax3 = fig.add_subplot(223)
        ratio_bins = [0, 0.25, 0.5, 0.75, 1.0]
        ratio_labels = ['0-25%', '25-50%', '50-75%', '75-100%']
        ratio_counts = []

        for i in range(len(ratio_bins) - 1):
            count = sum(1 for r in all_ratios if ratio_bins[i] <= r < ratio_bins[i + 1])
            ratio_counts.append(count)

        # æ·»åŠ 100%çš„åŒ–åˆç‰©
        ratio_counts[-1] += sum(1 for r in all_ratios if r == 1.0)

        colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFD700']
        wedges, texts, autotexts = ax3.pie(ratio_counts, labels=ratio_labels, colors=colors,
                                           autopct='%1.1f%%', startangle=90)
        ax3.set_title(f'æ­£ä¾‹æ¯”ä¾‹åˆ†å¸ƒ\n(é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f})')

        # å­å›¾4: ç®±çº¿å›¾
        ax4 = fig.add_subplot(224)
        data_to_plot = [all_probs, all_confs, all_ratios]
        box_plot = ax4.boxplot(data_to_plot, labels=['æ¦‚ç‡', 'ç½®ä¿¡åº¦', 'æ­£ä¾‹æ¯”ä¾‹'])

        # æ·»åŠ é˜ˆå€¼çº¿
        ax4.axhline(self.analyzer.current_positive_prediction_threshold, color='blue', linestyle='-',
                    alpha=0.7, linewidth=2,
                    label=f'æ­£ä¾‹é¢„æµ‹é˜ˆå€¼ ({self.analyzer.current_positive_prediction_threshold:.3f})')

        ax4.set_title('æ•°æ®åˆ†å¸ƒç®±çº¿å›¾')
        ax4.set_ylabel('æ•°å€¼')
        ax4.grid(True, alpha=0.3)
        ax4.legend()

        fig.tight_layout()
        self.canvas.draw()

        self.status_var.set("åˆ†å¸ƒå›¾ç”Ÿæˆå®Œæˆ")

    # ===============================
    # æ–°å¢ï¼šå•æ¨¡å‹åˆ†æåŠŸèƒ½
    # ===============================

    def show_individual_model_stats(self):
        """æ˜¾ç¤ºå•ä¸ªæ¨¡å‹ç»Ÿè®¡"""
        if not self.check_analyzer():
            return

        selected_model = self.selected_model_var.get()
        if not selected_model:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæ¨¡å‹")
            return

        if selected_model not in self.analyzer.individual_model_results:
            messagebox.showerror("é”™è¯¯", f"æœªæ‰¾åˆ°æ¨¡å‹ {selected_model} çš„æ•°æ®")
            return

        self.status_var.set(f"ç”Ÿæˆæ¨¡å‹ {selected_model} çš„ç»Ÿè®¡...")

        model_result = self.analyzer.individual_model_results[selected_model]

        self.figure.clear()
        fig = self.figure

        # åˆ›å»º2x2å­å›¾æ˜¾ç¤ºå•æ¨¡å‹ç»Ÿè®¡
        ax1 = fig.add_subplot(221)
        ax2 = fig.add_subplot(222)
        ax3 = fig.add_subplot(223)
        ax4 = fig.add_subplot(224)

        # å­å›¾1: ç­›é€‰ç»“æœé¥¼å›¾
        labels = ['ç­›é€‰å‡º', 'æœªç­›é€‰']
        sizes = [model_result['filtered_compounds'],
                 model_result['total_compounds'] - model_result['filtered_compounds']]
        colors = ['#FF6B6B', '#C0C0C0']

        ax1.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
        ax1.set_title(f'{model_result["model_name"]}\nç­›é€‰ç»“æœåˆ†å¸ƒ')

        # å­å›¾2: ç­›é€‰å‡ºåŒ–åˆç‰©çš„æ¦‚ç‡åˆ†å¸ƒ
        if model_result['filtered_data']:
            probs = [item['probability_1'] for item in model_result['filtered_data']]
            ax2.hist(probs, bins=15, alpha=0.7, color='skyblue', edgecolor='black')
            ax2.axvline(self.analyzer.current_positive_prediction_threshold, color='red', linestyle='--',
                        label=f'é˜ˆå€¼ ({self.analyzer.current_positive_prediction_threshold:.3f})')
            ax2.set_title('ç­›é€‰åŒ–åˆç‰©æ¦‚ç‡åˆ†å¸ƒ')
            ax2.set_xlabel('Probability_1')
            ax2.set_ylabel('åŒ–åˆç‰©æ•°é‡')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
        else:
            ax2.text(0.5, 0.5, 'æ— ç­›é€‰æ•°æ®', ha='center', va='center', transform=ax2.transAxes)
            ax2.set_title('ç­›é€‰åŒ–åˆç‰©æ¦‚ç‡åˆ†å¸ƒ')

        # å­å›¾3: ç­›é€‰å‡ºåŒ–åˆç‰©çš„ç½®ä¿¡åº¦åˆ†å¸ƒ
        if model_result['filtered_data']:
            confs = [item['confidence'] for item in model_result['filtered_data']]
            ax3.hist(confs, bins=15, alpha=0.7, color='lightgreen', edgecolor='black')
            ax3.set_title('ç­›é€‰åŒ–åˆç‰©ç½®ä¿¡åº¦åˆ†å¸ƒ')
            ax3.set_xlabel('Confidence')
            ax3.set_ylabel('åŒ–åˆç‰©æ•°é‡')
            ax3.grid(True, alpha=0.3)
        else:
            ax3.text(0.5, 0.5, 'æ— ç­›é€‰æ•°æ®', ha='center', va='center', transform=ax3.transAxes)
            ax3.set_title('ç­›é€‰åŒ–åˆç‰©ç½®ä¿¡åº¦åˆ†å¸ƒ')

        # å­å›¾4: ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬
        ax4.axis('off')
        stats_text = f"""æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯:
æ¨¡å‹ç±»å‹: {model_result['model_type']}
æ¨¡å‹åç§°: {model_result['model_name']}

æ€»åŒ–åˆç‰©æ•°: {model_result['total_compounds']:,}
ç­›é€‰å‡ºæ•°é‡: {model_result['filtered_compounds']:,}
ç­›é€‰æ¯”ä¾‹: {model_result['filtered_ratio']:.3f}

ç­›é€‰åŒ–åˆç‰©ç»Ÿè®¡:
å¹³å‡æ¦‚ç‡: {model_result['avg_probability_1']:.4f}
å¹³å‡ç½®ä¿¡åº¦: {model_result['avg_confidence']:.4f}
æœ€å¤§æ¦‚ç‡: {model_result['max_probability_1']:.4f}
æœ€å°æ¦‚ç‡: {model_result['min_probability_1']:.4f}

ä½¿ç”¨é˜ˆå€¼: {model_result['threshold_used']:.3f}"""

        ax4.text(0.05, 0.95, stats_text, transform=ax4.transAxes, fontsize=10,
                 verticalalignment='top', fontfamily='monospace')

        fig.tight_layout()
        self.canvas.draw()

        self.status_var.set(f"æ¨¡å‹ {selected_model} ç»Ÿè®¡å®Œæˆ")

    def show_model_filtering_summary(self):
        """æ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹ç­›é€‰æ±‡æ€»"""
        if not self.check_analyzer():
            return

        if not self.analyzer.individual_model_results:
            messagebox.showwarning("è­¦å‘Š", "æ— å•æ¨¡å‹ç­›é€‰æ•°æ®")
            return

        self.status_var.set("ç”Ÿæˆæ¨¡å‹ç­›é€‰æ±‡æ€»...")

        self.figure.clear()
        fig = self.figure

        # å‡†å¤‡æ•°æ®
        model_names = []
        filtered_counts = []
        filtered_ratios = []
        avg_probs = []
        avg_confs = []

        for model_key, result in self.analyzer.individual_model_results.items():
            model_names.append(result['model_name'][:15])  # æˆªæ–­é•¿åç§°
            filtered_counts.append(result['filtered_compounds'])
            filtered_ratios.append(result['filtered_ratio'])
            avg_probs.append(result['avg_probability_1'])
            avg_confs.append(result['avg_confidence'])

        # åˆ›å»º2x2å­å›¾
        ax1 = fig.add_subplot(221)
        ax2 = fig.add_subplot(222)
        ax3 = fig.add_subplot(223)
        ax4 = fig.add_subplot(224)

        # å­å›¾1: å„æ¨¡å‹ç­›é€‰åŒ–åˆç‰©æ•°é‡
        bars1 = ax1.bar(range(len(model_names)), filtered_counts, color='skyblue', alpha=0.8)
        ax1.set_title(f'å„æ¨¡å‹ç­›é€‰åŒ–åˆç‰©æ•°é‡\n(é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f})')
        ax1.set_ylabel('ç­›é€‰åŒ–åˆç‰©æ•°é‡')
        ax1.set_xticks(range(len(model_names)))
        ax1.set_xticklabels(model_names, rotation=45, ha='right')
        ax1.grid(True, alpha=0.3)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, count in zip(bars1, filtered_counts):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width() / 2., height + max(filtered_counts) * 0.01,
                     f'{count}', ha='center', va='bottom', fontsize=8)

        # å­å›¾2: å„æ¨¡å‹ç­›é€‰æ¯”ä¾‹
        bars2 = ax2.bar(range(len(model_names)), filtered_ratios, color='lightgreen', alpha=0.8)
        ax2.set_title('å„æ¨¡å‹ç­›é€‰æ¯”ä¾‹')
        ax2.set_ylabel('ç­›é€‰æ¯”ä¾‹')
        ax2.set_xticks(range(len(model_names)))
        ax2.set_xticklabels(model_names, rotation=45, ha='right')
        ax2.grid(True, alpha=0.3)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, ratio in zip(bars2, filtered_ratios):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width() / 2., height + max(filtered_ratios) * 0.01,
                     f'{ratio:.3f}', ha='center', va='bottom', fontsize=8)

        # å­å›¾3: å„æ¨¡å‹å¹³å‡æ¦‚ç‡
        bars3 = ax3.bar(range(len(model_names)), avg_probs, color='lightcoral', alpha=0.8)
        ax3.axhline(self.analyzer.current_positive_prediction_threshold, color='red', linestyle='--',
                    label=f'é˜ˆå€¼ ({self.analyzer.current_positive_prediction_threshold:.3f})')
        ax3.set_title('å„æ¨¡å‹ç­›é€‰åŒ–åˆç‰©å¹³å‡æ¦‚ç‡')
        ax3.set_ylabel('å¹³å‡ Probability_1')
        ax3.set_xticks(range(len(model_names)))
        ax3.set_xticklabels(model_names, rotation=45, ha='right')
        ax3.legend()
        ax3.grid(True, alpha=0.3)

        # å­å›¾4: å„æ¨¡å‹å¹³å‡ç½®ä¿¡åº¦
        bars4 = ax4.bar(range(len(model_names)), avg_confs, color='gold', alpha=0.8)
        ax4.set_title('å„æ¨¡å‹ç­›é€‰åŒ–åˆç‰©å¹³å‡ç½®ä¿¡åº¦')
        ax4.set_ylabel('å¹³å‡ Confidence')
        ax4.set_xticks(range(len(model_names)))
        ax4.set_xticklabels(model_names, rotation=45, ha='right')
        ax4.grid(True, alpha=0.3)

        fig.tight_layout()
        self.canvas.draw()

        # æ›´æ–°ä¿¡æ¯æ˜¾ç¤º
        self.update_model_summary_info()

        self.status_var.set("æ¨¡å‹ç­›é€‰æ±‡æ€»å®Œæˆ")

    def show_model_filtered_compounds(self):
        """åœ¨è¡¨æ ¼ä¸­æ˜¾ç¤ºé€‰å®šæ¨¡å‹çš„ç­›é€‰åŒ–åˆç‰©"""
        if not self.check_analyzer():
            return

        selected_model = self.selected_model_var.get()
        if not selected_model:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæ¨¡å‹")
            return

        if selected_model not in self.analyzer.individual_model_results:
            messagebox.showerror("é”™è¯¯", f"æœªæ‰¾åˆ°æ¨¡å‹ {selected_model} çš„æ•°æ®")
            return

        self.status_var.set(f"æ˜¾ç¤ºæ¨¡å‹ {selected_model} çš„ç­›é€‰åŒ–åˆç‰©...")

        model_result = self.analyzer.individual_model_results[selected_model]
        filtered_data = model_result['filtered_data']

        # æ¸…é™¤ç°æœ‰æ•°æ®
        for item in self.model_tree.get_children():
            self.model_tree.delete(item)

        # è®¾ç½®åˆ—
        columns = ('è›‹ç™½è´¨ID', 'åŒ–åˆç‰©ID', 'é¢„æµ‹', 'æ¦‚ç‡0', 'æ¦‚ç‡1', 'ç½®ä¿¡åº¦')
        self.model_tree['columns'] = columns

        for col in columns:
            self.model_tree.heading(col, text=col)
            self.model_tree.column(col, width=100)

        # æ·»åŠ æ•°æ®
        for item in filtered_data[:100]:  # é™åˆ¶æ˜¾ç¤ºå‰100ä¸ª
            self.model_tree.insert('', 'end', values=(
                item['protein_id'],
                item['compound_id'],
                'ç›¸äº’ä½œç”¨' if item['custom_prediction'] == 1 else 'æ— ç›¸äº’ä½œç”¨',
                f"{item['probability_0']:.4f}",
                f"{item['probability_1']:.4f}",
                f"{item['confidence']:.4f}"
            ))

        # åˆ‡æ¢åˆ°å•æ¨¡å‹æ•°æ®æ ‡ç­¾é¡µ
        self.notebook.select(1)  # å•æ¨¡å‹æ•°æ®æ˜¯ç¬¬äºŒä¸ªæ ‡ç­¾é¡µ

        self.status_var.set(f"å·²æ˜¾ç¤ºæ¨¡å‹ {selected_model} çš„ç­›é€‰ç»“æœ")

    # ===============================
    # ä¿¡æ¯æ›´æ–°å‡½æ•°
    # ===============================

    def show_welcome_info(self):
        """æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯"""
        welcome_text = """
ğŸ¯ å¢å¼ºæ¨¡å‹è¯¦æƒ…é¢„æµ‹ç»“æœåˆ†æå™¨ v3.5 - åŒ…å«å•æ¨¡å‹ç­›é€‰
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ†• æ–°å¢åŠŸèƒ½:
âœ¨ å•æ¨¡å‹ç­›é€‰åˆ†æï¼šæŸ¥çœ‹æ¯ä¸ªæ¨¡å‹ç­›é€‰å‡ºçš„å¤§äºé˜ˆå€¼çš„åŒ–åˆç‰©
âœ¨ æ¨¡å‹ç­›é€‰æ±‡æ€»ï¼šå¯¹æ¯”æ‰€æœ‰æ¨¡å‹çš„ç­›é€‰æ•ˆæœ
âœ¨ æ¨¡å‹ç­›é€‰è¯¦æƒ…ï¼šæ˜¾ç¤ºå…·ä½“çš„ç­›é€‰åŒ–åˆç‰©åˆ—è¡¨
âœ¨ å•æ¨¡å‹å¯¼å‡ºï¼šå¯¼å‡ºæ¯ä¸ªæ¨¡å‹çš„ç­›é€‰ç»“æœ

ğŸ‰ æ ¸å¿ƒåŠŸèƒ½:
âœ¨ è‡ªå®šä¹‰æ­£ä¾‹é¢„æµ‹é˜ˆå€¼ï¼šå¯è®¾ç½®probability_1 â‰¥ é˜ˆå€¼æ—¶è®¤ä¸ºé¢„æµ‹ä¸ºæ­£ä¾‹
âœ¨ å®æ—¶é‡æ–°åˆ†æï¼šä¿®æ”¹é˜ˆå€¼åç«‹å³é‡æ–°è®¡ç®—æ‰€æœ‰ç»Ÿè®¡ç»“æœ
âœ¨ æ™ºèƒ½å‚æ•°æ§åˆ¶ï¼šæ»‘å—+ç›´æ¥è¾“å…¥+å¿«é€Ÿè®¾ç½®
âœ¨ å®Œæ•´å¯¼å‡ºåŠŸèƒ½ï¼šç®€å•/è¯¦ç»†/å•æ¨¡å‹å¤šç§å¯¼å‡ºé€‰é¡¹

âš¡ æ€§èƒ½ä¼˜åŒ–ç‰¹æ€§:
â€¢ å¿«é€Ÿæ–‡ä»¶æ‰«æï¼šé™åˆ¶æœç´¢æ·±åº¦ï¼Œé¿å…æ·±åº¦é€’å½’
â€¢ æ™ºèƒ½æ–‡ä»¶éªŒè¯ï¼šåªæ£€æŸ¥æ–‡ä»¶å¤§å°å’ŒåŸºæœ¬æ ¼å¼
â€¢ åˆ†å—æ•°æ®åŠ è½½ï¼šå¤§æ–‡ä»¶è‡ªåŠ¨åˆ†å—å¤„ç†
â€¢ å†…å­˜ä¼˜åŒ–å¤„ç†ï¼šåŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„æ•°æ®

ğŸ–±ï¸ ç•Œé¢æ“ä½œè¯´æ˜:
â€¢ æ§åˆ¶é¢æ¿æ”¯æŒé¼ æ ‡æ»šè½®æ»šåŠ¨
â€¢ æ–°å¢å•æ¨¡å‹é€‰æ‹©åŒºåŸŸï¼Œå¯é€‰æ‹©æŸ¥çœ‹å…·ä½“æ¨¡å‹
â€¢ å•æ¨¡å‹æ•°æ®æ ‡ç­¾é¡µæ˜¾ç¤ºç­›é€‰åŒ–åˆç‰©è¯¦æƒ…
â€¢ æ‰€æœ‰åŠŸèƒ½æŒ‰é’®éƒ½å¯æ­£å¸¸è®¿é—®

ğŸ“‹ ä½¿ç”¨æ­¥éª¤:
1. ç‚¹å‡»"æµè§ˆ"é€‰æ‹©é¢„æµ‹ç»“æœç›®å½•
2. ç‚¹å‡»"ğŸ” å¿«é€Ÿæ‰«æ"é¢„è§ˆæ–‡ä»¶ç»“æ„
3. ç‚¹å‡»"âš¡ å¿«é€ŸåŠ è½½"å¯¼å…¥æ•°æ®
4. è®¾ç½®æ­£ä¾‹é¢„æµ‹é˜ˆå€¼ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰ï¼š
   â€¢ ä½¿ç”¨æ»‘å—æ‹–æ‹½è°ƒæ•´ï¼ˆ0.1-0.9ï¼‰
   â€¢ ç›´æ¥åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥ç²¾ç¡®æ•°å€¼
   â€¢ ä½¿ç”¨å¿«é€Ÿè®¾ç½®æŒ‰é’®ï¼ˆä¸¥æ ¼0.7/ä¸­ç­‰0.5/å®½æ¾0.3ï¼‰
   â€¢ ç‚¹å‡»"ğŸ”„ é‡æ–°åˆ†æ"åº”ç”¨æ–°é˜ˆå€¼
5. è°ƒæ•´å…¶ä»–ç­›é€‰å‚æ•°
6. ç‚¹å‡»"âœ… åº”ç”¨æ‰€æœ‰å‚æ•°"ç¡®è®¤è®¾ç½®
7. é€‰æ‹©ç»¼åˆåˆ†æåŠŸèƒ½æŸ¥çœ‹æ•´ä½“ç»“æœ
8. ä½¿ç”¨å•æ¨¡å‹åˆ†æåŠŸèƒ½ï¼š
   â€¢ åœ¨ä¸‹æ‹‰æ¡†ä¸­é€‰æ‹©è¦åˆ†æçš„æ¨¡å‹
   â€¢ ç‚¹å‡»"ğŸ“Š å•æ¨¡å‹ç»Ÿè®¡"æŸ¥çœ‹è¯¥æ¨¡å‹çš„è¯¦ç»†ç»Ÿè®¡
   â€¢ ç‚¹å‡»"ğŸ“‹ æ¨¡å‹ç­›é€‰æ±‡æ€»"å¯¹æ¯”æ‰€æœ‰æ¨¡å‹
   â€¢ ç‚¹å‡»"ğŸ¯ æŸ¥çœ‹ç­›é€‰ç»“æœ"æŸ¥çœ‹å…·ä½“åŒ–åˆç‰©åˆ—è¡¨
9. ä½¿ç”¨å¯¼å‡ºåŠŸèƒ½ä¿å­˜ç»“æœ

ğŸ¤– å•æ¨¡å‹ç­›é€‰åŠŸèƒ½è¯´æ˜:
â€¢ æ¯ä¸ªæ¨¡å‹çš„ç­›é€‰ï¼šåŸºäºå½“å‰æ­£ä¾‹é¢„æµ‹é˜ˆå€¼ç­›é€‰probability_1 â‰¥ é˜ˆå€¼çš„åŒ–åˆç‰©
â€¢ ç­›é€‰ç»Ÿè®¡ï¼šæ˜¾ç¤ºç­›é€‰æ•°é‡ã€æ¯”ä¾‹ã€å¹³å‡æ¦‚ç‡ã€å¹³å‡ç½®ä¿¡åº¦ç­‰
â€¢ ç­›é€‰ç»“æœï¼šæŒ‰ç½®ä¿¡åº¦å’Œæ¦‚ç‡æ’åºçš„å…·ä½“åŒ–åˆç‰©åˆ—è¡¨
â€¢ æ¨¡å‹å¯¹æ¯”ï¼šæ¨ªå‘å¯¹æ¯”æ‰€æœ‰æ¨¡å‹çš„ç­›é€‰æ•ˆæœ

ğŸ¯ æ­£ä¾‹é¢„æµ‹é˜ˆå€¼åŠŸèƒ½:
â€¢ ä¼ ç»Ÿæ–¹å¼ï¼šå›ºå®šä½¿ç”¨0.5ä½œä¸ºæ­£ä¾‹é¢„æµ‹é˜ˆå€¼
â€¢ å¢å¼ºæ–¹å¼ï¼šå¯è‡ªå®šä¹‰è®¾ç½®0.1-0.9ä¹‹é—´çš„ä»»æ„é˜ˆå€¼
â€¢ å®æ—¶è°ƒæ•´ï¼šä¿®æ”¹é˜ˆå€¼åç‚¹å‡»"ğŸ”„ é‡æ–°åˆ†æ"ç«‹å³ç”Ÿæ•ˆ
â€¢ å•æ¨¡å‹åº”ç”¨ï¼šæ–°é˜ˆå€¼åŒæ—¶åº”ç”¨äºç»¼åˆåˆ†æå’Œå•æ¨¡å‹åˆ†æ

ğŸ’¾ å®Œæ•´å¯¼å‡ºåŠŸèƒ½:
â€¢ ğŸ“‹ è‡ªåŠ¨ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Šï¼ˆåŒ…å«å•æ¨¡å‹ä¿¡æ¯ï¼‰
â€¢ ğŸ“ ç®€å•ç»“æœå¯¼å‡ºï¼ˆæ‘˜è¦æ•°æ®ï¼‰
â€¢ ğŸ” è¯¦ç»†ç»“æœå¯¼å‡ºï¼ˆå«æ¯ä¸ªæ¨¡å‹é¢„æµ‹ï¼‰
â€¢ ğŸ¤– å•æ¨¡å‹ç­›é€‰å¯¼å‡ºï¼ˆæ¯ä¸ªæ¨¡å‹çš„ç­›é€‰ç»“æœï¼‰
â€¢ ğŸ–¼ï¸ é«˜è´¨é‡å›¾è¡¨ä¿å­˜

ğŸ’¡ åº”ç”¨åœºæ™¯:
â€¢ æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šæ¯”è¾ƒä¸åŒæ¨¡å‹çš„ç­›é€‰æ•ˆæœ
â€¢ åŒ–åˆç‰©ä¼˜å…ˆçº§ï¼šæ ¹æ®å•æ¨¡å‹ç»“æœç¡®å®šåŒ–åˆç‰©ä¼˜å…ˆçº§
â€¢ é˜ˆå€¼ä¼˜åŒ–ï¼šé€šè¿‡å•æ¨¡å‹åˆ†æä¼˜åŒ–æ­£ä¾‹é¢„æµ‹é˜ˆå€¼
â€¢ ç»“æœéªŒè¯ï¼šäº¤å‰éªŒè¯ä¸åŒæ¨¡å‹çš„é¢„æµ‹ä¸€è‡´æ€§

å¼€å‘è€…: woyaokaoyanhaha
ç‰ˆæœ¬: 3.5.0 (å¢å¼ºæ¨¡å‹è¯¦æƒ…ç‰ˆ)
æ›´æ–°æ—¥æœŸ: 2025-06-18 13:59:41
"""

        self.info_text.delete(1.0, tk.END)
        self.info_text.insert(tk.END, welcome_text)

    def update_info_display(self):
        """æ›´æ–°ä¿¡æ¯æ˜¾ç¤º"""
        if len(self.analyzer.compound_stats) == 0:
            return

        summary = self.analyzer.get_summary_info()

        info_text = f"""
ğŸ“Š æ•°æ®æ¦‚å†µ (å¢å¼ºæ¨¡å‹è¯¦æƒ…ç‰ˆv3.5)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
æ•°æ®ç›®å½•: {summary['directory']}
æ£€æµ‹æ ¼å¼: {summary['format']}
åŒ–åˆç‰©æ€»æ•°: {summary['total_compounds']:,}
æ¨¡å‹æ€»æ•°: {summary['total_models']}
å•æ¨¡å‹åˆ†ææ•°: {summary['individual_models_analyzed']}

ğŸ¯ æ ¸å¿ƒé˜ˆå€¼å‚æ•° (å¯åœ¨æ»šåŠ¨æ§åˆ¶é¢æ¿ä¸­è°ƒæ•´)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
æ­£ä¾‹é¢„æµ‹é˜ˆå€¼: {summary['positive_prediction_threshold']:.3f} â­
æœ€å°å…±è¯†æ¨¡å‹æ•°: {self.analyzer.current_min_consensus}
æ¦‚ç‡é˜ˆå€¼: {self.analyzer.current_prob_threshold:.3f}
ç½®ä¿¡åº¦é˜ˆå€¼: {self.analyzer.current_conf_threshold:.3f}

ğŸ†• å•æ¨¡å‹ç­›é€‰åŠŸèƒ½ (v3.5æ–°å¢)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
å·²åˆ†ææ¨¡å‹æ•°é‡: {len(self.analyzer.individual_model_results)}
å½“å‰é€‰æ‹©æ¨¡å‹: {self.selected_model_var.get() or 'æœªé€‰æ‹©'}
å•æ¨¡å‹æ•°æ®æ ‡ç­¾é¡µ: âœ… å¯ç”¨
æ¨¡å‹ç­›é€‰å¯¼å‡º: âœ… æ”¯æŒ

ğŸ¤– åŠ è½½çš„æ¨¡å‹åˆ—è¡¨
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

        for model_type, models in self.analyzer.raw_predictions.items():
            info_text += f"\n{model_type}:\n"
            for model_name in models.keys():
                row_count = len(models[model_name])
                model_key = f"{model_type}_{model_name}"
                if model_key in self.analyzer.individual_model_results:
                    filtered_count = self.analyzer.individual_model_results[model_key]['filtered_compounds']
                    info_text += f"  â€¢ {model_name} ({row_count:,} æ¡é¢„æµ‹, ç­›é€‰: {filtered_count:,})\n"
                else:
                    info_text += f"  â€¢ {model_name} ({row_count:,} æ¡é¢„æµ‹)\n"

        info_text += f"""

ğŸ¯ æ­£ä¾‹é¢„æµ‹é˜ˆå€¼è¯´æ˜ (v3.5å¢å¼ºæ¨¡å‹è¯¦æƒ…ç‰ˆ)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ å½“å‰è®¾ç½®: probability_1 â‰¥ {summary['positive_prediction_threshold']:.3f} â†’ æ­£ä¾‹
â€¢ é˜ˆå€¼èŒƒå›´: 0.1 - 0.9 (åœ¨æ§åˆ¶é¢æ¿ä¸­å¯è°ƒèŠ‚)
â€¢ é‡åˆ†æåŠŸèƒ½: ä¿®æ”¹é˜ˆå€¼åå¯å®æ—¶é‡æ–°è®¡ç®—ç»Ÿè®¡
â€¢ å•æ¨¡å‹åº”ç”¨: æ–°é˜ˆå€¼åŒæ—¶åº”ç”¨äºç»¼åˆåˆ†æå’Œå•æ¨¡å‹åˆ†æ

ğŸ¤– å•æ¨¡å‹ç­›é€‰è¯´æ˜ (v3.5æ–°åŠŸèƒ½)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ ç­›é€‰é€»è¾‘: æ¯ä¸ªæ¨¡å‹ç‹¬ç«‹ç­›é€‰ probability_1 â‰¥ é˜ˆå€¼çš„åŒ–åˆç‰©
â€¢ ç­›é€‰ç»Ÿè®¡: ç­›é€‰æ•°é‡ã€æ¯”ä¾‹ã€å¹³å‡æ¦‚ç‡ã€å¹³å‡ç½®ä¿¡åº¦
â€¢ ç»“æœæ’åº: æŒ‰ç½®ä¿¡åº¦å’Œæ¦‚ç‡é™åºæ’åˆ—
â€¢ æ•°æ®å±•ç¤º: åœ¨"å•æ¨¡å‹æ•°æ®"æ ‡ç­¾é¡µä¸­æ˜¾ç¤ºå…·ä½“åŒ–åˆç‰©

ğŸ’¡ ä½¿ç”¨æç¤º (v3.5)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ åœ¨å•æ¨¡å‹é€‰æ‹©åŒºåŸŸé€‰æ‹©è¦åˆ†æçš„æ¨¡å‹
â€¢ ä½¿ç”¨"ğŸ“Š å•æ¨¡å‹ç»Ÿè®¡"æŸ¥çœ‹è¯¦ç»†çš„æ¨¡å‹è¡¨ç°
â€¢ ä½¿ç”¨"ğŸ“‹ æ¨¡å‹ç­›é€‰æ±‡æ€»"å¯¹æ¯”æ‰€æœ‰æ¨¡å‹çš„ç­›é€‰æ•ˆæœ
â€¢ ä½¿ç”¨"ğŸ¯ æŸ¥çœ‹ç­›é€‰ç»“æœ"æŸ¥çœ‹å…·ä½“çš„ç­›é€‰åŒ–åˆç‰©
â€¢ ä½¿ç”¨"ğŸ¤– å•æ¨¡å‹ç­›é€‰å¯¼å‡º"å¯¼å‡ºæ¯ä¸ªæ¨¡å‹çš„ç­›é€‰ç»“æœ
â€¢ æ”¯æŒå•å±‚æ‰¹å¤„ç†.pyå’Œæ‰¹é‡é¢„æµ‹çš„ç»“æœæ ¼å¼
"""

        self.info_text.delete(1.0, tk.END)
        self.info_text.insert(tk.END, info_text)

    def update_consensus_info(self, all_positive, majority_positive, high_confidence,
                              high_probability, custom_consensus):
        """æ›´æ–°å…±è¯†åˆ†æä¿¡æ¯"""
        info_text = f"""
ğŸ¯ å…±è¯†åˆ†æç»“æœ (å¢å¼ºæ¨¡å‹è¯¦æƒ…ç‰ˆ)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
æ­£ä¾‹é¢„æµ‹é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f} â­
åˆ†ææ¨¡å‹æ•°: {len(self.analyzer.available_models)}

ğŸ“Š ç­›é€‰ç»“æœç»Ÿè®¡ (åŸºäºè‡ªå®šä¹‰é˜ˆå€¼)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹: {len(all_positive):,} ä¸ªåŒ–åˆç‰©
å¤§å¤šæ•°æ¨¡å‹é¢„æµ‹ä¸ºæ­£ä¾‹: {len(majority_positive):,} ä¸ªåŒ–åˆç‰©
é«˜ç½®ä¿¡åº¦é¢„æµ‹: {len(high_confidence):,} ä¸ªåŒ–åˆç‰©
é«˜æ¦‚ç‡é¢„æµ‹: {len(high_probability):,} ä¸ªåŒ–åˆç‰©
ç»¼åˆç­›é€‰ç»“æœ: {len(custom_consensus):,} ä¸ªåŒ–åˆç‰©

ğŸ¥‡ æœ€é«˜ä¼˜å…ˆçº§åŒ–åˆç‰© (æ‰€æœ‰æ¨¡å‹ä¸€è‡´, é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f})
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

        if all_positive:
            for i, compound in enumerate(all_positive[:10], 1):
                info_text += f"{i:2d}. {compound['compound_id']} (è›‹ç™½è´¨: {compound['protein_id']}) "
                info_text += f"æ¦‚ç‡: {compound['avg_probability_1']:.3f}, ç½®ä¿¡åº¦: {compound['avg_confidence']:.3f}\n"
        else:
            info_text += "æš‚æ— ç¬¦åˆæ¡ä»¶çš„åŒ–åˆç‰©\n"

        info_text += f"""
ğŸ¥ˆ é«˜ç½®ä¿¡åº¦åŒ–åˆç‰©
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

        if high_confidence:
            for i, compound in enumerate(high_confidence[:10], 1):
                info_text += f"{i:2d}. {compound['compound_id']} (è›‹ç™½è´¨: {compound['protein_id']}) "
                info_text += f"æ¦‚ç‡: {compound['avg_probability_1']:.3f}, ç½®ä¿¡åº¦: {compound['avg_confidence']:.3f}\n"
        else:
            info_text += "æš‚æ— ç¬¦åˆæ¡ä»¶çš„åŒ–åˆç‰©\n"

        info_text += f"""
ğŸ¤– å•æ¨¡å‹ç­›é€‰æ‘˜è¦ (v3.5æ–°å¢)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

        # æ˜¾ç¤ºå‰5ä¸ªæ¨¡å‹çš„ç­›é€‰æ‘˜è¦
        model_summary = self.analyzer.get_individual_model_summary()
        for i, (model_key, result) in enumerate(list(model_summary.items())[:5], 1):
            info_text += f"{i}. {result['model_name']}: ç­›é€‰ {result['filtered_compounds']} ä¸ª "
            info_text += f"(æ¯”ä¾‹: {result['filtered_ratio']:.3f})\n"

        if len(model_summary) > 5:
            info_text += f"... è¿˜æœ‰ {len(model_summary) - 5} ä¸ªæ¨¡å‹\n"

        info_text += f"""

ğŸ’¡ åˆ†æå»ºè®® (å¢å¼ºæ¨¡å‹è¯¦æƒ…ç‰ˆ)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

        if len(all_positive) > 0:
            info_text += f"â€¢ ä¼˜å…ˆéªŒè¯æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹çš„åŒ–åˆç‰© (é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f})\n"
        if len(high_confidence) > len(all_positive):
            info_text += "â€¢ è€ƒè™‘é«˜ç½®ä¿¡åº¦åŒ–åˆç‰©ä½œä¸ºäºŒçº¿é€‰æ‹©\n"
        if len(majority_positive) > 50:
            info_text += "â€¢ å¤§å¤šæ•°æ¨¡å‹é¢„æµ‹ä¸ºæ­£ä¾‹çš„åŒ–åˆç‰©æ•°é‡è¾ƒå¤šï¼Œå»ºè®®è¿›ä¸€æ­¥ç­›é€‰\n"

        info_text += "â€¢ å»ºè®®ç»“åˆç”Ÿç‰©å­¦çŸ¥è¯†å’ŒåŒ–åˆç‰©ç‰¹æ€§è¿›è¡Œæœ€ç»ˆç­›é€‰\n"
        info_text += "â€¢ è€ƒè™‘åˆ†æ‰¹è¿›è¡Œå®éªŒéªŒè¯ï¼Œä»æœ€é«˜ç½®ä¿¡åº¦å¼€å§‹\n"
        info_text += f"â€¢ å½“å‰ä½¿ç”¨è‡ªå®šä¹‰æ­£ä¾‹é¢„æµ‹é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f}\n"
        info_text += "â€¢ ä½¿ç”¨å•æ¨¡å‹åˆ†æåŠŸèƒ½å¯¹æ¯”ä¸åŒæ¨¡å‹çš„ç­›é€‰æ•ˆæœ\n"
        info_text += "â€¢ æŸ¥çœ‹å•æ¨¡å‹ç­›é€‰ç»“æœï¼Œè¯†åˆ«è¡¨ç°çªå‡ºçš„æ¨¡å‹\n"
        info_text += "â€¢ ä½¿ç”¨å¯¼å‡ºåŠŸèƒ½è·å–è¯¦ç»†çš„ç­›é€‰ç»“æœå’Œå•æ¨¡å‹æ•°æ®\n"

        self.info_text.delete(1.0, tk.END)
        self.info_text.insert(tk.END, info_text)

    def update_model_summary_info(self):
        """æ›´æ–°æ¨¡å‹ç­›é€‰æ±‡æ€»ä¿¡æ¯"""
        if not self.analyzer.individual_model_results:
            return

        info_text = f"""
ğŸ¤– æ¨¡å‹ç­›é€‰æ±‡æ€»ä¿¡æ¯ (v3.5)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
æ­£ä¾‹é¢„æµ‹é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f}
åˆ†ææ¨¡å‹æ€»æ•°: {len(self.analyzer.individual_model_results)}

ğŸ“Š ç­›é€‰æ•ˆæœæ’å (æŒ‰ç­›é€‰æ•°é‡)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

        # æŒ‰ç­›é€‰æ•°é‡æ’åº
        sorted_models = sorted(
            self.analyzer.individual_model_results.items(),
            key=lambda x: x[1]['filtered_compounds'],
            reverse=True
        )

        for i, (model_key, result) in enumerate(sorted_models[:10], 1):
            info_text += f"{i:2d}. {result['model_name']}\n"
            info_text += f"    ç­›é€‰: {result['filtered_compounds']:,} / {result['total_compounds']:,} "
            info_text += f"({result['filtered_ratio']:.3f})\n"
            info_text += f"    å¹³å‡æ¦‚ç‡: {result['avg_probability_1']:.4f}, "
            info_text += f"å¹³å‡ç½®ä¿¡åº¦: {result['avg_confidence']:.4f}\n"

        info_text += f"""

ğŸ“ˆ ç­›é€‰æ•ˆæœåˆ†æ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

        # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
        all_filtered = [result['filtered_compounds'] for result in self.analyzer.individual_model_results.values()]
        all_ratios = [result['filtered_ratio'] for result in self.analyzer.individual_model_results.values()]
        all_avg_probs = [result['avg_probability_1'] for result in self.analyzer.individual_model_results.values() if
                         result['filtered_compounds'] > 0]
        all_avg_confs = [result['avg_confidence'] for result in self.analyzer.individual_model_results.values() if
                         result['filtered_compounds'] > 0]

        if all_filtered:
            info_text += f"æ€»ç­›é€‰åŒ–åˆç‰©æ•°: {sum(all_filtered):,}\n"
            info_text += f"å¹³å‡ç­›é€‰æ•°é‡: {np.mean(all_filtered):.1f}\n"
            info_text += f"å¹³å‡ç­›é€‰æ¯”ä¾‹: {np.mean(all_ratios):.4f}\n"

            if all_avg_probs:
                info_text += f"ç­›é€‰åŒ–åˆç‰©å¹³å‡æ¦‚ç‡: {np.mean(all_avg_probs):.4f}\n"
            if all_avg_confs:
                info_text += f"ç­›é€‰åŒ–åˆç‰©å¹³å‡ç½®ä¿¡åº¦: {np.mean(all_avg_confs):.4f}\n"

        info_text += f"""

ğŸ¯ æ¨¡å‹è¡¨ç°åˆ†ç±»
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

        # æ¨¡å‹è¡¨ç°åˆ†ç±»
        high_performers = [result for result in self.analyzer.individual_model_results.values()
                           if result['filtered_ratio'] > np.mean(all_ratios) + np.std(all_ratios)]
        low_performers = [result for result in self.analyzer.individual_model_results.values()
                          if result['filtered_ratio'] < np.mean(all_ratios) - np.std(all_ratios)]

        info_text += f"é«˜ç­›é€‰ç‡æ¨¡å‹ ({len(high_performers)} ä¸ª):\n"
        for result in high_performers[:5]:
            info_text += f"  â€¢ {result['model_name']} (æ¯”ä¾‹: {result['filtered_ratio']:.3f})\n"

        info_text += f"\nä½ç­›é€‰ç‡æ¨¡å‹ ({len(low_performers)} ä¸ª):\n"
        for result in low_performers[:5]:
            info_text += f"  â€¢ {result['model_name']} (æ¯”ä¾‹: {result['filtered_ratio']:.3f})\n"

        info_text += f"""

ğŸ’¡ ä½¿ç”¨å»ºè®®
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ é‡ç‚¹å…³æ³¨é«˜ç­›é€‰ç‡ä¸”é«˜ç½®ä¿¡åº¦çš„æ¨¡å‹
â€¢ å¯¹æ¯”ä¸åŒæ¨¡å‹ç±»å‹çš„ç­›é€‰è¡¨ç°
â€¢ è€ƒè™‘å¤šä¸ªé«˜è¡¨ç°æ¨¡å‹çš„äº¤é›†åŒ–åˆç‰©
â€¢ ä½¿ç”¨å•æ¨¡å‹å¯¼å‡ºåŠŸèƒ½è·å–è¯¦ç»†æ•°æ®
â€¢ æ ¹æ®æ¨¡å‹è¡¨ç°è°ƒæ•´ç­›é€‰ç­–ç•¥
"""

        self.info_text.delete(1.0, tk.END)
        self.info_text.insert(tk.END, info_text)

    # ===============================
    # å¯¼å‡ºåŠŸèƒ½
    # ===============================

    def export_simple_results(self):
        """ç®€å•ç»“æœå¯¼å‡º"""
        if not self.check_analyzer():
            return

        directory = filedialog.askdirectory(title="é€‰æ‹©å¯¼å‡ºç›®å½• - ç®€å•ç»“æœ")
        if not directory:
            return

        self.status_var.set("æ­£åœ¨å¯¼å‡ºç®€å•ç­›é€‰ç»“æœ...")

        try:
            results = {
                'all_positive': self.analyzer._find_all_positive(),
                'majority_positive': self.analyzer._find_majority_positive(),
                'high_confidence': self.analyzer._find_high_confidence(),
                'high_probability': self.analyzer._find_high_probability(),
                'custom_consensus': self.analyzer._find_custom_consensus()
            }

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            export_dir = os.path.join(directory, f"enhanced_model_results_{timestamp}")
            os.makedirs(export_dir, exist_ok=True)

            exported_files = []

            for result_type, compounds in results.items():
                if compounds:
                    df_data = []
                    for compound in compounds:
                        row = {
                            'protein_id': compound['protein_id'],
                            'compound_id': compound['compound_id'],
                            'total_models': compound['total_models'],
                            'positive_predictions': compound['positive_predictions'],
                            'negative_predictions': compound['negative_predictions'],
                            'positive_ratio': f"{compound['positive_ratio']:.4f}",
                            'avg_probability_0': f"{1 - compound['avg_probability_1']:.4f}",
                            'avg_probability_1': f"{compound['avg_probability_1']:.4f}",
                            'avg_confidence': f"{compound['avg_confidence']:.4f}",
                            'positive_prediction_threshold': f"{self.analyzer.current_positive_prediction_threshold:.3f}"
                        }
                        df_data.append(row)

                    df = pd.DataFrame(df_data)
                    output_file = os.path.join(export_dir, f"{result_type}_simple.csv")
                    df.to_csv(output_file, index=False, encoding='utf-8-sig')
                    exported_files.append(output_file)

            self._save_enhanced_export_parameters(export_dir, "simple")

            files_list = '\n'.join([os.path.basename(f) for f in exported_files])
            messagebox.showinfo("å¯¼å‡ºæˆåŠŸ",
                                f"å¢å¼ºæ¨¡å‹è¯¦æƒ…ç­›é€‰ç»“æœå·²å¯¼å‡ºåˆ°:\n{export_dir}\n\n"
                                f"æ­£ä¾‹é¢„æµ‹é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f}\n\n"
                                f"å¯¼å‡ºæ–‡ä»¶:\n{files_list}")

            self.status_var.set("ç®€å•ç»“æœå¯¼å‡ºå®Œæˆ")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {e}")
            self.status_var.set("å¯¼å‡ºå¤±è´¥")

    def export_detailed_results(self):
        """è¯¦ç»†ç»“æœå¯¼å‡º"""
        if not self.check_analyzer():
            return

        directory = filedialog.askdirectory(title="é€‰æ‹©å¯¼å‡ºç›®å½• - è¯¦ç»†ç»“æœ")
        if not directory:
            return

        self.status_var.set("æ­£åœ¨å¯¼å‡ºè¯¦ç»†ç­›é€‰ç»“æœ...")

        try:
            results = {
                'all_positive': self.analyzer._find_all_positive(),
                'majority_positive': self.analyzer._find_majority_positive(),
                'high_confidence': self.analyzer._find_high_confidence(),
                'high_probability': self.analyzer._find_high_probability(),
                'custom_consensus': self.analyzer._find_custom_consensus()
            }

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            export_dir = os.path.join(directory, f"enhanced_model_detailed_{timestamp}")
            os.makedirs(export_dir, exist_ok=True)

            exported_files = []

            for result_type, compounds in results.items():
                if compounds:
                    summary_data = []
                    detailed_data = []

                    for compound in compounds:
                        summary_row = {
                            'protein_id': compound['protein_id'],
                            'compound_id': compound['compound_id'],
                            'total_models': compound['total_models'],
                            'positive_predictions': compound['positive_predictions'],
                            'negative_predictions': compound['negative_predictions'],
                            'positive_ratio': f"{compound['positive_ratio']:.4f}",
                            'avg_probability_0': f"{1 - compound['avg_probability_1']:.4f}",
                            'avg_probability_1': f"{compound['avg_probability_1']:.4f}",
                            'avg_confidence': f"{compound['avg_confidence']:.4f}",
                            'positive_prediction_threshold': f"{self.analyzer.current_positive_prediction_threshold:.3f}"
                        }
                        summary_data.append(summary_row)

                        for pred in compound['predictions']:
                            detailed_row = {
                                'protein_id': compound['protein_id'],
                                'compound_id': compound['compound_id'],
                                'model_type': pred['model_type'],
                                'model_name': pred['model_name'],
                                'original_prediction': pred['original_prediction'],
                                'custom_prediction': pred['custom_prediction'],
                                'prediction_label': 'ç›¸äº’ä½œç”¨' if pred['custom_prediction'] == 1 else 'æ— ç›¸äº’ä½œç”¨',
                                'probability_0': f"{pred['probability_0']:.4f}",
                                'probability_1': f"{pred['probability_1']:.4f}",
                                'confidence': f"{pred['confidence']:.4f}",
                                'positive_prediction_threshold': f"{self.analyzer.current_positive_prediction_threshold:.3f}",
                                'avg_probability_1': f"{compound['avg_probability_1']:.4f}",
                                'avg_confidence': f"{compound['avg_confidence']:.4f}",
                                'positive_ratio': f"{compound['positive_ratio']:.4f}"
                            }
                            detailed_data.append(detailed_row)

                    summary_df = pd.DataFrame(summary_data)
                    summary_file = os.path.join(export_dir, f"{result_type}_summary.csv")
                    summary_df.to_csv(summary_file, index=False, encoding='utf-8-sig')
                    exported_files.append(summary_file)

                    detailed_df = pd.DataFrame(detailed_data)
                    detailed_file = os.path.join(export_dir, f"{result_type}_detailed.csv")
                    detailed_df.to_csv(detailed_file, index=False, encoding='utf-8-sig')
                    exported_files.append(detailed_file)

            self._save_enhanced_export_parameters(export_dir, "detailed")

            files_list = '\n'.join([os.path.basename(f) for f in exported_files])
            messagebox.showinfo("å¯¼å‡ºæˆåŠŸ",
                                f"å¢å¼ºæ¨¡å‹è¯¦æƒ…è¯¦ç»†ç»“æœå·²å¯¼å‡ºåˆ°:\n{export_dir}\n\n"
                                f"æ­£ä¾‹é¢„æµ‹é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f}\n\n"
                                f"å¯¼å‡ºæ–‡ä»¶:\n{files_list}\n\n"
                                f"æ¯ä¸ªç­›é€‰ç±»å‹åŒ…å«ä¸¤ä¸ªæ–‡ä»¶:\n"
                                f"â€¢ *_summary.csv: åŸºç¡€æ‘˜è¦æ•°æ®\n"
                                f"â€¢ *_detailed.csv: æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†é¢„æµ‹\n"
                                f"åŒ…å«åŸå§‹é¢„æµ‹å’ŒåŸºäºè‡ªå®šä¹‰é˜ˆå€¼çš„é¢„æµ‹")

            self.status_var.set("è¯¦ç»†ç»“æœå¯¼å‡ºå®Œæˆ")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {e}")
            self.status_var.set("å¯¼å‡ºå¤±è´¥")

    def export_individual_model_results(self):
        """æ–°å¢ï¼šå¯¼å‡ºå•æ¨¡å‹ç­›é€‰ç»“æœ"""
        if not self.check_analyzer():
            return

        if not self.analyzer.individual_model_results:
            messagebox.showwarning("è­¦å‘Š", "æ— å•æ¨¡å‹ç­›é€‰æ•°æ®å¯å¯¼å‡º")
            return

        directory = filedialog.askdirectory(title="é€‰æ‹©å¯¼å‡ºç›®å½• - å•æ¨¡å‹ç­›é€‰ç»“æœ")
        if not directory:
            return

        self.status_var.set("æ­£åœ¨å¯¼å‡ºå•æ¨¡å‹ç­›é€‰ç»“æœ...")

        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            export_dir = os.path.join(directory, f"individual_model_results_{timestamp}")
            os.makedirs(export_dir, exist_ok=True)

            exported_files = []

            # å¯¼å‡ºæ¨¡å‹ç­›é€‰æ±‡æ€»
            summary_data = []
            for model_key, result in self.analyzer.individual_model_results.items():
                summary_row = {
                    'model_type': result['model_type'],
                    'model_name': result['model_name'],
                    'total_compounds': result['total_compounds'],
                    'filtered_compounds': result['filtered_compounds'],
                    'filtered_ratio': f"{result['filtered_ratio']:.4f}",
                    'avg_probability_1': f"{result['avg_probability_1']:.4f}",
                    'avg_confidence': f"{result['avg_confidence']:.4f}",
                    'max_probability_1': f"{result['max_probability_1']:.4f}",
                    'min_probability_1': f"{result['min_probability_1']:.4f}",
                    'threshold_used': f"{result['threshold_used']:.3f}"
                }
                summary_data.append(summary_row)

            summary_df = pd.DataFrame(summary_data)
            summary_file = os.path.join(export_dir, "model_filtering_summary.csv")
            summary_df.to_csv(summary_file, index=False, encoding='utf-8-sig')
            exported_files.append(summary_file)

            # ä¸ºæ¯ä¸ªæ¨¡å‹å¯¼å‡ºè¯¦ç»†çš„ç­›é€‰åŒ–åˆç‰©
            model_details_dir = os.path.join(export_dir, "individual_models")
            os.makedirs(model_details_dir, exist_ok=True)

            for model_key, result in self.analyzer.individual_model_results.items():
                if result['filtered_data']:
                    model_df_data = []
                    for item in result['filtered_data']:
                        row = {
                            'protein_id': item['protein_id'],
                            'compound_id': item['compound_id'],
                            'original_prediction': item['prediction'],
                            'custom_prediction': item['custom_prediction'],
                            'prediction_label': 'ç›¸äº’ä½œç”¨' if item['custom_prediction'] == 1 else 'æ— ç›¸äº’ä½œç”¨',
                            'probability_0': f"{item['probability_0']:.4f}",
                            'probability_1': f"{item['probability_1']:.4f}",
                            'confidence': f"{item['confidence']:.4f}",
                            'threshold_used': f"{result['threshold_used']:.3f}",
                            'model_type': result['model_type'],
                            'model_name': result['model_name']
                        }
                        model_df_data.append(row)

                    model_df = pd.DataFrame(model_df_data)
                    # å®‰å…¨çš„æ–‡ä»¶åå¤„ç†
                    safe_model_name = "".join(
                        c for c in result['model_name'] if c.isalnum() or c in (' ', '-', '_')).rstrip()
                    safe_model_name = safe_model_name.replace(' ', '_')
                    model_file = os.path.join(model_details_dir, f"{safe_model_name}_filtered_compounds.csv")
                    model_df.to_csv(model_file, index=False, encoding='utf-8-sig')
                    exported_files.append(model_file)

            # å¯¼å‡ºTopåŒ–åˆç‰©æ±‡æ€»ï¼ˆæ‰€æœ‰æ¨¡å‹çš„Top10åŒ–åˆç‰©ï¼‰
            top_compounds_data = []
            for model_key, result in self.analyzer.individual_model_results.items():
                top_compounds = result['filtered_data'][:10]  # Top 10
                for i, item in enumerate(top_compounds, 1):
                    row = {
                        'model_type': result['model_type'],
                        'model_name': result['model_name'],
                        'rank': i,
                        'protein_id': item['protein_id'],
                        'compound_id': item['compound_id'],
                        'probability_1': f"{item['probability_1']:.4f}",
                        'confidence': f"{item['confidence']:.4f}",
                        'threshold_used': f"{result['threshold_used']:.3f}"
                    }
                    top_compounds_data.append(row)

            if top_compounds_data:
                top_df = pd.DataFrame(top_compounds_data)
                top_file = os.path.join(export_dir, "all_models_top10_compounds.csv")
                top_df.to_csv(top_file, index=False, encoding='utf-8-sig')
                exported_files.append(top_file)

            self._save_enhanced_export_parameters(export_dir, "individual_model")

            # åˆ›å»ºREADMEæ–‡ä»¶
            readme_file = os.path.join(export_dir, "README.txt")
            with open(readme_file, 'w', encoding='utf-8') as f:
                f.write("å•æ¨¡å‹ç­›é€‰ç»“æœå¯¼å‡ºè¯´æ˜\n")
                f.write("=" * 40 + "\n")
                f.write(f"å¯¼å‡ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ•°æ®æ¥æº: {self.analyzer.result_dir}\n")
                f.write(f"æ­£ä¾‹é¢„æµ‹é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f}\n")
                f.write(f"ç”¨æˆ·: woyaokaoyanhaha\n\n")

                f.write("æ–‡ä»¶ç»“æ„:\n")
                f.write("- model_filtering_summary.csv: æ‰€æœ‰æ¨¡å‹çš„ç­›é€‰æ±‡æ€»ç»Ÿè®¡\n")
                f.write("- all_models_top10_compounds.csv: æ‰€æœ‰æ¨¡å‹çš„Top10åŒ–åˆç‰©æ±‡æ€»\n")
                f.write("- individual_models/: æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†ç­›é€‰åŒ–åˆç‰©æ–‡ä»¶\n")
                f.write("- export_parameters.json: å¯¼å‡ºæ—¶çš„å‚æ•°è®¾ç½®\n\n")

                f.write("æ•°æ®è¯´æ˜:\n")
                f.write("- filtered_compounds: åŸºäºæ­£ä¾‹é¢„æµ‹é˜ˆå€¼ç­›é€‰å‡ºçš„åŒ–åˆç‰©æ•°é‡\n")
                f.write("- filtered_ratio: ç­›é€‰åŒ–åˆç‰©å æ€»åŒ–åˆç‰©çš„æ¯”ä¾‹\n")
                f.write("- custom_prediction: åŸºäºè‡ªå®šä¹‰é˜ˆå€¼çš„é¢„æµ‹ç»“æœ (1=æ­£ä¾‹, 0=è´Ÿä¾‹)\n")
                f.write("- æ‰€æœ‰åŒ–åˆç‰©æŒ‰ç½®ä¿¡åº¦å’Œæ¦‚ç‡é™åºæ’åˆ—\n")

            files_count = len(exported_files)
            model_count = len([f for f in exported_files if 'individual_models' in f])

            messagebox.showinfo("å¯¼å‡ºæˆåŠŸ",
                                f"å•æ¨¡å‹ç­›é€‰ç»“æœå·²å¯¼å‡ºåˆ°:\n{export_dir}\n\n"
                                f"å¯¼å‡ºç»Ÿè®¡:\n"
                                f"â€¢ åˆ†ææ¨¡å‹æ•°é‡: {len(self.analyzer.individual_model_results)}\n"
                                f"â€¢ å¯¼å‡ºæ–‡ä»¶æ•°é‡: {files_count}\n"
                                f"â€¢ å•æ¨¡å‹è¯¦ç»†æ–‡ä»¶: {model_count}\n"
                                f"â€¢ æ­£ä¾‹é¢„æµ‹é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f}\n\n"
                                f"åŒ…å«:\n"
                                f"â€¢ æ¨¡å‹ç­›é€‰æ±‡æ€»ç»Ÿè®¡\n"
                                f"â€¢ æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†ç­›é€‰åŒ–åˆç‰©\n"
                                f"â€¢ æ‰€æœ‰æ¨¡å‹Top10åŒ–åˆç‰©æ±‡æ€»\n"
                                f"â€¢ è¯¦ç»†çš„ä½¿ç”¨è¯´æ˜")

            self.status_var.set("å•æ¨¡å‹ç»“æœå¯¼å‡ºå®Œæˆ")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {e}")
            self.status_var.set("å¯¼å‡ºå¤±è´¥")

    def generate_enhanced_report(self):
        """ç”Ÿæˆå¢å¼ºæ¨¡å‹è¯¦æƒ…åˆ†ææŠ¥å‘Š"""
        if not self.check_analyzer():
            return

        file_path = filedialog.asksaveasfilename(
            title="ä¿å­˜å¢å¼ºæ¨¡å‹è¯¦æƒ…åˆ†ææŠ¥å‘Š",
            defaultextension=".txt",
            filetypes=[("æ–‡æœ¬æ–‡ä»¶", "*.txt"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )

        if not file_path:
            return

        self.status_var.set("æ­£åœ¨ç”Ÿæˆå¢å¼ºæ¨¡å‹è¯¦æƒ…æŠ¥å‘Š...")

        try:
            all_positive = self.analyzer._find_all_positive()
            majority_positive = self.analyzer._find_majority_positive()
            high_confidence = self.analyzer._find_high_confidence()
            high_probability = self.analyzer._find_high_probability()
            custom_consensus = self.analyzer._find_custom_consensus()

            with open(file_path, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write("å¢å¼ºæ¨¡å‹è¯¦æƒ…é¢„æµ‹ç»“æœåˆ†ææŠ¥å‘Š v3.5\n")
                f.write("=" * 80 + "\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"åˆ†æç”¨æˆ·: woyaokaoyanhaha\n")
                f.write(f"æ•°æ®æ¥æº: {self.analyzer.result_dir}\n")
                f.write(f"æ£€æµ‹æ ¼å¼: {self.analyzer.get_summary_info()['format']}\n")
                f.write(f"åˆ†æå·¥å…·: å¢å¼ºæ¨¡å‹è¯¦æƒ…é¢„æµ‹ç»“æœåˆ†æå™¨ GUI v3.5\n\n")

                f.write("æ–°å¢åŠŸèƒ½ (v3.5)\n")
                f.write("-" * 40 + "\n")
                f.write("ğŸ†• å•æ¨¡å‹ç­›é€‰åˆ†æï¼šæŸ¥çœ‹æ¯ä¸ªæ¨¡å‹ç­›é€‰å‡ºçš„å¤§äºé˜ˆå€¼çš„åŒ–åˆç‰©\n")
                f.write("ğŸ†• æ¨¡å‹ç­›é€‰æ±‡æ€»ï¼šå¯¹æ¯”æ‰€æœ‰æ¨¡å‹çš„ç­›é€‰æ•ˆæœ\n")
                f.write("ğŸ†• æ¨¡å‹ç­›é€‰è¯¦æƒ…ï¼šæ˜¾ç¤ºå…·ä½“çš„ç­›é€‰åŒ–åˆç‰©åˆ—è¡¨\n")
                f.write("ğŸ†• å•æ¨¡å‹å¯¼å‡ºï¼šå¯¼å‡ºæ¯ä¸ªæ¨¡å‹çš„ç­›é€‰ç»“æœ\n\n")

                f.write("æ ¸å¿ƒå‚æ•°è®¾ç½®\n")
                f.write("-" * 40 + "\n")
                f.write(f"ğŸ¯ æ­£ä¾‹é¢„æµ‹é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f} (æ ¸å¿ƒå‚æ•°)\n")
                f.write(
                    f"   è¯´æ˜: probability_1 â‰¥ {self.analyzer.current_positive_prediction_threshold:.3f} æ—¶è®¤ä¸ºé¢„æµ‹ä¸ºæ­£ä¾‹\n")
                f.write(f"æœ€å°å…±è¯†æ¨¡å‹æ•°: {self.analyzer.current_min_consensus}\n")
                f.write(f"æ¦‚ç‡é˜ˆå€¼: {self.analyzer.current_prob_threshold:.3f}\n")
                f.write(f"ç½®ä¿¡åº¦é˜ˆå€¼: {self.analyzer.current_conf_threshold:.3f}\n\n")

                f.write("æ•°æ®æ¦‚å†µ\n")
                f.write("-" * 40 + "\n")
                f.write(f"åŒ–åˆç‰©æ€»æ•°: {len(self.analyzer.compound_stats):,}\n")
                f.write(f"æ¨¡å‹æ€»æ•°: {len(self.analyzer.available_models)}\n")
                f.write(f"å•æ¨¡å‹åˆ†ææ•°: {len(self.analyzer.individual_model_results)}\n")
                f.write(f"æ•°æ®æ ‡å‡†åŒ–: âœ… æˆåŠŸ\n")
                f.write(f"è‡ªå®šä¹‰é˜ˆå€¼åˆ†æ: âœ… å¯ç”¨\n")
                f.write(f"å•æ¨¡å‹ç­›é€‰åŠŸèƒ½: âœ… å¯ç”¨\n\n")

                f.write("åŸºäºè‡ªå®šä¹‰é˜ˆå€¼çš„ç­›é€‰ç»“æœç»Ÿè®¡\n")
                f.write("-" * 40 + "\n")
                f.write(f"æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹: {len(all_positive):,} ä¸ªåŒ–åˆç‰©\n")
                f.write(f"å¤§å¤šæ•°æ¨¡å‹é¢„æµ‹ä¸ºæ­£ä¾‹: {len(majority_positive):,} ä¸ªåŒ–åˆç‰©\n")
                f.write(f"é«˜ç½®ä¿¡åº¦é¢„æµ‹: {len(high_confidence):,} ä¸ªåŒ–åˆç‰©\n")
                f.write(f"é«˜æ¦‚ç‡é¢„æµ‹: {len(high_probability):,} ä¸ªåŒ–åˆç‰©\n")
                f.write(f"ç»¼åˆç­›é€‰ç»“æœ: {len(custom_consensus):,} ä¸ªåŒ–åˆç‰©\n\n")

                # å•æ¨¡å‹ç­›é€‰ç»“æœåˆ†æ
                if self.analyzer.individual_model_results:
                    f.write("å•æ¨¡å‹ç­›é€‰ç»“æœåˆ†æ (v3.5æ–°å¢)\n")
                    f.write("-" * 40 + "\n")

                    # æŒ‰ç­›é€‰æ•°é‡æ’åº
                    sorted_models = sorted(
                        self.analyzer.individual_model_results.items(),
                        key=lambda x: x[1]['filtered_compounds'],
                        reverse=True
                    )

                    f.write(f"åˆ†ææ¨¡å‹æ•°é‡: {len(self.analyzer.individual_model_results)}\n")
                    f.write(f"ä½¿ç”¨é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f}\n\n")

                    f.write("æ¨¡å‹ç­›é€‰æ’å (æŒ‰ç­›é€‰æ•°é‡):\n")
                    for i, (model_key, result) in enumerate(sorted_models[:10], 1):
                        f.write(f"  {i:2d}. {result['model_name']}\n")
                        f.write(f"      ç­›é€‰: {result['filtered_compounds']:,} / {result['total_compounds']:,} ")
                        f.write(f"({result['filtered_ratio']:.3f})\n")
                        f.write(f"      å¹³å‡æ¦‚ç‡: {result['avg_probability_1']:.4f}, ")
                        f.write(f"å¹³å‡ç½®ä¿¡åº¦: {result['avg_confidence']:.4f}\n")

                    # ç­›é€‰æ•ˆæœç»Ÿè®¡
                    all_filtered = [result['filtered_compounds'] for result in
                                    self.analyzer.individual_model_results.values()]
                    all_ratios = [result['filtered_ratio'] for result in
                                  self.analyzer.individual_model_results.values()]

                    if all_filtered:
                        f.write(f"\nç­›é€‰æ•ˆæœç»Ÿè®¡:\n")
                        f.write(f"  æ€»ç­›é€‰åŒ–åˆç‰©æ•°: {sum(all_filtered):,}\n")
                        f.write(f"  å¹³å‡ç­›é€‰æ•°é‡: {np.mean(all_filtered):.1f}\n")
                        f.write(f"  å¹³å‡ç­›é€‰æ¯”ä¾‹: {np.mean(all_ratios):.4f}\n")
                        f.write(f"  ç­›é€‰æ¯”ä¾‹æ ‡å‡†å·®: {np.std(all_ratios):.4f}\n")
                        f.write(f"  æœ€é«˜ç­›é€‰æ¯”ä¾‹: {max(all_ratios):.4f}\n")
                        f.write(f"  æœ€ä½ç­›é€‰æ¯”ä¾‹: {min(all_ratios):.4f}\n\n")

                if all_positive:
                    f.write(f"é‡ç‚¹åŒ–åˆç‰©æ¨è (é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f})\n")
                    f.write("-" * 40 + "\n")
                    f.write("ğŸ¥‡ æœ€é«˜ä¼˜å…ˆçº§åŒ–åˆç‰© (æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹):\n")
                    for i, compound in enumerate(all_positive[:20], 1):
                        f.write(f"  {i:2d}. {compound['compound_id']} (è›‹ç™½è´¨: {compound['protein_id']}) - "
                                f"æ¦‚ç‡: {compound['avg_probability_1']:.3f}, ç½®ä¿¡åº¦: {compound['avg_confidence']:.3f}\n")
                    f.write("\n")

                # ç»Ÿè®¡åˆ†æ
                all_probs = [stats['avg_probability_1'] for stats in self.analyzer.compound_stats.values()]
                all_confs = [stats['avg_confidence'] for stats in self.analyzer.compound_stats.values()]

                f.write("ç»Ÿè®¡åˆ†æ\n")
                f.write("-" * 40 + "\n")
                f.write(f"æ¦‚ç‡åˆ†å¸ƒ (ç›¸å¯¹äºæ­£ä¾‹é¢„æµ‹é˜ˆå€¼ {self.analyzer.current_positive_prediction_threshold:.3f}):\n")
                f.write(f"  å¹³å‡å€¼: {np.mean(all_probs):.4f}\n")
                f.write(f"  ä¸­ä½æ•°: {np.median(all_probs):.4f}\n")
                f.write(f"  æ ‡å‡†å·®: {np.std(all_probs):.4f}\n")
                f.write(f"  æœ€å°å€¼: {np.min(all_probs):.4f}\n")
                f.write(f"  æœ€å¤§å€¼: {np.max(all_probs):.4f}\n")
                f.write(
                    f"  â‰¥ æ­£ä¾‹é¢„æµ‹é˜ˆå€¼çš„åŒ–åˆç‰©: {sum(1 for p in all_probs if p >= self.analyzer.current_positive_prediction_threshold)} ä¸ª\n\n")

                f.write(f"ç½®ä¿¡åº¦åˆ†å¸ƒ:\n")
                f.write(f"  å¹³å‡å€¼: {np.mean(all_confs):.4f}\n")
                f.write(f"  ä¸­ä½æ•°: {np.median(all_confs):.4f}\n")
                f.write(f"  æ ‡å‡†å·®: {np.std(all_confs):.4f}\n")
                f.write(f"  æœ€å°å€¼: {np.min(all_confs):.4f}\n")
                f.write(f"  æœ€å¤§å€¼: {np.max(all_confs):.4f}\n\n")

                # æ¨¡å‹è¯¦ç»†ä¿¡æ¯
                f.write("æ¨¡å‹è¯¦ç»†ä¿¡æ¯\n")
                f.write("-" * 40 + "\n")
                for model_type, models in self.analyzer.raw_predictions.items():
                    f.write(f"{model_type}:\n")
                    for model_name, df in models.items():
                        total_count = len(df)
                        model_key = f"{model_type}_{model_name}"
                        if model_key in self.analyzer.individual_model_results:
                            filtered_count = self.analyzer.individual_model_results[model_key]['filtered_compounds']
                            filtered_ratio = self.analyzer.individual_model_results[model_key]['filtered_ratio']
                            f.write(
                                f"  â€¢ {model_name}: {total_count:,} é¢„æµ‹, ç­›é€‰: {filtered_count:,} ({filtered_ratio:.3f})\n")
                        else:
                            f.write(f"  â€¢ {model_name}: {total_count:,} é¢„æµ‹\n")
                    f.write("\n")

                f.write("å¢å¼ºæ¨¡å‹è¯¦æƒ…ç‰ˆåˆ†æå»ºè®® (v3.5)\n")
                f.write("-" * 40 + "\n")
                f.write(f"1. å½“å‰ä½¿ç”¨çš„æ­£ä¾‹é¢„æµ‹é˜ˆå€¼: {self.analyzer.current_positive_prediction_threshold:.3f}\n")
                f.write("2. ä¼˜å…ˆéªŒè¯æ‰€æœ‰æ¨¡å‹éƒ½é¢„æµ‹ä¸ºæ­£ä¾‹çš„åŒ–åˆç‰©ï¼ŒæˆåŠŸç‡æœ€é«˜\n")
                f.write("3. å…³æ³¨é«˜ç­›é€‰ç‡ä¸”é«˜ç½®ä¿¡åº¦çš„å•ä¸ªæ¨¡å‹ç»“æœ\n")
                f.write("4. å¯¹æ¯”ä¸åŒæ¨¡å‹ç±»å‹çš„ç­›é€‰è¡¨ç°ï¼Œè¯†åˆ«æœ€ä½³æ¨¡å‹\n")
                f.write("5. è€ƒè™‘å¤šä¸ªé«˜è¡¨ç°æ¨¡å‹çš„äº¤é›†åŒ–åˆç‰©\n")
                f.write("6. ä½¿ç”¨å•æ¨¡å‹å¯¼å‡ºåŠŸèƒ½è·å–è¯¦ç»†çš„ç­›é€‰æ•°æ®\n")
                f.write("7. æ ¹æ®å•æ¨¡å‹è¡¨ç°è°ƒæ•´ç­›é€‰ç­–ç•¥å’Œé˜ˆå€¼è®¾ç½®\n")
                f.write("8. ç»“åˆç”Ÿç‰©å­¦çŸ¥è¯†éªŒè¯å•æ¨¡å‹ç­›é€‰ç»“æœ\n")

                f.write("\nå•æ¨¡å‹ç­›é€‰åŠŸèƒ½è¯´æ˜ (v3.5æ–°å¢)\n")
                f.write("-" * 40 + "\n")
                f.write("â€¢ ç­›é€‰é€»è¾‘: æ¯ä¸ªæ¨¡å‹ç‹¬ç«‹ç­›é€‰ probability_1 â‰¥ é˜ˆå€¼çš„åŒ–åˆç‰©\n")
                f.write("â€¢ ç­›é€‰ç»Ÿè®¡: æä¾›ç­›é€‰æ•°é‡ã€æ¯”ä¾‹ã€å¹³å‡æ¦‚ç‡ã€å¹³å‡ç½®ä¿¡åº¦\n")
                f.write("â€¢ ç»“æœæ’åº: æŒ‰ç½®ä¿¡åº¦å’Œæ¦‚ç‡é™åºæ’åˆ—\n")
                f.write("â€¢ æ¨¡å‹å¯¹æ¯”: æ¨ªå‘å¯¹æ¯”æ‰€æœ‰æ¨¡å‹çš„ç­›é€‰æ•ˆæœ\n")
                f.write("â€¢ æ•°æ®å¯¼å‡º: æ”¯æŒå•æ¨¡å‹ç­›é€‰ç»“æœçš„ä¸“é—¨å¯¼å‡º\n")
                f.write("â€¢ å®æ—¶æ›´æ–°: é˜ˆå€¼ä¿®æ”¹åå•æ¨¡å‹ç»“æœåŒæ­¥æ›´æ–°\n")

                f.write("\nä½¿ç”¨åœºæ™¯å»ºè®®\n")
                f.write("-" * 40 + "\n")
                f.write("â€¢ æ¨¡å‹æ€§èƒ½è¯„ä¼°: æ¯”è¾ƒä¸åŒæ¨¡å‹çš„ç­›é€‰æ•ˆæœå’Œä¸€è‡´æ€§\n")
                f.write("â€¢ åŒ–åˆç‰©ä¼˜å…ˆçº§: æ ¹æ®å•æ¨¡å‹å’Œç»¼åˆç»“æœç¡®å®šåŒ–åˆç‰©ä¼˜å…ˆçº§\n")
                f.write("â€¢ é˜ˆå€¼ä¼˜åŒ–: é€šè¿‡å•æ¨¡å‹åˆ†æä¼˜åŒ–æ­£ä¾‹é¢„æµ‹é˜ˆå€¼è®¾ç½®\n")
                f.write("â€¢ ç»“æœéªŒè¯: äº¤å‰éªŒè¯ä¸åŒæ¨¡å‹çš„é¢„æµ‹ä¸€è‡´æ€§å’Œå¯é æ€§\n")
                f.write("â€¢ æ¨¡å‹é€‰æ‹©: è¯†åˆ«è¡¨ç°æœ€ä½³çš„æ¨¡å‹ç±»å‹å’Œé…ç½®\n")

                f.write("\n" + "=" * 80 + "\n")
                f.write("å¢å¼ºæ¨¡å‹è¯¦æƒ…åˆ†ææŠ¥å‘Šç»“æŸ\n")
                f.write("=" * 80 + "\n")

            messagebox.showinfo("æˆåŠŸ", f"å¢å¼ºæ¨¡å‹è¯¦æƒ…åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°:\n{file_path}")
            self.status_var.set("æŠ¥å‘Šç”Ÿæˆå®Œæˆ")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            self.status_var.set("æŠ¥å‘Šç”Ÿæˆå¤±è´¥")

    def save_current_plot(self):
        """ä¿å­˜å½“å‰å›¾è¡¨"""
        if not self.figure:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰å¯ä¿å­˜çš„å›¾è¡¨")
            return

        file_path = filedialog.asksaveasfilename(
            title="ä¿å­˜å›¾è¡¨",
            defaultextension=".png",
            filetypes=[
                ("PNGå›¾ç‰‡", "*.png"),
                ("JPEGå›¾ç‰‡", "*.jpg"),
                ("PDFæ–‡ä»¶", "*.pdf"),
                ("SVGçŸ¢é‡å›¾", "*.svg"),
                ("æ‰€æœ‰æ–‡ä»¶", "*.*")
            ]
        )

        if not file_path:
            return

        try:
            self.figure.savefig(file_path, dpi=300, bbox_inches='tight')
            messagebox.showinfo("æˆåŠŸ", f"å›¾è¡¨å·²ä¿å­˜åˆ°:\n{file_path}")
            self.status_var.set("å›¾è¡¨ä¿å­˜æˆåŠŸ")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"ä¿å­˜å›¾è¡¨å¤±è´¥: {e}")
            self.status_var.set("ä¿å­˜å¤±è´¥")

    def _save_enhanced_export_parameters(self, export_dir, export_type):
        """ä¿å­˜å¢å¼ºç‰ˆå¯¼å‡ºå‚æ•°"""
        params = {
            'export_type': export_type,
            'positive_prediction_threshold': self.analyzer.current_positive_prediction_threshold,
            'min_consensus_models': self.analyzer.current_min_consensus,
            'probability_threshold': self.analyzer.current_prob_threshold,
            'confidence_threshold': self.analyzer.current_conf_threshold,
            'export_time': datetime.now().isoformat(),
            'total_compounds_analyzed': len(self.analyzer.compound_stats),
            'total_models': len(self.analyzer.available_models),
            'individual_models_analyzed': len(self.analyzer.individual_model_results),
            'data_source': self.analyzer.result_dir,
            'user': 'woyaokaoyanhaha',
            'version': '3.5.0_enhanced_model_details',
            'new_features': {
                'individual_model_filtering': True,
                'model_comparison': True,
                'model_specific_export': True,
                'threshold_based_filtering': True
            }
        }

        params_file = os.path.join(export_dir, "export_parameters.json")
        if safe_json_dump(params, params_file, indent=2, ensure_ascii=False):
            print(f"å¢å¼ºæ¨¡å‹è¯¦æƒ…ç‰ˆå¯¼å‡ºå‚æ•°å·²ä¿å­˜: {params_file}")


def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºä¸»çª—å£
    root = tk.Tk()

    # åˆ›å»ºåº”ç”¨
    app = EnhancedModelDetailsAnalyzerGUI(root)

    # è®¾ç½®çª—å£å…³é—­äº‹ä»¶
    def on_closing():
        if messagebox.askokcancel("é€€å‡º", "ç¡®å®šè¦é€€å‡ºå¢å¼ºæ¨¡å‹è¯¦æƒ…é¢„æµ‹ç»“æœåˆ†æå™¨å—ï¼Ÿ"):
            root.destroy()

    root.protocol("WM_DELETE_WINDOW", on_closing)

    # è¿è¡Œåº”ç”¨
    try:
        print("ğŸ¯ å¯åŠ¨å¢å¼ºæ¨¡å‹è¯¦æƒ…é¢„æµ‹ç»“æœåˆ†æå™¨ GUI v3.5...")
        print("ğŸ†• æ–°å¢åŠŸèƒ½: å•æ¨¡å‹ç­›é€‰åˆ†æ")
        print("âœ¨ æ ¸å¿ƒåŠŸèƒ½: æ”¯æŒè‡ªå®šä¹‰æ­£ä¾‹é¢„æµ‹é˜ˆå€¼")
        print("âš¡ æ€§èƒ½ä¼˜åŒ–: å¿«é€ŸåŠ è½½ + æ™ºèƒ½é‡åˆ†æ")
        print("ğŸ–±ï¸ ç•Œé¢ä¼˜åŒ–: å¯æ»šåŠ¨æ§åˆ¶é¢æ¿ + é¼ æ ‡æ»šè½®æ”¯æŒ")
        print("ğŸ¤– å•æ¨¡å‹åŠŸèƒ½: ç­›é€‰åˆ†æ + æ¨¡å‹å¯¹æ¯” + ä¸“é—¨å¯¼å‡º")
        print("ğŸ“Š å®Œæ•´å¯¼å‡º: ç®€å•/è¯¦ç»†/å•æ¨¡å‹å¤šç§å¯¼å‡ºé€‰é¡¹")
        print("âœ… ä¸­æ–‡å­—ä½“å·²é…ç½®")
        print("âœ… ç•Œé¢ç»„ä»¶å·²åŠ è½½")
        print("âœ… å¯æ»šåŠ¨åŠŸèƒ½å·²å¯ç”¨")
        print("âœ… å¢å¼ºé˜ˆå€¼åŠŸèƒ½å·²å¯ç”¨")
        print("âœ… å•æ¨¡å‹ç­›é€‰åŠŸèƒ½å·²å¯ç”¨")
        print("âœ… æ‰€æœ‰åŠŸèƒ½éƒ½å¯æ­£å¸¸è®¿é—®")
        print("âœ… å‡†å¤‡å°±ç»ªï¼")

        root.mainloop()

    except KeyboardInterrupt:
        print("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()