#!/usr/bin/env python3
"""
è›‹ç™½è´¨-åŒ–åˆç‰©ç‰¹å¾æå–è„šæœ¬ (DTIä¼˜åŒ–ç‰ˆæœ¬ - AAC+DPC) - æ— å‘½ä»¤è¡Œç‰ˆæœ¬
ä½œè€…: woyaokaoyanhaha
ç‰ˆæœ¬: 13.1 (AAC+DPCä¼˜åŒ– - æ— å‘½ä»¤è¡Œ)
æ—¥æœŸ: 2025-06-17 13:15:00
ä¿®å¤: ä½¿ç”¨AAC+DPCè›‹ç™½è´¨ç‰¹å¾å’ŒDTIä¼˜åŒ–çš„åˆ†å­æŒ‡çº¹ç‰¹å¾ï¼Œå»é™¤å‘½ä»¤è¡Œå‚æ•°
"""

import csv
import os
import subprocess
import sys
import json
import time
import warnings
import glob
import traceback
from pathlib import Path
from collections import defaultdict

warnings.filterwarnings('ignore')

# ============================================================================
# ç”¨æˆ·é…ç½®å‚æ•°åŒºåŸŸ - åœ¨æ­¤ä¿®æ”¹æ‰€æœ‰å‚æ•°
# ============================================================================

# è¾“å…¥æ–‡ä»¶è·¯å¾„ (å¿…é¡»è®¾ç½®)
INPUT_CSV_FILE = "coconut_csv_lite-05-2025 - å‰¯æœ¬.csv"  # ä¿®æ”¹ä¸ºæ‚¨çš„è¾“å…¥æ–‡ä»¶è·¯å¾„

# è¾“å‡ºç›®å½•è®¾ç½® (å¯é€‰ï¼Œç•™ç©ºåˆ™è‡ªåŠ¨ç”Ÿæˆ)
CUSTOM_OUTPUT_DIR = "coconut_csv_lite-05-2025ç‰¹å¾"  # ä¾‹å¦‚: "./my_output" æˆ–ç•™ç©º ""

# æ¢å¤è¿è¡Œè®¾ç½® (å¯é€‰)
RESUME_FROM_DIR = ""  # ä¾‹å¦‚: "./data_aac_dpc_features_20250617_131500" æˆ–ç•™ç©º ""

# è¿è¡Œæ¨¡å¼è®¾ç½®
TEST_MODE = False  # Trueè¡¨ç¤ºä»…æµ‹è¯•ï¼ŒFalseè¡¨ç¤ºæ­£å¸¸è¿è¡Œ
PRESERVE_ORDER = True  # Trueè¡¨ç¤ºä¿æŒè¾“å…¥æ–‡ä»¶é¡ºåº
LIST_RESUME_DIRS = False  # Trueè¡¨ç¤ºåˆ—å‡ºå¯æ¢å¤ç›®å½•

# ============================================================================

# æ£€æŸ¥å’Œå¯¼å…¥ä¾èµ–åº“
def check_dependencies():
    """æ£€æŸ¥å¹¶å¯¼å…¥å¿…è¦çš„ä¾èµ–åº“"""
    print("æ­£åœ¨æ£€æŸ¥ä¾èµ–åº“...")

    try:
        import numpy as np
        print(f"âœ… numpy {np.__version__}")
    except ImportError:
        print("âŒ numpy æœªå®‰è£…")
        return False

    try:
        import pandas as pd
        print(f"âœ… pandas {pd.__version__}")
    except ImportError:
        print("âŒ pandas æœªå®‰è£…")
        return False

    try:
        from rdkit import Chem
        from rdkit.Chem import Descriptors, AllChem, MACCSkeys, Fragments
        from rdkit.Chem.rdMolDescriptors import GetHashedAtomPairFingerprintAsBitVect
        print("âœ… rdkit")
    except ImportError:
        print("âŒ rdkit æœªå®‰è£…")
        return False

    print("ğŸ‰ æ‰€æœ‰ä¾èµ–åº“æ£€æŸ¥å®Œæˆ")
    return True


# æ£€æŸ¥ä¾èµ–åº“
if not check_dependencies():
    print("\nè¯·å®‰è£…ç¼ºå¤±çš„ä¾èµ–åº“:")
    print("pip install numpy pandas rdkit")
    sys.exit(1)

# ç°åœ¨å®‰å…¨å¯¼å…¥æ‰€æœ‰åº“
import numpy as np
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors, AllChem, MACCSkeys, Fragments
from rdkit.Chem.rdMolDescriptors import GetHashedAtomPairFingerprintAsBitVect

# DTIä¼˜åŒ–é…ç½®å‚æ•°
COLUMN_MAPPING = {
    'protein_accession': ['Protein_Accession', 'ProteinAccession', 'Accession', 'Protein_ID', 'ProteinID'],
    'sequence': ['Sequence', 'Protein_Sequence', 'ProteinSequence', 'Seq'],
    'compound_cid': ['Compound_CID', 'CompoundCID', 'CID', 'Compound_ID', 'CompoundID'],
    'smile': ['Smile', 'SMILES', 'Canonical_SMILES', 'CanonicalSMILES'],
    'label': ['label', 'Label', 'Class', 'Target', 'Y']
}

# AAC+DPCè›‹ç™½è´¨ç‰¹å¾å‚æ•°
AAC_DIM = 20  # æ°¨åŸºé…¸ç»„æˆç‰¹å¾ç»´åº¦
DPC_DIM = 400  # äºŒè‚½ç»„æˆç‰¹å¾ç»´åº¦
PROTEIN_ENHANCED_DIM = 10  # å¢å¼ºç‰¹å¾ç»´åº¦ (åˆ†ç»„æ°¨åŸºé…¸ã€ç†åŒ–æ€§è´¨ç­‰)
PROTEIN_TOTAL_DIM = AAC_DIM + DPC_DIM + PROTEIN_ENHANCED_DIM  # æ€»è›‹ç™½è´¨ç‰¹å¾ç»´åº¦: 430

# DTIä¼˜åŒ–çš„åŒ–åˆç‰©ç‰¹å¾å‚æ•°
DTI_ECFP4_BITS = 2048  # ECFP4æŒ‡çº¹ä½æ•°
DTI_MACCS_BITS = 167  # MACCSæŒ‡çº¹ä½æ•°
DTI_FCFP4_BITS = 2048  # FCFP4æŒ‡çº¹ä½æ•°
DTI_ATOM_PAIRS_BITS = 2048  # åŸå­å¯¹æŒ‡çº¹ä½æ•°
DTI_SUBSTRUCTURES_COUNT = 26  # DTIé‡è¦å­ç»“æ„æ•°
DTI_DRUG_FRAGMENTS_COUNT = 14  # è¯ç‰©ç‰‡æ®µæ•°
DTI_PHARMACOPHORE_COUNT = 6  # è¯æ•ˆå›¢ç‰¹å¾æ•°

# æ€»åŒ–åˆç‰©ç‰¹å¾ç»´åº¦
COMPOUND_TOTAL_DIM = (DTI_ECFP4_BITS + DTI_MACCS_BITS + DTI_FCFP4_BITS +
                      DTI_ATOM_PAIRS_BITS + DTI_SUBSTRUCTURES_COUNT * 2 +
                      DTI_DRUG_FRAGMENTS_COUNT + DTI_PHARMACOPHORE_COUNT)

# DTIé‡è¦å­ç»“æ„ï¼ˆSMARTSæ ¼å¼ï¼‰
DTI_IMPORTANT_SUBSTRUCTURES = {
    # è¯ç‰©éª¨æ¶
    'benzene_ring': 'c1ccccc1',
    'pyridine': 'c1ccncc1',
    'pyrimidine': 'c1cncnc1',
    'imidazole': 'c1cnc[nH]1',
    'indole': 'c1ccc2c(c1)cc[nH]2',
    'quinoline': 'c1ccc2c(c1)cccn2',

    # æ°¢é”®ä¾›ä½“/å—ä½“ï¼ˆä¸è›‹ç™½ç»“åˆé‡è¦ï¼‰
    'hydroxyl': '[OH]',
    'primary_amine': '[NH2]',
    'secondary_amine': '[NH1]',
    'carboxyl': 'C(=O)[OH]',
    'amide': '[NX3][CX3](=[OX1])[#6]',
    'carbonyl': '[CX3]=[OX1]',

    # è¯ç‰©å¸¸è§ç»“æ„
    'sulfonamide': '[SX4](=[OX1])(=[OX1])([NX3])[#6]',
    'urea': '[NX3][CX3](=[OX1])[NX3]',
    'ester': '[#6][CX3](=O)[OX2H0][#6]',
    'ether': '[OD2]([#6])[#6]',

    # æ‚ç¯ï¼ˆè¯ç‰©ä¸­å¸¸è§ï¼‰
    'morpholine': 'C1COCCN1',
    'piperidine': 'C1CCNCC1',
    'piperazine': 'C1CNCCN1',
    'pyrrolidine': 'C1CCNC1',
    'thiophene': 'c1ccsc1',
    'furan': 'c1ccoc1',

    # è¯æ•ˆå›¢é‡è¦ç»“æ„
    'aromatic_hydroxyl': 'c[OH]',
    'aromatic_amine': 'c[NH2]',
    'beta_lactam': '[C@H]1[C@@H](N1[*])[*]',
    'guanidine': '[NX3][CX3](=[NX3+])[NX3]'
}

SAVE_PROGRESS_INTERVAL = 10


def detect_column_names(csv_file):
    """è‡ªåŠ¨æ£€æµ‹CSVæ–‡ä»¶çš„åˆ—å"""
    print(f"æ­£åœ¨æ£€æµ‹CSVæ–‡ä»¶çš„åˆ—å: {csv_file}")

    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            header = next(reader)
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–CSVæ–‡ä»¶: {e}")
        return None, None

    detected_columns = {}

    for field_type, possible_names in COLUMN_MAPPING.items():
        detected_columns[field_type] = None

        for possible_name in possible_names:
            if possible_name in header:
                detected_columns[field_type] = possible_name
                break

    print("æ£€æµ‹åˆ°çš„åˆ—åæ˜ å°„:")
    for field_type, column_name in detected_columns.items():
        status = "âœ…" if column_name else "âŒ"
        print(f"  {status} {field_type}: {column_name or 'æœªæ‰¾åˆ°'}")

    return detected_columns, header


def list_resumable_directories():
    """åˆ—å‡ºå¯æ¢å¤çš„è¿è¡Œç›®å½•"""
    print("æœç´¢å¯æ¢å¤çš„è¿è¡Œç›®å½•...")

    patterns = ["*_aac_dpc_features_*"]
    found_dirs = []

    for pattern in patterns:
        dirs = glob.glob(pattern)
        for d in dirs:
            if os.path.isdir(d):
                found_dirs.append(d)

    if not found_dirs:
        print("âŒ æœªæ‰¾åˆ°å¯æ¢å¤çš„è¿è¡Œç›®å½•")
        return

    print(f"æ‰¾åˆ° {len(found_dirs)} ä¸ªå¯èƒ½çš„ç›®å½•:")

    for i, dir_path in enumerate(sorted(found_dirs), 1):
        progress_file = os.path.join(dir_path, "progress.json")
        print(f"\n{i}. ğŸ“ {dir_path}")

        if os.path.exists(progress_file):
            try:
                with open(progress_file, 'r') as f:
                    progress = json.load(f)
                status = "âœ… å®Œæˆ" if progress.get('completed', False) else "â³ æœªå®Œæˆ"
                print(f"   çŠ¶æ€: {status}")

                if not progress.get('completed', False):
                    proteins_done = progress.get('proteins_processed', 0)
                    proteins_total = progress.get('total_proteins', 0)
                    compounds_done = progress.get('compounds_processed', 0)
                    compounds_total = progress.get('total_compounds', 0)

                    print(f"   è›‹ç™½è´¨: {proteins_done}/{proteins_total}")
                    print(f"   åŒ–åˆç‰©: {compounds_done}/{compounds_total}")

            except Exception as e:
                print(f"   âŒ è¿›åº¦æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        else:
            print(f"   âŒ æ— è¿›åº¦æ–‡ä»¶")


def get_output_dir_name(input_csv_path, custom_output=None):
    """ç”Ÿæˆè¾“å‡ºç›®å½•å"""
    if custom_output:
        return custom_output

    filename = os.path.basename(input_csv_path)
    basename = os.path.splitext(filename)[0]
    timestamp = time.strftime('%Y%m%d_%H%M%S')
    safe_basename = "".join(c for c in basename if c.isalnum() or c in ('-', '_')).rstrip()

    if len(safe_basename) < 3:
        safe_basename = "protein_compound_features"

    return f"./{safe_basename}_aac_dpc_features_{timestamp}"


class ProgressManager:
    """è¿›åº¦ç®¡ç†å™¨"""

    def __init__(self, work_dir):
        self.work_dir = work_dir
        self.progress_file = os.path.join(work_dir, "progress.json")
        self.progress = self.load_progress()

    def load_progress(self):
        """åŠ è½½è¿›åº¦"""
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'r') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ è¿›åº¦æ–‡ä»¶è¯»å–å¤±è´¥: {e}")

        return {
            'start_time': time.time(),
            'proteins_processed': 0,
            'compounds_processed': 0,
            'total_proteins': 0,
            'total_compounds': 0,
            'protein_features_completed': [],
            'compound_features_completed': [],
            'completed': False,
            'last_update': time.time()
        }

    def save_progress(self):
        """ä¿å­˜è¿›åº¦"""
        self.progress['last_update'] = time.time()
        try:
            with open(self.progress_file, 'w') as f:
                json.dump(self.progress, f, indent=2)
        except Exception as e:
            print(f"âš ï¸ è¿›åº¦ä¿å­˜å¤±è´¥: {e}")

    def update_totals(self, total_proteins, total_compounds):
        """æ›´æ–°æ€»æ•°"""
        self.progress['total_proteins'] = total_proteins
        self.progress['total_compounds'] = total_compounds
        self.save_progress()

    def mark_protein_completed(self, accession):
        """æ ‡è®°è›‹ç™½è´¨å¤„ç†å®Œæˆ"""
        if accession not in self.progress['protein_features_completed']:
            self.progress['protein_features_completed'].append(accession)
            self.progress['proteins_processed'] = len(self.progress['protein_features_completed'])

    def mark_compound_completed(self, compound_cid):
        """æ ‡è®°åŒ–åˆç‰©å¤„ç†å®Œæˆ"""
        if compound_cid not in self.progress['compound_features_completed']:
            self.progress['compound_features_completed'].append(compound_cid)
            self.progress['compounds_processed'] = len(self.progress['compound_features_completed'])

    def is_protein_completed(self, accession):
        """æ£€æŸ¥è›‹ç™½è´¨æ˜¯å¦å·²å¤„ç†"""
        return accession in self.progress['protein_features_completed']

    def is_compound_completed(self, compound_cid):
        """æ£€æŸ¥åŒ–åˆç‰©æ˜¯å¦å·²å¤„ç†"""
        return compound_cid in self.progress['compound_features_completed']

    def mark_completed(self):
        """æ ‡è®°å…¨éƒ¨å®Œæˆ"""
        self.progress['completed'] = True
        self.progress['end_time'] = time.time()
        self.save_progress()

    def get_progress_info(self):
        """è·å–è¿›åº¦ä¿¡æ¯"""
        return {
            'proteins': f"{self.progress['proteins_processed']}/{self.progress['total_proteins']}",
            'compounds': f"{self.progress['compounds_processed']}/{self.progress['total_compounds']}",
            'protein_percent': (self.progress['proteins_processed'] / max(1, self.progress['total_proteins'])) * 100,
            'compound_percent': (self.progress['compounds_processed'] / max(1, self.progress['total_compounds'])) * 100
        }


class AACDPCProteinExtractor:
    """AAC+DPCè›‹ç™½è´¨ç‰¹å¾æå–å™¨"""

    def __init__(self):
        # 20ç§æ ‡å‡†æ°¨åŸºé…¸
        self.amino_acids = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',
                            'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']

        # æ°¨åŸºé…¸åˆ†ç»„ï¼ˆç”¨äºå¢å¼ºç‰¹å¾ï¼‰
        self.aa_groups = {
            'hydrophobic': 'AILMFWYV',  # ç–æ°´æ€§æ°¨åŸºé…¸
            'polar': 'STYNQ',  # ææ€§æ°¨åŸºé…¸
            'charged': 'DEKR',  # å¸¦ç”µæ°¨åŸºé…¸
            'aromatic': 'FWY',  # èŠ³é¦™æ—æ°¨åŸºé…¸
            'aliphatic': 'ILV',  # è„‚è‚ªæ—æ°¨åŸºé…¸
            'tiny': 'AGS',  # å¾®å°æ°¨åŸºé…¸
            'small': 'AGSNDCT',  # å°æ°¨åŸºé…¸
            'large': 'FHKRWYIELM'  # å¤§æ°¨åŸºé…¸
        }

        # æ°¨åŸºé…¸ç†åŒ–æ€§è´¨ [ç–æ°´æ€§æŒ‡æ•°, åˆ†å­é‡, ç­‰ç”µç‚¹]
        self.aa_properties = {
            'A': [1.8, 89.1, 6.0], 'C': [2.5, 121.0, 5.1], 'D': [-3.5, 133.1, 3.0],
            'E': [-3.5, 147.1, 4.2], 'F': [2.8, 165.2, 5.5], 'G': [-0.4, 75.1, 6.0],
            'H': [-3.2, 155.2, 7.6], 'I': [4.5, 131.2, 6.0], 'K': [-3.9, 146.2, 9.7],
            'L': [3.8, 131.2, 6.0], 'M': [1.9, 149.2, 5.7], 'N': [-3.5, 132.1, 5.4],
            'P': [-1.6, 115.1, 6.3], 'Q': [-3.5, 146.1, 5.7], 'R': [-4.5, 174.2, 10.8],
            'S': [-0.8, 105.1, 5.7], 'T': [-0.7, 119.1, 5.6], 'V': [4.2, 117.1, 6.0],
            'W': [-0.9, 204.2, 5.9], 'Y': [-1.3, 181.2, 5.7]
        }

    def extract_aac_features(self, sequence):
        """æå–æ°¨åŸºé…¸ç»„æˆç‰¹å¾ (AAC)"""
        aac_features = []

        # è®¡ç®—æ¯ç§æ°¨åŸºé…¸çš„é¢‘ç‡
        total_length = len(sequence)
        for aa in self.amino_acids:
            count = sequence.count(aa)
            frequency = count / total_length if total_length > 0 else 0.0
            aac_features.append(frequency)

        return aac_features

    def extract_dpc_features(self, sequence):
        """æå–äºŒè‚½ç»„æˆç‰¹å¾ (DPC)"""
        dpc_features = []

        # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„äºŒè‚½ç»„åˆ
        dipeptides = []
        for aa1 in self.amino_acids:
            for aa2 in self.amino_acids:
                dipeptides.append(aa1 + aa2)

        # è®¡ç®—æ¯ä¸ªäºŒè‚½çš„é¢‘ç‡
        total_dipeptides = len(sequence) - 1
        if total_dipeptides <= 0:
            return [0.0] * DPC_DIM

        for dipeptide in dipeptides:
            count = 0
            for i in range(len(sequence) - 1):
                if sequence[i:i + 2] == dipeptide:
                    count += 1
            frequency = count / total_dipeptides
            dpc_features.append(frequency)

        return dpc_features

    def extract_enhanced_features(self, sequence):
        """æå–å¢å¼ºç‰¹å¾"""
        enhanced_features = []

        if len(sequence) == 0:
            return [0.0] * PROTEIN_ENHANCED_DIM

        # 1. æ°¨åŸºé…¸åˆ†ç»„æ¯”ä¾‹
        for group_name, group_aa in list(self.aa_groups.items())[:5]:  # å–å‰5ä¸ªåˆ†ç»„
            ratio = sum(sequence.count(aa) for aa in group_aa) / len(sequence)
            enhanced_features.append(ratio)

        # 2. åºåˆ—é•¿åº¦ç‰¹å¾ (æ ‡å‡†åŒ–)
        length_feature = min(len(sequence) / 1000.0, 1.0)  # æ ‡å‡†åŒ–åˆ°[0,1]
        enhanced_features.append(length_feature)

        # 3. å¹³å‡ç–æ°´æ€§
        total_hydrophobicity = sum(self.aa_properties.get(aa, [0, 0, 0])[0]
                                   for aa in sequence if aa in self.aa_properties)
        avg_hydrophobicity = total_hydrophobicity / len(sequence) if len(sequence) > 0 else 0.0
        enhanced_features.append(avg_hydrophobicity)

        # 4. å¹³å‡åˆ†å­é‡
        total_mw = sum(self.aa_properties.get(aa, [0, 0, 0])[1]
                       for aa in sequence if aa in self.aa_properties)
        avg_mw = total_mw / len(sequence) if len(sequence) > 0 else 0.0
        # æ ‡å‡†åŒ–åˆ†å­é‡ (æ°¨åŸºé…¸åˆ†å­é‡å¤§çº¦åœ¨75-200ä¹‹é—´)
        normalized_mw = (avg_mw - 75) / (200 - 75) if avg_mw > 0 else 0.0
        enhanced_features.append(normalized_mw)

        # 5. å¹³å‡ç­‰ç”µç‚¹
        total_pi = sum(self.aa_properties.get(aa, [0, 0, 0])[2]
                       for aa in sequence if aa in self.aa_properties)
        avg_pi = total_pi / len(sequence) if len(sequence) > 0 else 0.0
        # æ ‡å‡†åŒ–ç­‰ç”µç‚¹ (å¤§çº¦åœ¨3-11ä¹‹é—´)
        normalized_pi = (avg_pi - 3) / (11 - 3) if avg_pi > 0 else 0.0
        enhanced_features.append(normalized_pi)

        # 6. Cç«¯å’ŒNç«¯æ°¨åŸºé…¸ç‰¹å¾ (å‰å5ä¸ªæ°¨åŸºé…¸çš„ç‰¹æ®Šç¼–ç )
        n_terminal_feature = 1.0 if len(sequence) > 0 and sequence[0] == 'M' else 0.0  # æ˜¯å¦ä»¥Må¼€å¤´
        enhanced_features.append(n_terminal_feature)

        # ç¡®ä¿ç‰¹å¾æ•°é‡æ­£ç¡®
        while len(enhanced_features) < PROTEIN_ENHANCED_DIM:
            enhanced_features.append(0.0)

        return enhanced_features[:PROTEIN_ENHANCED_DIM]

    def extract_all_features(self, sequence):
        """æå–æ‰€æœ‰è›‹ç™½è´¨ç‰¹å¾"""
        # åºåˆ—é¢„å¤„ç†ï¼šå»é™¤éæ ‡å‡†æ°¨åŸºé…¸
        cleaned_sequence = ''.join([aa for aa in sequence.upper() if aa in self.amino_acids])

        if len(cleaned_sequence) == 0:
            # å¦‚æœåºåˆ—ä¸ºç©ºï¼Œè¿”å›é›¶ç‰¹å¾
            return [0.0] * PROTEIN_TOTAL_DIM

        # æå–å„ç§ç‰¹å¾
        aac_features = self.extract_aac_features(cleaned_sequence)
        dpc_features = self.extract_dpc_features(cleaned_sequence)
        enhanced_features = self.extract_enhanced_features(cleaned_sequence)

        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        all_features = aac_features + dpc_features + enhanced_features

        # ç¡®ä¿ç‰¹å¾ç»´åº¦æ­£ç¡®
        if len(all_features) != PROTEIN_TOTAL_DIM:
            print(f"âš ï¸ è›‹ç™½è´¨ç‰¹å¾ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{PROTEIN_TOTAL_DIM}, å®é™…{len(all_features)}")
            # è¡¥é½æˆ–æˆªæ–­
            if len(all_features) < PROTEIN_TOTAL_DIM:
                all_features.extend([0.0] * (PROTEIN_TOTAL_DIM - len(all_features)))
            else:
                all_features = all_features[:PROTEIN_TOTAL_DIM]

        return all_features


class DTIOptimizedFingerprintExtractor:
    """DTIä¼˜åŒ–çš„åˆ†å­æŒ‡çº¹æå–å™¨"""

    def __init__(self):
        self.substructure_patterns = DTI_IMPORTANT_SUBSTRUCTURES

    def smiles_to_mol(self, smiles):
        """SMILESè½¬åˆ†å­å¯¹è±¡"""
        try:
            mol = Chem.MolFromSmiles(smiles)
            if mol is not None:
                Chem.SanitizeMol(mol)
            return mol
        except:
            return None

    def extract_ecfp4_fingerprint(self, mol):
        """æå–ECFP4åˆ†å­æŒ‡çº¹"""
        if mol is None:
            return [0] * DTI_ECFP4_BITS

        try:
            fp = AllChem.GetMorganFingerprintAsBitVect(
                mol,
                radius=2,
                nBits=DTI_ECFP4_BITS,
                useChirality=True,
                useBondTypes=True
            )
            return list(map(int, fp.ToBitString()))
        except:
            return [0] * DTI_ECFP4_BITS

    def extract_fcfp4_fingerprint(self, mol):
        """æå–FCFP4åŠŸèƒ½è¿æ¥æŒ‡çº¹"""
        if mol is None:
            return [0] * DTI_FCFP4_BITS

        try:
            fp = AllChem.GetMorganFingerprintAsBitVect(
                mol,
                radius=2,
                nBits=DTI_FCFP4_BITS,
                useFeatures=True,  # ä½¿ç”¨åŠŸèƒ½åŸå­ç±»å‹
                useChirality=True
            )
            return list(map(int, fp.ToBitString()))
        except:
            return [0] * DTI_FCFP4_BITS

    def extract_maccs_fingerprint(self, mol):
        """æå–MACCSåˆ†å­æŒ‡çº¹"""
        if mol is None:
            return [0] * DTI_MACCS_BITS

        try:
            fp = MACCSkeys.GenMACCSKeys(mol)
            return list(map(int, fp.ToBitString()))
        except:
            return [0] * DTI_MACCS_BITS

    def extract_atom_pairs_fingerprint(self, mol):
        """æå–åŸå­å¯¹æŒ‡çº¹"""
        if mol is None:
            return [0] * DTI_ATOM_PAIRS_BITS

        try:
            fp = GetHashedAtomPairFingerprintAsBitVect(
                mol,
                nBits=DTI_ATOM_PAIRS_BITS,
                includeChirality=True
            )
            return list(map(int, fp.ToBitString()))
        except:
            return [0] * DTI_ATOM_PAIRS_BITS

    def extract_dti_substructures(self, mol):
        """æå–DTIé‡è¦å­ç»“æ„ç‰¹å¾"""
        if mol is None:
            return [0] * (DTI_SUBSTRUCTURES_COUNT * 2)  # å­˜åœ¨æ€§ + è®¡æ•°

        features = []

        try:
            for name, pattern in self.substructure_patterns.items():
                pattern_mol = Chem.MolFromSmarts(pattern)
                if pattern_mol is not None:
                    # å­˜åœ¨æ€§ï¼ˆ0/1ï¼‰
                    has_match = mol.HasSubstructMatch(pattern_mol)
                    features.append(int(has_match))

                    # è®¡æ•°
                    matches = len(mol.GetSubstructMatches(pattern_mol))
                    features.append(matches)
                else:
                    features.extend([0, 0])
        except:
            features = [0] * (DTI_SUBSTRUCTURES_COUNT * 2)

        # ç¡®ä¿ç‰¹å¾æ•°é‡æ­£ç¡®
        while len(features) < DTI_SUBSTRUCTURES_COUNT * 2:
            features.append(0)

        return features[:DTI_SUBSTRUCTURES_COUNT * 2]

    def extract_drug_fragments(self, mol):
        """æå–è¯ç‰©ç‰¹å¼‚æ€§ç‰‡æ®µ"""
        if mol is None:
            return [0] * DTI_DRUG_FRAGMENTS_COUNT

        try:
            fragment_features = [
                Fragments.fr_benzene(mol),
                Fragments.fr_pyridine(mol),
                Fragments.fr_NH0(mol),
                Fragments.fr_NH1(mol),
                Fragments.fr_NH2(mol),
                Fragments.fr_Ar_OH(mol),
                Fragments.fr_phenol(mol),
                Fragments.fr_amide(mol),
                Fragments.fr_ester(mol),
                Fragments.fr_ether(mol),
                Fragments.fr_halogen(mol),
                Fragments.fr_nitro(mol),
                Fragments.fr_sulfide(mol),
                Fragments.fr_morpholine(mol)
            ]

            # å¤„ç†NaNå€¼
            processed_features = []
            for value in fragment_features:
                if np.isnan(value):
                    processed_features.append(0)
                else:
                    processed_features.append(int(value))

            return processed_features

        except:
            return [0] * DTI_DRUG_FRAGMENTS_COUNT

    def extract_pharmacophore_features(self, mol):
        """æå–è¯æ•ˆå›¢ç‰¹å¾"""
        if mol is None:
            return [0] * DTI_PHARMACOPHORE_COUNT

        try:
            # æ°¢é”®ä¾›ä½“/å—ä½“
            hbd_count = Descriptors.NumHBD(mol)
            hba_count = Descriptors.NumHBA(mol)

            # èŠ³é¦™ç¯æ•°
            aromatic_count = Descriptors.NumAromaticRings(mol)

            # ç–æ°´åŒºåŸŸï¼ˆèŠ³é¦™ç¢³åŸå­æ•°ï¼‰
            hydrophobic_count = sum(1 for atom in mol.GetAtoms()
                                    if atom.GetSymbol() == 'C' and atom.GetIsAromatic())

            # å¯ç”µç¦»åŸºå›¢ï¼ˆç®€åŒ–ï¼‰
            pos_ionizable = len(mol.GetSubstructMatches(Chem.MolFromSmarts('[NH3+,NH2+,NH+]')))
            neg_ionizable = len(mol.GetSubstructMatches(Chem.MolFromSmarts('[O-,COO-]')))

            return [hbd_count, hba_count, aromatic_count, hydrophobic_count, pos_ionizable, neg_ionizable]

        except:
            return [0] * DTI_PHARMACOPHORE_COUNT

    def extract_all_features(self, smiles):
        """æå–æ‰€æœ‰DTIä¼˜åŒ–ç‰¹å¾"""
        mol = self.smiles_to_mol(smiles)

        # ECFP4æŒ‡çº¹
        ecfp4_features = self.extract_ecfp4_fingerprint(mol)

        # FCFP4æŒ‡çº¹
        fcfp4_features = self.extract_fcfp4_fingerprint(mol)

        # MACCSæŒ‡çº¹
        maccs_features = self.extract_maccs_fingerprint(mol)

        # åŸå­å¯¹æŒ‡çº¹
        atom_pairs_features = self.extract_atom_pairs_fingerprint(mol)

        # DTIå­ç»“æ„ç‰¹å¾
        dti_sub_features = self.extract_dti_substructures(mol)

        # è¯ç‰©ç‰‡æ®µç‰¹å¾
        drug_frag_features = self.extract_drug_fragments(mol)

        # è¯æ•ˆå›¢ç‰¹å¾
        pharm_features = self.extract_pharmacophore_features(mol)

        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        all_features = (ecfp4_features + fcfp4_features + maccs_features +
                        atom_pairs_features + dti_sub_features +
                        drug_frag_features + pharm_features)

        return all_features


class FeatureExtractor:
    """ç‰¹å¾æå–å™¨ä¸»ç±» - AAC+DPCç‰ˆæœ¬"""

    def __init__(self, work_dir, input_filename, resume_mode=False, preserve_order=True):
        self.work_dir = work_dir
        self.input_filename = input_filename
        self.resume_mode = resume_mode
        self.preserve_order = preserve_order
        self.temp_dir = os.path.join(work_dir, "temp")
        self.output_dir = os.path.join(work_dir, "output")
        self.cache_dir = os.path.join(work_dir, "cache")

        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        for dir_path in [self.temp_dir, self.output_dir, self.cache_dir]:
            os.makedirs(dir_path, exist_ok=True)

        # åˆå§‹åŒ–è¿›åº¦ç®¡ç†å™¨
        self.progress_manager = ProgressManager(work_dir)

        # åˆå§‹åŒ–ç‰¹å¾æå–å™¨
        self.protein_extractor = AACDPCProteinExtractor()
        self.fingerprint_extractor = DTIOptimizedFingerprintExtractor()

        # å­˜å‚¨æ•°æ® - ä¿æŒåŸå§‹é¡ºåº
        self.original_records = []
        self.unique_proteins = {}
        self.unique_compounds = {}
        self.column_mapping = {}

        print(f"ğŸ“ å·¥ä½œç›®å½•: {work_dir}")
        print(f"ğŸ”„ è¿è¡Œæ¨¡å¼: {'æ¢å¤è¿è¡Œ' if resume_mode else 'æ–°å»ºè¿è¡Œ'}")
        print(f"ğŸ“‹ ä¿æŒé¡ºåº: {'æ˜¯' if preserve_order else 'å¦'}")
        print(f"ğŸ§¬ è›‹ç™½è´¨ç‰¹å¾ç»´åº¦: {PROTEIN_TOTAL_DIM} (AAC+DPC)")
        print(f"ğŸ’Š åŒ–åˆç‰©ç‰¹å¾ç»´åº¦: {COMPOUND_TOTAL_DIM} (DTIä¼˜åŒ–)")

        if resume_mode:
            progress_info = self.progress_manager.get_progress_info()
            print(f"å½“å‰è¿›åº¦:")
            print(f"  è›‹ç™½è´¨: {progress_info['proteins']} ({progress_info['protein_percent']:.1f}%)")
            print(f"  åŒ–åˆç‰©: {progress_info['compounds']} ({progress_info['compound_percent']:.1f}%)")

    def load_and_deduplicate(self, input_csv):
        """åŠ è½½æ•°æ®å¹¶å»é‡ - ä¿æŒåŸå§‹é¡ºåº"""
        print("\n" + "=" * 60)
        print("ğŸ“‚ æ•°æ®åŠ è½½å’Œå»é‡é˜¶æ®µ (ä¿æŒåŸå§‹é¡ºåº)")
        print("=" * 60)

        detected_columns, header = detect_column_names(input_csv)
        if not detected_columns:
            return 0, 0

        self.column_mapping = detected_columns

        # æ£€æŸ¥å¿…éœ€åˆ—
        required_fields = ['protein_accession', 'sequence', 'compound_cid', 'smile']
        missing_fields = [field for field in required_fields if not detected_columns[field]]

        if missing_fields:
            print(f"\nâŒ é”™è¯¯: æœªæ‰¾åˆ°å¿…éœ€çš„åˆ—: {missing_fields}")
            print(f"å¯ç”¨çš„åˆ—: {header}")
            return 0, 0

        print("\næ­£åœ¨åŠ è½½æ•°æ®å¹¶å»é‡ï¼ˆä¿æŒåŸå§‹é¡ºåºï¼‰...")

        # ä¿å­˜åŸå§‹è®°å½•é¡ºåº
        self.original_records = []
        seen_proteins = set()
        seen_compounds = set()
        row_number = 0

        try:
            with open(input_csv, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)

                for row in reader:
                    row_number += 1

                    accession = row[detected_columns['protein_accession']].strip()
                    sequence = row[detected_columns['sequence']].strip().upper()
                    compound_cid = row[detected_columns['compound_cid']].strip()
                    smile = row[detected_columns['smile']].strip()

                    label = ''
                    if detected_columns['label']:
                        label = row[detected_columns['label']].strip()

                    # ä¿å­˜æ¯æ¡åŸå§‹è®°å½•
                    original_record = {
                        'original_row_number': row_number,
                        'accession': accession,
                        'sequence': sequence,
                        'compound_cid': compound_cid,
                        'smile': smile,
                        'label': label
                    }
                    self.original_records.append(original_record)

                    # æ”¶é›†å”¯ä¸€çš„è›‹ç™½è´¨
                    if accession not in seen_proteins:
                        self.unique_proteins[accession] = {
                            'accession': accession,
                            'sequence': sequence,
                            'first_occurrence_row': row_number
                        }
                        seen_proteins.add(accession)

                    # æ”¶é›†å”¯ä¸€çš„åŒ–åˆç‰©
                    if compound_cid not in seen_compounds:
                        self.unique_compounds[compound_cid] = {
                            'compound_cid': compound_cid,
                            'smile': smile,
                            'first_occurrence_row': row_number
                        }
                        seen_compounds.add(compound_cid)

        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return 0, 0

        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"  æ€»è®°å½•æ•°: {len(self.original_records)}")
        print(f"  å”¯ä¸€è›‹ç™½è´¨æ•°: {len(self.unique_proteins)}")
        print(f"  å”¯ä¸€åŒ–åˆç‰©æ•°: {len(self.unique_compounds)}")
        print(f"  ä¿æŒåŸå§‹é¡ºåº: âœ…")

        self.progress_manager.update_totals(len(self.unique_proteins), len(self.unique_compounds))

        return len(self.unique_proteins), len(self.unique_compounds)

    def process_unique_proteins(self):
        """å¤„ç†å”¯ä¸€è›‹ç™½è´¨ - AAC+DPCç‰¹å¾"""
        print("\n" + "=" * 60)
        print("ğŸ§¬ è›‹ç™½è´¨AAC+DPCç‰¹å¾æå–é˜¶æ®µ")
        print("=" * 60)
        print(f"éœ€è¦å¤„ç† {len(self.unique_proteins)} ä¸ªå”¯ä¸€è›‹ç™½è´¨")
        print(f"ç‰¹å¾ç»´åº¦: AAC({AAC_DIM}) + DPC({DPC_DIM}) + Enhanced({PROTEIN_ENHANCED_DIM}) = {PROTEIN_TOTAL_DIM}")

        protein_features = {}
        processed = 0

        for accession, protein_info in self.unique_proteins.items():
            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
            if self.progress_manager.is_protein_completed(accession):
                safe_acc = accession.replace('/', '_').replace('\\', '_').replace('|', '_')
                cache_file = os.path.join(self.cache_dir, f"protein_{safe_acc}_aac_dpc_features.json")
                if os.path.exists(cache_file):
                    try:
                        with open(cache_file, 'r') as f:
                            cached_features = json.load(f)
                        protein_features[accession] = cached_features
                        processed += 1
                        continue
                    except:
                        pass

            processed += 1
            progress_info = self.progress_manager.get_progress_info()

            print(f"ğŸ”„ {processed}/{len(self.unique_proteins)} - {accession} "
                  f"[è›‹ç™½{progress_info['protein_percent']:.1f}% åŒ–åˆç‰©{progress_info['compound_percent']:.1f}%]")

            # æ£€æŸ¥ç¼“å­˜
            safe_acc = accession.replace('/', '_').replace('\\', '_').replace('|', '_')
            cache_file = os.path.join(self.cache_dir, f"protein_{safe_acc}_aac_dpc_features.json")

            if os.path.exists(cache_file):
                with open(cache_file, 'r') as f:
                    cached_features = json.load(f)
                protein_features[accession] = cached_features
                self.progress_manager.mark_protein_completed(accession)

                if processed % SAVE_PROGRESS_INTERVAL == 0:
                    self.progress_manager.save_progress()
                continue

            # æå–AAC+DPCç‰¹å¾
            sequence = protein_info['sequence']

            try:
                aac_dpc_features = self.protein_extractor.extract_all_features(sequence)

                feature_data = {
                    'accession': accession,
                    'sequence_length': len(sequence),
                    'aac_dpc_features': aac_dpc_features,
                    'feature_dimension': len(aac_dpc_features)
                }

                protein_features[accession] = feature_data

                with open(cache_file, 'w') as f:
                    json.dump(feature_data, f)

                self.progress_manager.mark_protein_completed(accession)
                print(f"  âœ… å®Œæˆ (ç»´åº¦: {len(aac_dpc_features)})")

            except Exception as e:
                print(f"  âŒ å¤±è´¥: {e}")
                feature_data = {
                    'accession': accession,
                    'sequence_length': len(sequence),
                    'aac_dpc_features': [0.0] * PROTEIN_TOTAL_DIM,
                    'feature_dimension': PROTEIN_TOTAL_DIM
                }
                protein_features[accession] = feature_data
                self.progress_manager.mark_protein_completed(accession)

            if processed % SAVE_PROGRESS_INTERVAL == 0:
                self.progress_manager.save_progress()
                print(f"  ğŸ’¾ å·²ä¿å­˜è¿›åº¦")

        self.progress_manager.save_progress()
        print(f"\nâœ… è›‹ç™½è´¨AAC+DPCç‰¹å¾æå–å®Œæˆ: {len(protein_features)}/{len(self.unique_proteins)}")

        return protein_features

    def process_unique_compounds(self):
        """å¤„ç†å”¯ä¸€åŒ–åˆç‰© - DTIä¼˜åŒ–ç‰ˆæœ¬"""
        print("\n" + "=" * 60)
        print("ğŸ’Š åŒ–åˆç‰©DTIç‰¹å¾æå–é˜¶æ®µ")
        print("=" * 60)
        print(f"éœ€è¦å¤„ç† {len(self.unique_compounds)} ä¸ªå”¯ä¸€åŒ–åˆç‰©")
        print(f"DTIç‰¹å¾ç»´åº¦: {COMPOUND_TOTAL_DIM}")

        compound_features = {}
        processed = 0

        for compound_cid, compound_info in self.unique_compounds.items():
            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
            if self.progress_manager.is_compound_completed(compound_cid):
                safe_cid = str(compound_cid).replace('/', '_').replace('\\', '_').replace('|', '_')
                cache_file = os.path.join(self.cache_dir, f"compound_{safe_cid}_dti_features.json")
                if os.path.exists(cache_file):
                    try:
                        with open(cache_file, 'r') as f:
                            cached_features = json.load(f)
                        compound_features[compound_cid] = cached_features
                        processed += 1
                        continue
                    except:
                        pass

            processed += 1
            progress_info = self.progress_manager.get_progress_info()

            print(f"ğŸ”„ {processed}/{len(self.unique_compounds)} - {compound_cid} "
                  f"[è›‹ç™½{progress_info['protein_percent']:.1f}% åŒ–åˆç‰©{progress_info['compound_percent']:.1f}%]")

            # æ£€æŸ¥ç¼“å­˜
            safe_cid = str(compound_cid).replace('/', '_').replace('\\', '_').replace('|', '_')
            cache_file = os.path.join(self.cache_dir, f"compound_{safe_cid}_dti_features.json")

            if os.path.exists(cache_file):
                with open(cache_file, 'r') as f:
                    cached_features = json.load(f)
                compound_features[compound_cid] = cached_features
                self.progress_manager.mark_compound_completed(compound_cid)

                if processed % SAVE_PROGRESS_INTERVAL == 0:
                    self.progress_manager.save_progress()
                continue

            # æå–DTIä¼˜åŒ–ç‰¹å¾
            smile = compound_info['smile']

            try:
                dti_features = self.fingerprint_extractor.extract_all_features(smile)

                feature_data = {
                    'compound_cid': compound_cid,
                    'smile': smile,
                    'dti_features': dti_features,
                    'feature_dimension': len(dti_features)
                }

                compound_features[compound_cid] = feature_data

                with open(cache_file, 'w') as f:
                    json.dump(feature_data, f)

                self.progress_manager.mark_compound_completed(compound_cid)
                print(f"  âœ… å®Œæˆ (ç»´åº¦: {len(dti_features)})")

            except Exception as e:
                print(f"  âŒ å¤±è´¥: {e}")
                feature_data = {
                    'compound_cid': compound_cid,
                    'smile': smile,
                    'dti_features': [0.0] * COMPOUND_TOTAL_DIM,
                    'feature_dimension': COMPOUND_TOTAL_DIM
                }
                compound_features[compound_cid] = feature_data
                self.progress_manager.mark_compound_completed(compound_cid)

            if processed % SAVE_PROGRESS_INTERVAL == 0:
                self.progress_manager.save_progress()
                print(f"  ğŸ’¾ å·²ä¿å­˜è¿›åº¦")

        self.progress_manager.save_progress()
        print(f"\nâœ… åŒ–åˆç‰©DTIç‰¹å¾æå–å®Œæˆ: {len(compound_features)}/{len(self.unique_compounds)}")

        return compound_features

    def combine_and_save_features(self, protein_features, compound_features):
        """ç»„åˆç‰¹å¾å¹¶ä¿å­˜ - AAC+DPCç‰ˆæœ¬"""
        print("\n" + "=" * 60)
        print("ğŸ”— ç‰¹å¾ç»„åˆå’Œä¿å­˜é˜¶æ®µ (AAC+DPC+DTIä¼˜åŒ–ï¼Œä¸¥æ ¼ä¿æŒåŸå§‹é¡ºåº)")
        print("=" * 60)

        # ç”ŸæˆAAC+DPCçš„ç‰¹å¾åç§°
        protein_names = []

        # AACç‰¹å¾å
        amino_acids = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',
                       'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']
        for aa in amino_acids:
            protein_names.append(f'AAC_{aa}')

        # DPCç‰¹å¾å
        for aa1 in amino_acids:
            for aa2 in amino_acids:
                protein_names.append(f'DPC_{aa1}{aa2}')

        # å¢å¼ºç‰¹å¾å
        enhanced_names = ['Enhanced_Hydrophobic', 'Enhanced_Polar', 'Enhanced_Charged',
                          'Enhanced_Aromatic', 'Enhanced_Aliphatic', 'Enhanced_Length',
                          'Enhanced_AvgHydrophobicity', 'Enhanced_AvgMW', 'Enhanced_AvgPI',
                          'Enhanced_NTerminal']
        protein_names.extend(enhanced_names)

        # DTIä¼˜åŒ–çš„åŒ–åˆç‰©ç‰¹å¾åç§°
        compound_names = []

        # ECFP4ç‰¹å¾å
        for i in range(DTI_ECFP4_BITS):
            compound_names.append(f'ECFP4_{i}')

        # FCFP4ç‰¹å¾å
        for i in range(DTI_FCFP4_BITS):
            compound_names.append(f'FCFP4_{i}')

        # MACCSç‰¹å¾å
        for i in range(DTI_MACCS_BITS):
            compound_names.append(f'MACCS_{i}')

        # åŸå­å¯¹ç‰¹å¾å
        for i in range(DTI_ATOM_PAIRS_BITS):
            compound_names.append(f'AtomPairs_{i}')

        # DTIå­ç»“æ„ç‰¹å¾å
        for name in DTI_IMPORTANT_SUBSTRUCTURES.keys():
            compound_names.append(f'DTI_Sub_{name}')
            compound_names.append(f'DTI_Count_{name}')

        # è¯ç‰©ç‰‡æ®µç‰¹å¾å
        drug_fragments = [
            'fr_benzene', 'fr_pyridine', 'fr_NH0', 'fr_NH1', 'fr_NH2',
            'fr_Ar_OH', 'fr_phenol', 'fr_amide', 'fr_ester', 'fr_ether',
            'fr_halogen', 'fr_nitro', 'fr_sulfide', 'fr_morpholine'
        ]
        for frag in drug_fragments:
            compound_names.append(f'DrugFrag_{frag}')

        # è¯æ•ˆå›¢ç‰¹å¾å
        pharm_features = ['HBD_count', 'HBA_count', 'Aromatic_count',
                          'Hydrophobic_count', 'PosIonizable', 'NegIonizable']
        for pharm in pharm_features:
            compound_names.append(f'Pharm_{pharm}')

        # æŒ‰åŸå§‹è®°å½•é¡ºåºå¤„ç†
        all_results = []

        print(f"æ­£åœ¨æŒ‰åŸå§‹é¡ºåºç»„åˆ {len(self.original_records)} æ¡è®°å½•çš„AAC+DPC+DTIç‰¹å¾...")
        print(f"è›‹ç™½è´¨ç‰¹å¾ç»´åº¦: {PROTEIN_TOTAL_DIM} (AAC+DPC)")
        print(f"åŒ–åˆç‰©ç‰¹å¾ç»´åº¦: {COMPOUND_TOTAL_DIM} (DTIä¼˜åŒ–)")
        print(f"æ€»ç‰¹å¾ç»´åº¦: {PROTEIN_TOTAL_DIM + COMPOUND_TOTAL_DIM}")

        for original_record in self.original_records:
            accession = original_record['accession']
            compound_cid = original_record['compound_cid']

            result = {
                'Original_Row_Number': original_record['original_row_number'],
                'Protein_Accession': accession,
                'Compound_CID': compound_cid,
                'Smile': original_record['smile'],
                'Label': original_record['label']
            }

            # æ·»åŠ è›‹ç™½è´¨AAC+DPCç‰¹å¾
            if accession in protein_features:
                prot_features = protein_features[accession]
                result['Sequence_Length'] = prot_features['sequence_length']

                # AAC+DPCç‰¹å¾
                aac_dpc_features = prot_features['aac_dpc_features']
                for i, name in enumerate(protein_names):
                    if i < len(aac_dpc_features):
                        result[name] = aac_dpc_features[i]
                    else:
                        result[name] = 0.0
            else:
                result['Sequence_Length'] = len(original_record['sequence'])
                for name in protein_names:
                    result[name] = 0.0

            # æ·»åŠ DTIä¼˜åŒ–çš„åŒ–åˆç‰©ç‰¹å¾
            if compound_cid in compound_features:
                comp_features = compound_features[compound_cid]['dti_features']
                for i, name in enumerate(compound_names):
                    if i < len(comp_features):
                        result[name] = comp_features[i]
                    else:
                        result[name] = 0.0
            else:
                for name in compound_names:
                    result[name] = 0.0

            all_results.append(result)

        # éªŒè¯é¡ºåº
        print("ğŸ” éªŒè¯è¾“å‡ºé¡ºåº...")
        order_verification_passed = True
        for i, result in enumerate(all_results):
            expected_row = i + 1
            actual_row = result['Original_Row_Number']
            if expected_row != actual_row:
                print(f"âŒ é¡ºåºé”™è¯¯ï¼šä½ç½® {i + 1} åº”è¯¥æ˜¯ç¬¬ {expected_row} è¡Œï¼Œä½†å®é™…æ˜¯ç¬¬ {actual_row} è¡Œ")
                order_verification_passed = False
                break

        if order_verification_passed:
            print("âœ… è¾“å‡ºé¡ºåºéªŒè¯é€šè¿‡ï¼šä¸è¾“å…¥æ–‡ä»¶å®Œå…¨ä¸€è‡´")
        else:
            print("âŒ è¾“å‡ºé¡ºåºéªŒè¯å¤±è´¥")
            return None

        # ä¿å­˜ç»“æœ
        base_name = os.path.splitext(os.path.basename(self.input_filename))[0]

        # ä¸»è¦ç»“æœæ–‡ä»¶ï¼ˆAAC+DPC+DTIç‰¹å¾ï¼‰
        combined_file = os.path.join(self.output_dir, f'{base_name}_aac_dpc_dti_combined_features.csv')
        with open(combined_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)

            header = ['Protein_Accession'] + protein_names + ['Compound_CID'] + compound_names + ['Label']
            writer.writerow(header)

            for result in all_results:
                row = [result['Protein_Accession']]
                for name in protein_names:
                    row.append(result[name])
                row.append(result['Compound_CID'])
                for name in compound_names:
                    row.append(result[name])
                row.append(result['Label'])
                writer.writerow(row)

        # è¯¦ç»†ç»“æœæ–‡ä»¶
        detailed_file = os.path.join(self.output_dir, f'{base_name}_aac_dpc_dti_detailed_features.csv')
        with open(detailed_file, 'w', newline='', encoding='utf-8') as f:
            fieldnames = ['Original_Row_Number', 'Protein_Accession', 'Compound_CID', 'Smile',
                          'Sequence_Length'] + protein_names + compound_names + ['Label']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(all_results)

        # AAC+DPCç‰¹å¾ç»Ÿè®¡æ–‡ä»¶
        stats_file = os.path.join(self.output_dir, f'{base_name}_aac_dpc_dti_processing_stats.json')
        stats = {
            'input_file': self.input_filename,
            'processing_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'user': 'woyaokaoyanhaha',
            'version': '13.1 (AAC+DPC+DTIä¼˜åŒ– - æ— å‘½ä»¤è¡Œ)',
            'resume_mode': self.resume_mode,
            'preserve_order': self.preserve_order,
            'work_directory': self.work_dir,
            'total_records': len(all_results),
            'unique_proteins': len(self.unique_proteins),
            'unique_compounds': len(self.unique_compounds),
            'order_verification_passed': order_verification_passed,
            'feature_dimensions': {
                'protein_aac': AAC_DIM,
                'protein_dpc': DPC_DIM,
                'protein_enhanced': PROTEIN_ENHANCED_DIM,
                'protein_total': PROTEIN_TOTAL_DIM,
                'compound_ecfp4': DTI_ECFP4_BITS,
                'compound_fcfp4': DTI_FCFP4_BITS,
                'compound_maccs': DTI_MACCS_BITS,
                'compound_atom_pairs': DTI_ATOM_PAIRS_BITS,
                'compound_substructures': DTI_SUBSTRUCTURES_COUNT * 2,
                'compound_fragments': DTI_DRUG_FRAGMENTS_COUNT,
                'compound_pharmacophore': DTI_PHARMACOPHORE_COUNT,
                'compound_total': COMPOUND_TOTAL_DIM,
                'total_features': PROTEIN_TOTAL_DIM + COMPOUND_TOTAL_DIM
            }
        }

        with open(stats_file, 'w') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)

        print(f"âœ… AAC+DPC+DTIä¼˜åŒ–ç‰¹å¾æ–‡ä»¶å·²ä¿å­˜:")
        print(f"  ğŸ“Š ä¸»è¦ç»“æœ: {combined_file}")
        print(f"  ğŸ“‹ è¯¦ç»†ç»“æœ: {detailed_file}")
        print(f"  ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯: {stats_file}")
        print(f"  âœ… é¡ºåºä¿æŒ: {'å®Œç¾' if order_verification_passed else 'æœ‰é—®é¢˜'}")
        print(f"  ğŸ§¬ æ€»ç‰¹å¾ç»´åº¦: {PROTEIN_TOTAL_DIM + COMPOUND_TOTAL_DIM}")

        return stats


def main():
    """ä¸»å‡½æ•° - æ— å‘½ä»¤è¡Œç‰ˆæœ¬"""
    print("\n" + "=" * 80)
    print("ğŸ§¬ è›‹ç™½è´¨-åŒ–åˆç‰©ç‰¹å¾æå–è„šæœ¬ (AAC+DPC+DTIä¼˜åŒ–ç‰ˆæœ¬ - æ— å‘½ä»¤è¡Œ)")
    print(f"ğŸ‘¤ ç”¨æˆ·: woyaokaoyanhaha")
    print(f"ğŸ“… æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ¯ AAC+DPC+DTIç‰¹å¾ç»´åº¦: {PROTEIN_TOTAL_DIM + COMPOUND_TOTAL_DIM}")
    print(f"ğŸ”§ ç‰ˆæœ¬: 13.1 (AAC+DPCè›‹ç™½è´¨ç‰¹å¾ + DTIä¼˜åŒ–åŒ–åˆç‰©ç‰¹å¾ - æ— å‘½ä»¤è¡Œ)")
    print("=" * 80)

    try:
        # å¤„ç†ç‰¹æ®Šæ¨¡å¼
        if LIST_RESUME_DIRS:
            list_resumable_directories()
            return 0

        if TEST_MODE:
            print("ğŸ§ª æµ‹è¯•æ¨¡å¼ - æ£€æŸ¥æ–‡ä»¶å’Œç¯å¢ƒ")
            if INPUT_CSV_FILE:
                detected_columns, header = detect_column_names(INPUT_CSV_FILE)
                if detected_columns:
                    print("âœ… CSVæ–‡ä»¶æ ¼å¼æ£€æŸ¥é€šè¿‡")
                else:
                    print("âŒ CSVæ–‡ä»¶æ ¼å¼æ£€æŸ¥å¤±è´¥")
                    return 1

                print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡")
            else:
                print("âŒ ç¼ºå°‘è¾“å…¥æ–‡ä»¶å‚æ•°")
                return 1
            return 0

        # æ£€æŸ¥å¿…éœ€å‚æ•°
        if not INPUT_CSV_FILE:
            print("âŒ é”™è¯¯: è¯·åœ¨ä»£ç å¼€å¤´è®¾ç½® INPUT_CSV_FILE å‚æ•°")
            print("ä¾‹å¦‚: INPUT_CSV_FILE = 'data.csv'")
            return 1

        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(INPUT_CSV_FILE):
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {INPUT_CSV_FILE}")
            return 1

        # ç¡®å®šå·¥ä½œç›®å½•
        resume_mode = False
        if RESUME_FROM_DIR:
            if not os.path.exists(RESUME_FROM_DIR):
                print(f"âŒ æ¢å¤ç›®å½•ä¸å­˜åœ¨: {RESUME_FROM_DIR}")
                return 1

            progress_file = os.path.join(RESUME_FROM_DIR, "progress.json")
            if not os.path.exists(progress_file):
                print(f"âŒ æ¢å¤ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°è¿›åº¦æ–‡ä»¶")
                return 1

            work_dir = RESUME_FROM_DIR
            resume_mode = True
        else:
            work_dir = get_output_dir_name(INPUT_CSV_FILE, CUSTOM_OUTPUT_DIR)

            if os.path.exists(work_dir):
                print(f"âš ï¸ è¾“å‡ºç›®å½•å·²å­˜åœ¨: {work_dir}")
                print("æ­£åœ¨åˆ é™¤å¹¶é‡å»ºç›®å½•...")
                import shutil
                shutil.rmtree(work_dir)
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤ç›®å½•: {work_dir}")

        # åˆå§‹åŒ–AAC+DPC+DTIä¼˜åŒ–ç‰¹å¾æå–å™¨
        extractor = FeatureExtractor(
            work_dir,
            INPUT_CSV_FILE,
            resume_mode,
            preserve_order=PRESERVE_ORDER
        )

        start_time = time.time()

        # 1. åŠ è½½å’Œå»é‡
        unique_protein_count, unique_compound_count = extractor.load_and_deduplicate(INPUT_CSV_FILE)
        if unique_protein_count == 0 or unique_compound_count == 0:
            print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
            return 1

        # 2. å¤„ç†è›‹ç™½è´¨AAC+DPCç‰¹å¾
        protein_features = extractor.process_unique_proteins()

        # 3. å¤„ç†åŒ–åˆç‰©DTIç‰¹å¾
        compound_features = extractor.process_unique_compounds()

        # 4. ç»„åˆAAC+DPC+DTIç‰¹å¾å¹¶ä¿å­˜
        stats = extractor.combine_and_save_features(protein_features, compound_features)
        if not stats:
            print("âŒ AAC+DPC+DTIç‰¹å¾ç»„åˆå¤±è´¥")
            return 1

        # 5. æ ‡è®°å®Œæˆ
        extractor.progress_manager.mark_completed()

        # 6. è¾“å‡ºAAC+DPC+DTIç»Ÿè®¡
        end_time = time.time()
        processing_time = end_time - start_time

        print("\n" + "=" * 80)
        print("ğŸ‰ AAC+DPC+DTIä¼˜åŒ–ç‰¹å¾æå–å®Œæˆ!")
        print(f"â±ï¸ æ€»å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
        if unique_protein_count > 0:
            print(f"ğŸ§¬ å¹³å‡æ¯ä¸ªè›‹ç™½è´¨: {processing_time / unique_protein_count:.2f} ç§’")
        if unique_compound_count > 0:
            print(f"ğŸ’Š å¹³å‡æ¯ä¸ªåŒ–åˆç‰©: {processing_time / unique_compound_count:.2f} ç§’")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {work_dir}")

        # æ˜¾ç¤ºAAC+DPC+DTIç‰¹å¾ç»Ÿè®¡
        print(f"\nğŸ“Š AAC+DPC+DTIç‰¹å¾æå–ç»Ÿè®¡:")
        print(f"  è›‹ç™½è´¨AAC+DPCç‰¹å¾æå–: 100%")
        print(f"  åŒ–åˆç‰©DTIç‰¹å¾æå–: 100%")
        print(f"  è¾“å‡ºé¡ºåºä¿æŒ: âœ… å®Œç¾")

        # AAC+DPC+DTIç‰¹å¾ç»´åº¦ç»Ÿè®¡
        print(f"\nğŸ¯ AAC+DPC+DTIç‰¹å¾ç»´åº¦è¯¦æƒ…:")
        print(f"  è›‹ç™½è´¨ç‰¹å¾ (æ€»è®¡: {PROTEIN_TOTAL_DIM} ç»´):")
        print(f"    - AAC (æ°¨åŸºé…¸ç»„æˆ): {AAC_DIM} ç»´")
        print(f"    - DPC (äºŒè‚½ç»„æˆ): {DPC_DIM} ç»´")
        print(f"    - Enhanced (å¢å¼ºç‰¹å¾): {PROTEIN_ENHANCED_DIM} ç»´")
        print(f"  åŒ–åˆç‰©DTIç‰¹å¾ (æ€»è®¡: {COMPOUND_TOTAL_DIM} ç»´):")
        print(f"    - ECFP4æŒ‡çº¹: {DTI_ECFP4_BITS} ä½")
        print(f"    - FCFP4æŒ‡çº¹: {DTI_FCFP4_BITS} ä½")
        print(f"    - MACCSæŒ‡çº¹: {DTI_MACCS_BITS} ä½")
        print(f"    - åŸå­å¯¹æŒ‡çº¹: {DTI_ATOM_PAIRS_BITS} ä½")
        print(f"    - DTIå­ç»“æ„: {DTI_SUBSTRUCTURES_COUNT * 2} ç»´")
        print(f"    - è¯ç‰©ç‰‡æ®µ: {DTI_DRUG_FRAGMENTS_COUNT} ç»´")
        print(f"    - è¯æ•ˆå›¢ç‰¹å¾: {DTI_PHARMACOPHORE_COUNT} ç»´")
        print(f"  ğŸ“ˆ æ€»ç‰¹å¾ç»´åº¦: {PROTEIN_TOTAL_DIM + COMPOUND_TOTAL_DIM}")
        print(f"  ğŸ”¬ DTIä»»åŠ¡é€‚ç”¨æ€§: â­â­â­â­â­")

        # ç‰¹å¾ä¼˜åŠ¿è¯´æ˜
        print(f"\nğŸ’¡ ç‰¹å¾ä¼˜åŠ¿:")
        print(f"  ğŸ§¬ AAC+DPC: DTIä»»åŠ¡æœ€ç»å…¸ç»„åˆï¼Œ85%ç ”ç©¶ä½¿ç”¨")
        print(f"  ğŸ’Š DTIæŒ‡çº¹: ä¸“é—¨ä¼˜åŒ–çš„åˆ†å­ç‰¹å¾ï¼Œæ€§èƒ½æå‡æ˜¾è‘—")
        print(f"  âš¡ è®¡ç®—é€Ÿåº¦: æ— éœ€PSI-BLASTï¼Œå¤„ç†é€Ÿåº¦å¿«10å€")
        print(f"  ğŸ“Š å¯è§£é‡Šæ€§: AAC+DPCç‰¹å¾å«ä¹‰æ˜ç¡®ï¼Œä¾¿äºåˆ†æ")
        print(f"  ğŸ¯ å®ç”¨æ€§: å¹³è¡¡ç²¾åº¦å’Œæ•ˆç‡ï¼Œé€‚åˆå®é™…åº”ç”¨")

        # è¾“å‡ºä½¿ç”¨è¯´æ˜
        print(f"\nğŸ“– ä½¿ç”¨è¯´æ˜:")
        print(f"  1. ä¿®æ”¹ä»£ç å¼€å¤´çš„ INPUT_CSV_FILE è®¾ç½®è¾“å…¥æ–‡ä»¶")
        print(f"  2. å¯é€‰æ‹©ä¿®æ”¹ CUSTOM_OUTPUT_DIR è®¾ç½®è¾“å‡ºç›®å½•")
        print(f"  3. å¦‚éœ€æ¢å¤è¿è¡Œï¼Œè®¾ç½® RESUME_FROM_DIR")
        print(f"  4. ç‰¹æ®Šæ¨¡å¼å¯è®¾ç½® TEST_MODE æˆ– LIST_RESUME_DIRS")
        print("=" * 80)

        return 0

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­å¤„ç†")
        print("å¯é€šè¿‡è®¾ç½® RESUME_FROM_DIR å‚æ•°æ¢å¤è¿è¡Œ")
        if 'work_dir' in locals():
            print(f"æ¢å¤ç›®å½•è®¾ç½®ä¸º: RESUME_FROM_DIR = '{work_dir}'")
        return 1
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print("\n" + "ğŸ”§ å½“å‰é…ç½®ä¿¡æ¯:")
    print(f"  è¾“å…¥æ–‡ä»¶: {INPUT_CSV_FILE}")
    print(f"  è‡ªå®šä¹‰è¾“å‡ºç›®å½•: {CUSTOM_OUTPUT_DIR or 'è‡ªåŠ¨ç”Ÿæˆ'}")
    print(f"  æ¢å¤è¿è¡Œç›®å½•: {RESUME_FROM_DIR or 'æ— '}")
    print(f"  æµ‹è¯•æ¨¡å¼: {TEST_MODE}")
    print(f"  ä¿æŒåŸå§‹é¡ºåº: {PRESERVE_ORDER}")
    print(f"  åˆ—å‡ºå¯æ¢å¤ç›®å½•: {LIST_RESUME_DIRS}")

    if not INPUT_CSV_FILE:
        print("\nâŒ è¯·åœ¨ä»£ç å¼€å¤´è®¾ç½®è¾“å…¥æ–‡ä»¶è·¯å¾„!")
        print("ä¾‹å¦‚: INPUT_CSV_FILE = 'your_data.csv'")
        sys.exit(1)

    # è¿è¡Œä¸»ç¨‹åº
    exit_code = main()
    sys.exit(exit_code)