#!/usr/bin/env python3
"""
è›‹ç™½è´¨-åŒ–åˆç‰©åˆ†ç¦»åˆ†æ‰¹ç‰¹å¾æå–è„šæœ¬ - ä¿®æ”¹ç‰ˆ
ä½œè€…: woyaokaoyanhaha
ç‰ˆæœ¬: 18.1 (é›†æˆChempropé¢„è®­ç»ƒæ¨¡å‹)
æ—¥æœŸ: 2025-07-02
"""

import csv
import os
import json
import time
import warnings
import gc
from pathlib import Path
from collections import defaultdict
import traceback
import sys
import numpy as np
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors, AllChem, MACCSkeys
import torch
from torch.cuda.amp import autocast
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

# å®‰è£…Chemprop
try:
    from chemprop.models import MoleculeModel
    from chemprop.data import MoleculeDataset
    from chemprop.features import get_features_generator
except ImportError:
    print("âŒ Chemprop æœªå®‰è£…ï¼Œè¯·è¿è¡Œï¼špip install chemprop")
    sys.exit(1)

# ============================================================================
# ç”¨æˆ·é…ç½®å‚æ•°åŒºåŸŸ - åœ¨æ­¤ä¿®æ”¹æ‰€æœ‰å‚æ•°
# ============================================================================

# è¾“å…¥æ–‡ä»¶è·¯å¾„ (å¿…é¡»è®¾ç½®)
INPUT_CSV_FILE = "test2.csv"  # ä¿®æ”¹ä¸ºæ‚¨çš„è¾“å…¥æ–‡ä»¶è·¯å¾„

# è¾“å‡ºç›®å½•è®¾ç½® (å¯é€‰ï¼Œç•™ç©ºåˆ™è‡ªåŠ¨ç”Ÿæˆ)
CUSTOM_OUTPUT_DIR = "Q13133å’ŒEHDPP"  # ä¾‹å¦‚: "./my_output" æˆ–ç•™ç©º ""

# æ¢å¤è¿è¡Œè®¾ç½® (å¯é€‰)
RESUME_FROM_DIR = ""  # ä¾‹å¦‚: "./previous_run_dir" æˆ–ç•™ç©º ""

# è¿è¡Œæ¨¡å¼è®¾ç½®
TEST_MODE = False  # Trueè¡¨ç¤ºä»…æµ‹è¯•ï¼ŒFalseè¡¨ç¤ºæ­£å¸¸è¿è¡Œ
DEBUG_MODE = True  # Trueè¡¨ç¤ºæ˜¾ç¤ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯

# åˆ†æ‰¹å¤„ç†é…ç½®
COMPOUND_BATCH_SIZE = 1000000  # æ¯æ‰¹å¤„ç†çš„åŒ–åˆç‰©æ•°é‡
MEMORY_LIMIT_MB = 6144  # å†…å­˜é™åˆ¶(MB)ï¼Œè¶…è¿‡æ—¶å¼ºåˆ¶åƒåœ¾å›æ”¶

# ç‰¹å¾æå–é…ç½®
EXTRACT_PROTEIN_FEATURES = True  # Trueè¡¨ç¤ºæå–è›‹ç™½è´¨ç‰¹å¾
EXTRACT_COMPOUND_FEATURES = True  # Trueè¡¨ç¤ºæå–åŒ–åˆç‰©ç‰¹å¾
SAVE_ORIGINAL_DATA = False  # Falseè¡¨ç¤ºä¸ä¿å­˜sequenceå’Œsmiles
GNN_FEATURE_DIM = 128  # Chempropé»˜è®¤è¾“å‡º300ç»´ï¼Œéœ€è°ƒæ•´è‡³128-256

# ============================================================================
# ç‰¹å¾ç»´åº¦é…ç½®
# ============================================================================

# è›‹ç™½è´¨ç‰¹å¾ç»´åº¦
AAC_DIM = 20  # æ°¨åŸºé…¸ç»„æˆç‰¹å¾ç»´åº¦
DPC_DIM = 400  # äºŒè‚½ç»„æˆç‰¹å¾ç»´åº¦
PROTEIN_ENHANCED_DIM = 10  # å¢å¼ºç‰¹å¾ç»´åº¦
PROTEIN_TOTAL_DIM = AAC_DIM + DPC_DIM + PROTEIN_ENHANCED_DIM  # 430

# åŒ–åˆç‰©ç‰¹å¾ç»´åº¦
GNN_DIM = GNN_FEATURE_DIM  # Chemprop GNNç‰¹å¾ç»´åº¦
ECFP4_BITS = 2048  # ECFP4æŒ‡çº¹ä½æ•°
MACCS_BITS = 167  # MACCSæŒ‡çº¹ä½æ•°
DTI_SUBSTRUCTURES_COUNT = 26  # DTIé‡è¦å­ç»“æ„æ•°
PHARMACOPHORE_COUNT = 6  # è¯æ•ˆå›¢ç‰¹å¾æ•°
RDKIT_DESCRIPTOR_COUNT = 50  # RDKitæè¿°ç¬¦æ•°é‡
COMPOUND_TOTAL_DIM = (GNN_DIM + ECFP4_BITS + MACCS_BITS +
                     DTI_SUBSTRUCTURES_COUNT * 2 + PHARMACOPHORE_COUNT +
                     RDKIT_DESCRIPTOR_COUNT)  # 2521-2649

# æ€»ç‰¹å¾ç»´åº¦
TOTAL_FEATURE_DIM = PROTEIN_TOTAL_DIM + COMPOUND_TOTAL_DIM

# DTIé‡è¦å­ç»“æ„ï¼ˆSMARTSæ ¼å¼ï¼‰
DTI_IMPORTANT_SUBSTRUCTURES = {
    'benzene_ring': 'c1ccccc1',
    'pyridine': 'c1ccncc1',
    'pyrimidine': 'c1cncnc1',
    'imidazole': 'c1cnc[nH]1',
    'indole': 'c1ccc2c(c1)cc[nH]2',
    'quinoline': 'c1ccc2c(c1)cccn2',
    'hydroxyl': '[OH]',
    'primary_amine': '[NH2]',
    'secondary_amine': '[NH1]',
    'carboxyl': 'C(=O)[OH]',
    'amide': '[NX3][CX3](=[OX1])[#6]',
    'carbonyl': '[CX3]=[OX1]',
    'sulfonamide': '[SX4](=[OX1])(=[OX1])([NX3])[#6]',
    'urea': '[NX3][CX3](=[OX1])[NX3]',
    'ester': '[#6][CX3](=O)[OX2H0][#6]',
    'ether': '[OD2]([#6])[#6]',
    'morpholine': 'C1COCCN1',
    'piperidine': 'C1CCNCC1',
    'piperazine': 'C1CNCCN1',
    'pyrrolidine': 'C1CCNC1',
    'thiophene': 'c1ccsc1',
    'furan': 'c1ccoc1',
    'aromatic_hydroxyl': 'c[OH]',
    'aromatic_amine': 'c[NH2]',
    'beta_lactam': '[C@H]1[C@@H](N1[*])[*]',
    'guanidine': '[NX3][CX3](=[NX3+])[NX3]'
}

# RDKitæè¿°ç¬¦é€‰æ‹©
RDKIT_DESCRIPTORS = [
    'MolWt', 'MolLogP', 'NumHDonors', 'NumHAcceptors', 'TPSA',
    'NumRotatableBonds', 'NumAromaticRings', 'NumAliphaticRings',
    'NumSaturatedRings', 'NumHeteroatoms', 'FractionCSP3',
    'MaxPartialCharge', 'MinPartialCharge', 'NumValenceElectrons',
    'NumRadicalElectrons', 'LabuteASA', 'BalabanJ', 'BertzCT',
    'Chi0', 'Chi1', 'Chi2n', 'Chi3n', 'Chi4n', 'HallKierAlpha',
    'Kappa1', 'Kappa2', 'Kappa3', 'PEOE_VSA1', 'PEOE_VSA2',
    'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6',
    'SMR_VSA1', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5',
    'SlogP_VSA1', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4',
    'SlogP_VSA5', 'EState_VSA1', 'EState_VSA2', 'EState_VSA3',
    'VSA_EState1', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4',
    'VSA_EState5'
]

# ============================================================================

# æ£€æŸ¥å’Œå¯¼å…¥ä¾èµ–åº“
def check_dependencies():
    """æ£€æŸ¥å¹¶å¯¼å…¥å¿…è¦çš„ä¾èµ–åº“"""
    print("æ­£åœ¨æ£€æŸ¥ä¾èµ–åº“...")
    dependencies_met = True

    for module, name, install_name in [
        (np, 'numpy', 'numpy'),
        (pd, 'pandas', 'pandas'),
        (Chem, 'rdkit', 'rdkit'),
        (torch, 'pytorch', 'torch'),
        (MoleculeModel, 'chemprop', 'chemprop')
    ]:
        try:
            print(f"âœ… {name} {module.__version__ if hasattr(module, '__version__') else ''}")
        except:
            print(f"âŒ {name} æœªå®‰è£…")
            dependencies_met = False

    if PSUTIL_AVAILABLE:
        print(f"âœ… psutil {psutil.__version__}")
    else:
        print("âš ï¸ psutil æœªå®‰è£…ï¼Œå°†æ— æ³•ç›‘æ§å†…å­˜ä½¿ç”¨")

    if not dependencies_met:
        print("\nè¯·å®‰è£…ç¼ºå¤±çš„ä¾èµ–åº“:")
        print("pip install numpy pandas rdkit torch chemprop")
        sys.exit(1)

    print("ğŸ‰ æ‰€æœ‰ä¾èµ–åº“æ£€æŸ¥å®Œæˆ")
    return True

# æ£€æŸ¥ä¾èµ–åº“
if not check_dependencies():
    sys.exit(1)

# åˆ—åæ˜ å°„é…ç½®
COLUMN_MAPPING = {
    'protein_accession': ['Protein_Accession', 'ProteinAccession', 'Accession', 'Protein_ID', 'ProteinID'],
    'sequence': ['Sequence', 'Protein_Sequence', 'ProteinSequence', 'Seq'],
    'compound_cid': ['Compound_CID', 'CompoundCID', 'CID', 'Compound_ID', 'CompoundID'],
    'smile': ['Smile', 'SMILES', 'Canonical_SMILES', 'CanonicalSMILES']
}

def get_memory_usage():
    """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    if PSUTIL_AVAILABLE:
        process = psutil.Process()
        memory_info = process.memory_info()
        return memory_info.rss / 1024 / 1024  # MB
    return 0

def force_garbage_collection():
    """å¼ºåˆ¶åƒåœ¾å›æ”¶"""
    gc.collect()
    if PSUTIL_AVAILABLE:
        return get_memory_usage()
    return 0

def detect_column_names(csv_file):
    """è‡ªåŠ¨æ£€æµ‹CSVæ–‡ä»¶çš„åˆ—å"""
    print(f"æ­£åœ¨æ£€æµ‹CSVæ–‡ä»¶çš„åˆ—å: {csv_file}")
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            header = next(reader)
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–CSVæ–‡ä»¶: {e}")
        return None, None

    detected_columns = {}
    for field_type, possible_names in COLUMN_MAPPING.items():
        detected_columns[field_type] = None
        for possible_name in possible_names:
            if possible_name in header:
                detected_columns[field_type] = possible_name
                break

    print("æ£€æµ‹åˆ°çš„åˆ—åæ˜ å°„:")
    for field_type, column_name in detected_columns.items():
        status = "âœ…" if column_name else "âŒ"
        print(f"  {status} {field_type}: {column_name or 'æœªæ‰¾åˆ°'}")
    return detected_columns, header

def analyze_data_distribution(csv_file, detected_columns):
    """åˆ†ææ•°æ®åˆ†å¸ƒæƒ…å†µ"""
    print("\nğŸ” æ­£åœ¨åˆ†ææ•°æ®åˆ†å¸ƒ...")
    protein_data = {}
    compound_data = {}
    total_rows = 0

    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                total_rows += 1
                accession = row[detected_columns['protein_accession']].strip()
                sequence = row[detected_columns['sequence']].strip().upper()
                compound_cid = row[detected_columns['compound_cid']].strip()
                smile = row[detected_columns['smile']].strip()

                if accession in protein_data:
                    if protein_data[accession] != sequence:
                        print(f"âš ï¸ è­¦å‘Š: è›‹ç™½è´¨ {accession} å¯¹åº”å¤šä¸ªä¸åŒåºåˆ—!")
                else:
                    protein_data[accession] = sequence

                if compound_cid not in compound_data:
                    compound_data[compound_cid] = smile

    except Exception as e:
        print(f"âŒ æ•°æ®åˆ†æå¤±è´¥: {e}")
        return None, None, 0

    print(f"ğŸ“Š æ•°æ®åˆ†å¸ƒç»Ÿè®¡:")
    print(f"  æ€»è®°å½•æ•°: {total_rows}")
    print(f"  å”¯ä¸€è›‹ç™½è´¨æ•°: {len(protein_data)}")
    print(f"  å”¯ä¸€åŒ–åˆç‰©æ•°: {len(compound_data)}")
    return protein_data, compound_data, total_rows

def get_output_dir_name(input_csv_path, custom_output=None):
    """ç”Ÿæˆè¾“å‡ºç›®å½•å"""
    if custom_output:
        return custom_output
    filename = os.path.basename(input_csv_path)
    basename = os.path.splitext(filename)[0]
    timestamp = time.strftime('%Y%m%d_%H%M%S')
    safe_basename = "".join(c for c in basename if c.isalnum() or c in ('-', '_')).rstrip()
    if len(safe_basename) < 3:
        safe_basename = "protein_compound_features"
    return f"./{safe_basename}_separated_batch_{timestamp}"

class ProgressManager:
    """è¿›åº¦ç®¡ç†å™¨"""
    def __init__(self, work_dir):
        self.work_dir = work_dir
        self.progress_file = os.path.join(work_dir, "progress.json")
        self.progress = self.load_progress()

    def load_progress(self):
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'r') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ è¿›åº¦æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return {
            'start_time': time.time(),
            'total_records': 0,
            'unique_proteins': 0,
            'unique_compounds': 0,
            'protein_extraction_completed': False,
            'compound_batches_total': 0,
            'compound_batches_completed': 0,
            'compound_batch_files': [],
            'protein_file': None,
            'completed': False,
            'last_update': time.time(),
            'memory_peak_mb': 0,
            'processing_errors': []
        }

    def save_progress(self):
        self.progress['last_update'] = time.time()
        current_memory = get_memory_usage()
        if current_memory > self.progress['memory_peak_mb']:
            self.progress['memory_peak_mb'] = current_memory
        try:
            with open(self.progress_file, 'w') as f:
                json.dump(self.progress, f, indent=2)
        except Exception as e:
            print(f"âš ï¸ è¿›åº¦ä¿å­˜å¤±è´¥: {e}")

    def update_totals(self, total_records, unique_proteins, unique_compounds, compound_batches_total):
        self Metz['total_records'] = total_records
        self.progress['unique_proteins'] = unique_proteins
        self.progress['unique_compounds'] = unique_compounds
        self.progress['compound_batches_total'] = compound_batches_total
        self.save_progress()

    def mark_protein_completed(self, protein_file):
        self.progress['protein_extraction_completed'] = True
        self.progress['protein_file'] = protein_file
        self.save_progress()

    def mark_compound_batch_completed(self, batch_number, batch_file):
        self.progress['compound_batches_completed'] = max(self.progress['compound_batches_completed'], batch_number)
        if batch_file not in self.progress['compound_batch_files']:
            self.progress['compound_batch_files'].append(batch_file)
        self.save_progress()

    def add_error(self, error_msg):
        error_record = {
            'time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'error': str(error_msg)
        }
        self.progress['processing_errors'].append(error_record)

    def mark_completed(self):
        self.progress['completed'] = True
        self.progress['end_time'] = time.time()
        self.save_progress()

    def get_progress_info(self):
        return {
            'protein_completed': self.progress['protein_extraction_completed'],
            'compound_batches': f"{self.progress['compound_batches_completed']}/{self.progress['compound_batches_total']}",
            'compound_percent': (self.progress['compound_batches_completed'] / max(1, self.progress['compound_batches_total'])) * 100,
            'memory_mb': get_memory_usage(),
            'memory_peak_mb': self.progress['memory_peak_mb']
        }

class AACDPCProteinExtractor:
    """AAC+DPCè›‹ç™½è´¨ç‰¹å¾æå–å™¨"""
    def __init__(self):
        self.amino_acids = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',
                           'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']
        self.aa_groups = {
            'hydrophobic': 'AILMFWYV',
            'polar': 'STYNQ',
            'charged': 'DEKR',
            'aromatic': 'FWY',
            'aliphatic': 'ILV',
        }
        self.aa_properties = {
            'A': [1.8, 89.1, 6.0], 'C': [2.5, 121.0, 5.1], 'D': [-3.5, 133.1, 3.0],
            'E': [-3.5, 147.1, 4.2], 'F': [2.8, 165.2, 5.5], 'G': [-0.4, 75.1, 6.0],
            'H': [-3.2, 155.2, 7.6], 'I': [4.5, 131.2, 6.0], 'K': [-3.9, 146.2, 9.7],
            'L': [3.8, 131.2, 6.0], 'M': [1.9, 149.2, 5.7], 'N': [-3.5, 132.1, 5.4],
            'P': [-1.6, 115.1, 6.3], 'Q': [-3.5, 146.1, 5.7], 'R': [-4.5, 174.2, 10.8],
            'S': [-0.8, 105.1, 5.7], 'T': [-0.7, 119.1, 5.6], 'V': [4.2, 117.1, 6.0],
            'W': [-0.9, 204.2, 5.9], 'Y': [-1.3, 181.2, 5.7]
        }

    def extract_aac_features(self, sequence):
        aac_features = []
        total_length = len(sequence)
        for aa in self.amino_acids:
            count = sequence.count(aa)
            frequency = count / total_length if total_length > 0 else 0.0
            aac_features.append(frequency)
        return aac_features

    def extract_dpc_features(self, sequence):
        dpc_features = []
        dipeptides = []
        for aa1 in self.amino_acids:
            for aa2 in self.amino_acids:
                dipeptides.append(aa1 + aa2)
        total_dipeptides = len(sequence) - 1
        if total_dipeptides <= 0:
            return [0.0] * DPC_DIM
        for dipeptide in dipeptides:
            count = 0
            for i in range(len(sequence) - 1):
                if sequence[i:i + 2] == dipeptide:
                    count += 1
            frequency = count / total_dipeptides
            dpc_features.append(frequency)
        return dpc_features

    def extract_enhanced_features(self, sequence):
        enhanced_features = []
        if len(sequence) == 0:
            return [0.0] * PROTEIN_ENHANCED_DIM
        for group_name, group_aa in list(self.aa_groups.items())[:5]:
            ratio = sum(sequence.count(aa) for aa in group_aa) / len(sequence)
            enhanced_features.append(ratio)
        length_feature = min(len(sequence) / 1000.0, 1.0)
        enhanced_features.append(length_feature)
        total_hydrophobicity = sum(self.aa_properties.get(aa, [0, 0, 0])[0]
                                 for aa in sequence if aa in self.aa_properties)
        avg_hydrophobicity = total_hydrophobicity / len(sequence) if len(sequence) > 0 else 0.0
        enhanced_features.append(avg_hydrophobicity)
        total_mw = sum(self.aa_properties.get(aa, [0, 0, 0])[1]
                      for aa in sequence if aa in self.aa_properties)
        avg_mw = total_mw / len(sequence) if len(sequence) > 0 else 0.0
        normalized_mw = (avg_mw - 75) / (200 - 75) if avg_mw > 0 else 0.0
        enhanced_features.append(normalized_mw)
        total_pi = sum(self.aa_properties.get(aa, [0, 0, 0])[2]
                      for aa in sequence if aa in self.aa_properties)
        avg_pi = total_pi / len(sequence) if len(sequence) > 0 else 0.0
        normalized_pi = (avg_pi - 3) / (11 - 3) if avg_pi > 0 else 0.0
        enhanced_features.append(normalized_pi)
        n_terminal_feature = 1.0 if len(sequence) > 0 and sequence[0] == 'M' else 0.0
        enhanced_features.append(n_terminal_feature)
        while len(enhanced_features) < PROTEIN_ENHANCED_DIM:
            enhanced_features.append(0.0)
        return enhanced_features[:PROTEIN_ENHANCED_DIM]

    def extract_all_features(self, sequence):
        cleaned_sequence = ''.join([aa for aa in sequence.upper() if aa in self.amino_acids])
        if len(cleaned_sequence) == 0:
            return [0.0] * PROTEIN_TOTAL_DIM
        aac_features = self.extract_aac_features(cleaned_sequence)
        dpc_features = self.extract_dpc_features(cleaned_sequence)
        enhanced_features = self.extract_enhanced_features(cleaned_sequence)
        all_features = aac_features + dpc_features + enhanced_features
        if len(all_features) != PROTEIN_TOTAL_DIM:
            if len(all_features) < PROTEIN_TOTAL_DIM:
                all_features.extend([0.0] * (PROTEIN_TOTAL_DIM - len(all_features)))
            else:
                all_features = all_features[:PROTEIN_TOTAL_DIM]
        return all_features

class DTIOptimizedFingerprintExtractor:
    """DTIä¼˜åŒ–çš„åˆ†å­æŒ‡çº¹æå–å™¨"""
    def __init__(self):
        self.substructure_patterns = DTI_IMPORTANT_SUBSTRUCTURES
        # åŠ è½½Chempropé¢„è®­ç»ƒæ¨¡å‹
        pretrained_path = 'chemprop_pretrain.pth'  # æ›¿æ¢ä¸ºå®é™…æƒé‡è·¯å¾„
        try:
            self.gnn_model = MoleculeModel.load_from_file(pretrained_path)
            self.gnn_model.to('cuda' if torch.cuda.is_available() else 'cpu')
            self.gnn_model.eval()
            print(f"âœ… åŠ è½½Chempropé¢„è®­ç»ƒæ¨¡å‹: {pretrained_path}")
        except Exception as e:
            print(f"âŒ æ— æ³•åŠ è½½Chempropæ¨¡å‹: {e}")
            sys.exit(1)
        # ç»´åº¦è°ƒæ•´å±‚ï¼ˆChempropé»˜è®¤è¾“å‡º300ç»´ï¼Œè°ƒæ•´è‡³GNN_DIMï¼‰
        self.dim_reducer = torch.nn.Linear(300, GNN_DIM)
        self.dim_reducer.to('cuda' if torch.cuda.is_available() else 'cpu')
        self.dim_reducer.eval()

    def smiles_to_mol(self, smiles):
        try:
            mol = Chem.MolFromSmiles(smiles)
            if mol is not None:
                Chem.SanitizeMol(mol)
            return mol
        except:
            return None

    def extract_gnn_features(self, smiles):
        """ä½¿ç”¨Chempropæå–GNNç‰¹å¾"""
        if not smiles or not isinstance(smiles, str):
            return [0.0] * GNN_DIM
        try:
            dataset = MoleculeDataset([{'smiles': smiles}])
            features_generator = get_features_generator('morgan')
            with torch.no_grad(), autocast():
                features = self.gnn_model(dataset, features_generator=features_generator)
                features = features.squeeze(0)  # ç§»é™¤batchç»´åº¦
                features = self.dim_reducer(features).cpu().numpy()
            return features.tolist()[:GNN_DIM]
        except Exception as e:
            print(f"âš ï¸ GNNç‰¹å¾æå–å¤±è´¥: {e}")
            return [0.0] * GNN_DIM

    def extract_ecfp4_fingerprint(self, mol):
        if mol is None:
            return [0] * ECFP4_BITS
        try:
            fp = AllChem.GetMorganFingerprintAsBitVect(
                mol, radius=2, nBits=ECFP4_BITS,
                useChirality=True, useBondTypes=True
            )
            return list(map(int, fp.ToBitString()))
        except:
            return [0] * ECFP4_BITS

    def extract_maccs_fingerprint(self, mol):
        if mol is None:
            return [0] * MACCS_BITS
        try:
            fp = MACCSkeys.GenMACCSKeys(mol)
            return list(map(int, fp.ToBitString()))
        except:
            return [0] * MACCS_BITS

    def extract_dti_substructures(self, mol):
        if mol is None:
            return [0] * (DTI_SUBSTRUCTURES_COUNT * 2)
        features = []
        try:
            for name, pattern in self.substructure_patterns.items():
                pattern_mol = Chem.MolFromSmarts(pattern)
                if pattern_mol is not None:
                    has_match = mol.HasSubstructMatch(pattern_mol)
                    features.append(int(has_match))
                    matches = len(mol.GetSubstructMatches(pattern_mol))
                    features.append(matches)
                else:
                    features.extend([0, 0])
        except:
            features = [0] * (DTI_SUBSTRUCTURES_COUNT * 2)
        while len(features) < DTI_SUBSTRUCTURES_COUNT * 2:
            features.append(0)
        return features[:DTI_SUBSTRUCTURES_COUNT * 2]

    def extract_pharmacophore_features(self, mol):
        if mol is None:
            return [0] * PHARMACOPHORE_COUNT
        try:
            hbd_count = Descriptors.NumHBD(mol)
            hba_count = Descriptors.NumHBA(mol)
            aromatic_count = Descriptors.NumAromaticRings(mol)
            hydrophobic_count = sum(1 for atom in mol.GetAtoms()
                                  if atom.GetSymbol() == 'C' and atom.GetIsAromatic())
            pos_ionizable = len(mol.GetSubstructMatches(Chem.MolFromSmarts('[NH3+,NH2+,NH+]')))
            neg_ionizable = len(mol.GetSubstructMatches(Chem.MolFromSmarts('[O-,COO-]')))
            return [hbd_count, hba_count, aromatic_count, hydrophobic_count, pos_ionizable, neg_ionizable]
        except:
            return [0] * PHARMACOPHORE_COUNT

    def extract_rdkit_descriptors(self, mol):
        if mol is None:
            return [0.0] * RDKIT_DESCRIPTOR_COUNT
        try:
            features = []
            for desc_name in RDKIT_DESCRIPTORS:
                desc_func = getattr(Descriptors, desc_name)
                value = desc_func(mol)
                if np.isnan(value) or np.isinf(value):
                    value = 0.0
                value = min(max(value, -10.0), 10.0) / 10.0
                features.append(value)
            return features[:RDKIT_DESCRIPTOR_COUNT]
        except:
            return [0.0] * RDKIT_DESCRIPTOR_COUNT

    def extract_all_features(self, smiles):
        mol = self.smiles_to_mol(smiles)
        gnn_features = self.extract_gnn_features(smiles)  # ç›´æ¥ä¼ é€’SMILES
        ecfp4_features = self.extract_ecfp4_fingerprint(mol)
        maccs_features = self.extract_maccs_fingerprint(mol)
        dti_sub_features = self.extract_dti_substructures(mol)
        pharm_features = self.extract_pharmacophore_features(mol)
        rdkit_features = self.extract_rdkit_descriptors(mol)
        all_features = (gnn_features + ecfp4_features + maccs_features +
                       dti_sub_features + pharm_features + rdkit_features)
        return all_features

class SeparatedBatchExtractor:
    """åˆ†ç¦»åˆ†æ‰¹ç‰¹å¾æå–å™¨ä¸»ç±»"""
    def __init__(self, work_dir, input_filename, resume_mode=False):
        self.work_dir = work_dir
        self.input_filename = input_filename
        self.resume_mode = resume_mode
        self.output_dir = os.path.join(work_dir, "output")
        os.makedirs(self.output_dir, exist_ok=True)
        self.progress_manager = ProgressManager(work_dir)
        self.protein_extractor = AACDPCProteinExtractor()
        self.fingerprint_extractor = DTIOptimizedFingerprintExtractor()
        self.protein_data = {}
        self.compound_data = {}
        self.total_rows = 0
        self.column_mapping = {}
        print(f"ğŸ“ å·¥ä½œç›®å½•: {work_dir}")
        print(f"ğŸ”„ è¿è¡Œæ¨¡å¼: {'æ¢å¤è¿è¡Œ' if resume_mode else 'æ–°å»ºè¿è¡Œ'}")
        print(f"ğŸ§¬ è›‹ç™½è´¨ç‰¹å¾ç»´åº¦: {PROTEIN_TOTAL_DIM}")
        print(f"ğŸ’Š åŒ–åˆç‰©ç‰¹å¾ç»´åº¦: {COMPOUND_TOTAL_DIM}")

    def analyze_input_file(self, input_csv):
        print("\n" + "=" * 60)
        print("ğŸ“‚ è¾“å…¥æ–‡ä»¶åˆ†æé˜¶æ®µ")
        print("=" * 60)
        detected_columns, header = detect_column_names(input_csv)
        if not detected_columns:
            return False
        self.column_mapping = detected_columns
        required_fields = ['protein_accession', 'sequence', 'compound_cid', 'smile']
        missing_fields = [field for field in required_fields if not detected_columns[field]]
        if missing_fields:
            print(f"\nâŒ é”™è¯¯: æœªæ‰¾åˆ°å¿…éœ€çš„åˆ—: {missing_fields}")
            return False
        protein_data, compound_data, total_rows = analyze_data_distribution(input_csv, detected_columns)
        if protein_data is None:
            return False
        self.protein_data = protein_data
        self.compound_data = compound_data
        self.total_rows = total_rows
        compound_batches_total = (len(compound_data) + COMPOUND_BATCH_SIZE - 1) // COMPOUND_BATCH_SIZE
        self.progress_manager.update_totals(
            total_records=total_rows,
            unique_proteins=len(protein_data),
            unique_compounds=len(compound_data),
            compound_batches_total=compound_batches_total
        )
        return True

    def extract_protein_features(self):
        if self.progress_manager.progress['protein_extraction_completed']:
            print("\nğŸ§¬ è›‹ç™½è´¨ç‰¹å¾å·²æå–ï¼Œè·³è¿‡")
            return True
        print("\n" + "=" * 60)
        print("ğŸ§¬ è›‹ç™½è´¨ç‰¹å¾æå–é˜¶æ®µ")
        print("=" * 60)
        base_name = os.path.splitext(os.path.basename(self.input_filename))[0]
        protein_file = os.path.join(self.output_dir, f'{base_name}_protein_features.csv')
        print(f"æ­£åœ¨æå– {len(self.protein_data)} ä¸ªè›‹ç™½è´¨ç‰¹å¾...")
        try:
            protein_names = self._generate_protein_feature_names()
            with open(protein_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                header = ['Protein_Accession'] + protein_names
                writer.writerow(header)
                for i, (accession, sequence) in enumerate(self.protein_data.items(), 1):
                    print(f"ğŸ”„ æå–è›‹ç™½è´¨ç‰¹å¾ {i}/{len(self.protein_data)}: {accession}")
                    try:
                        features = self.protein_extractor.extract_all_features(sequence)
                        row = [accession] + features
                        writer.writerow(row)
                    except Exception as e:
                        print(f"  âŒ è›‹ç™½è´¨ç‰¹å¾æå–å¤±è´¥: {e}")
                        self.progress_manager.add_error(f"Protein {accession}: {e}")
                        row = [accession] + [0.0] * PROTEIN_TOTAL_DIM
                        writer.writerow(row)
            self.progress_manager.mark_protein_completed(protein_file)
            print(f"âœ… è›‹ç™½è´¨ç‰¹å¾æå–å®Œæˆ: {protein_file}")
            return True
        except Exception as e:
            print(f"âŒ è›‹ç™½è´¨ç‰¹å¾æå–å¤±è´¥: {e}")
            self.progress_manager.add_error(f"Protein extraction: {e}")
            return False

    def extract_compound_features_in_batches(self):
        print("\n" + "=" * 60)
        print("ğŸ’Š åŒ–åˆç‰©ç‰¹å¾åˆ†æ‰¹æå–é˜¶æ®µ")
        print("=" * 60)
        base_name = os.path.splitext(os.path.basename(self.input_filename))[0]
        compound_list = list(self.compound_data.items())
        total_batches = (len(compound_list) + COMPOUND_BATCH_SIZE - 1) // COMPOUND_BATCH_SIZE
        print(f"å¼€å§‹åˆ†æ‰¹æå– {len(compound_list)} ä¸ªåŒ–åˆç‰©ç‰¹å¾ï¼Œå…± {total_batches} æ‰¹")
        for batch_num in range(1, total_batches + 1):
            if batch_num <= self.progress_manager.progress['compound_batches_completed']:
                print(f"ğŸ“¦ æ‰¹æ¬¡ {batch_num}/{total_batches} å·²å¤„ç†ï¼Œè·³è¿‡")
                continue
            print(f"\nğŸ”„ å¤„ç†åŒ–åˆç‰©æ‰¹æ¬¡ {batch_num}/{total_batches}")
            start_idx = (batch_num - 1) * COMPOUND_BATCH_SIZE
            end_idx = min(start_idx + COMPOUND_BATCH_SIZE, len(compound_list))
            batch_compounds = compound_list[start_idx:end_idx]
            print(f"ğŸ“ æ‰¹æ¬¡å¤§å°: {len(batch_compounds)} ä¸ªåŒ–åˆç‰©")
            batch_file = os.path.join(self.output_dir, f'{base_name}_compounds_batch_{batch_num:04d}.csv')
            if self._extract_compound_batch(batch_compounds, batch_file, batch_num):
                self.progress_manager.mark_compound_batch_completed(batch_num, batch_file)
                if get_memory_usage() > MEMORY_LIMIT_MB:
                    print(f"  ğŸ’¾ å†…å­˜ä½¿ç”¨è¶…é™ï¼Œå¼ºåˆ¶åƒåœ¾å›æ”¶...")
                    force_garbage_collection()
            else:
                print(f"âŒ æ‰¹æ¬¡ {batch_num} å¤„ç†å¤±è´¥")
        print(f"\nâœ… åŒ–åˆç‰©ç‰¹å¾åˆ†æ‰¹æå–å®Œæˆï¼Œå…± {total_batches} æ‰¹")
        return True

    def _extract_compound_batch(self, batch_compounds, batch_file, batch_num):
        try:
            compound_names = self._generate_compound_feature_names()
            with open(batch_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['Compound_CID'] + compound_names)
                # æ‰¹é‡æå–GNNç‰¹å¾
                smiles_list = [smile for _, smile in batch_compounds if smile and isinstance(smile, str)]
                if smiles_list:
                    dataset = MoleculeDataset([{'smiles': smi} for smi in smiles_list])
                    features_generator = get_features_generator('morgan')
                    with torch.no_grad(), autocast():
                        gnn_features = self.fingerprint_extractor.gnn_model(dataset, features_generator=features_generator)
                        gnn_features = self.fingerprint_extractor.dim_reducer(gnn_features).cpu().numpy()
                else:
                    gnn_features = np.zeros((len(batch_compounds), GNN_DIM))
                gnn_idx = 0
                for i, (compound_cid, smile) in enumerate(batch_compounds, 1):
                    if i % 100 == 0:
                        memory_mb = get_memory_usage()
                        print(f"  è¿›åº¦: {i}/{len(batch_compounds)} (å†…å­˜: {memory_mb:.1f}MB)")
                    try:
                        mol = self.fingerprint_extractor.smiles_to_mol(smile)
                        gnn_feat = gnn_features[gnn_idx].tolist() if gnn_idx < len(gnn_features) and smile in smiles_list else [0.0] * GNN_DIM
                        gnn_idx += 1
                        other_features = (self.fingerprint_extractor.extract_ecfp4_fingerprint(mol) +
                                         self.fingerprint_extractor.extract_maccs_fingerprint(mol) +
                                         self.fingerprint_extractor.extract_dti_substructures(mol) +
                                         self.fingerprint_extractor.extract_pharmacophore_features(mol) +
                                         self.fingerprint_extractor.extract_rdkit_descriptors(mol))
                        features = gnn_feat + other_features
                        writer.writerow([compound_cid] + features)
                    except Exception as e:
                        print(f"  âŒ åŒ–åˆç‰© {compound_cid} ç‰¹å¾æå–å¤±è´¥: {e}")
                        self.progress_manager.add_error(f"Compound {compound_cid}: {e}")
                        writer.writerow([compound_cid] + [0.0] * COMPOUND_TOTAL_DIM)
            print(f"  âœ… æ‰¹æ¬¡ {batch_num} å®Œæˆ: {os.path.basename(batch_file)}")
            return True
        except Exception as e:
            print(f"  âŒ æ‰¹æ¬¡ {batch_num} å¤„ç†å¤±è´¥: {e}")
            self.progress_manager.add_error(f"Batch {batch_num}: {e}")
            return False

    def _generate_protein_feature_names(self):
        protein_names = []
        amino_acids = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',
                      'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']
        for aa in amino_acids:
            protein_names.append(f'AAC_{aa}')
        for aa1 in amino_acids:
            for aa2 in amino_acids:
                protein_names.append(f'DPC_{aa1}{aa2}')
        enhanced_names = ['Enhanced_Hydrophobic', 'Enhanced_Polar', 'Enhanced_Charged',
                         'Enhanced_Aromatic', 'Enhanced_Aliphatic', 'Enhanced_Length',
                         'Enhanced_AvgHydrophobicity', 'Enhanced_AvgMW', 'Enhanced_AvgPI',
                         'Enhanced_NTerminal']
        protein_names.extend(enhanced_names)
        return protein_names

    def _generate_compound_feature_names(self):
        compound_names = []
        for i in range(GNN_DIM):
            compound_names.append(f'GNN_{i}')
        for i in range(ECFP4_BITS):
            compound_names.append(f'ECFP4_{i}')
        for i in range(MACCS_BITS):
            compound_names.append(f'MACCS_{i}')
        for name in DTI_IMPORTANT_SUBSTRUCTURES.keys():
            compound_names.append(f'DTI_Sub_{name}')
            compound_names.append(f'DTI_Count_{name}')
        pharm_features = ['HBD_count', 'HBA_count', 'Aromatic_count',
                         'Hydrophobic_count', 'PosIonizable', 'NegIonizable']
        for pharm in pharm_features:
            compound_names.append(f'Pharm_{pharm}')
        for desc in RDKIT_DESCRIPTORS:
            compound_names.append(f'RDKit_{desc}')
        return compound_names

    def save_processing_stats(self):
        base_name = os.path.splitext(os.path.basename(self.input_filename))[0]
        stats_file = os.path.join(self.output_dir, f'{base_name}_processing_stats.json')
        progress_info = self.progress_manager.get_progress_info()
        stats = {
            'input_file': self.input_filename,
            'processing_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'user': 'woyaokaoyanhaha',
            'version': '18.1 (é›†æˆChempropé¢„è®­ç»ƒæ¨¡å‹)',
            'work_directory': self.work_dir,
            'configuration': {
                'compound_batch_size': COMPOUND_BATCH_SIZE,
                'memory_limit_mb': MEMORY_LIMIT_MB,
                'extract_protein_features': EXTRACT_PROTEIN_FEATURES,
                'extract_compound_features': EXTRACT_COMPOUND_FEATURES,
                'save_original_data': SAVE_ORIGINAL_DATA,
                'gnn_feature_dim': GNN_DIM
            },
            'processing_statistics': {
                'total_records': self.total_rows,
                'unique_proteins': len(self.protein_data),
                'unique_compounds': len(self.compound_data),
                'compound_batches_total': self.progress_manager.progress['compound_batches_total'],
                'memory_peak_mb': progress_info['memory_peak_mb'],
                'processing_errors': len(self.progress_manager.progress['processing_errors'])
            },
            'output_files': {
                'protein_file': self.progress_manager.progress['protein_file'],
                'compound_batch_files': self.progress_manager.progress['compound_batch_files']
            },
            'feature_dimensions': {
                'protein_total': PROTEIN_TOTAL_DIM,
                'compound_total': COMPOUND_TOTAL_DIM,
                'total_features': TOTAL_FEATURE_DIM
            }
        }
        try:
            with open(stats_file, 'w') as f:
                json.dump(stats, f, indent=2, ensure_ascii=False)
            print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜: {os.path.basename(stats_file)}")
        except Exception as e:
            print(f"âŒ ç»Ÿè®¡ä¿¡æ¯ä¿å­˜å¤±è´¥: {e}")

def main():
    print("\n" + "=" * 80)
    print("ğŸ§¬ è›‹ç™½è´¨-åŒ–åˆç‰©åˆ†ç¦»åˆ†æ‰¹ç‰¹å¾æå–è„šæœ¬")
    print(f"ğŸ‘¤ ç”¨æˆ·: woyaokaoyanhaha")
    print(f"ğŸ“… æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ¯ ç‰¹å¾ç»´åº¦: è›‹ç™½è´¨{PROTEIN_TOTAL_DIM} + åŒ–åˆç‰©{COMPOUND_TOTAL_DIM} = æ€»è®¡{TOTAL_FEATURE_DIM}")
    print(f"ğŸ”§ ç‰ˆæœ¬: 18.1 (é›†æˆChempropé¢„è®­ç»ƒæ¨¡å‹)")
    print("=" * 80)

    try:
        if TEST_MODE:
            print("ğŸ§ª æµ‹è¯•æ¨¡å¼ - æ£€æŸ¥æ–‡ä»¶å’Œç¯å¢ƒ")
            if INPUT_CSV_FILE:
                detected_columns, header = detect_column_names(INPUT_CSV_FILE)
                if detected_columns:
                    print("âœ… CSVæ–‡ä»¶æ ¼å¼æ£€æŸ¥é€šè¿‡")
                    if PSUTIL_AVAILABLE:
                        initial_memory = get_memory_usage()
                        print(f"âœ… å½“å‰å†…å­˜ä½¿ç”¨: {initial_memory:.1f} MB")
                else:
                    print("âŒ CSVæ–‡ä»¶æ ¼å¼æ£€æŸ¥å¤±è´¥")
                    return 1
                print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡")
            else:
                print("âŒ ç¼ºå°‘è¾“å…¥æ–‡ä»¶å‚æ•°")
                return 1
            return 0

        if not INPUT_CSV_FILE:
            print("âŒ é”™è¯¯: è¯·åœ¨ä»£ç å¼€å¤´è®¾ç½® INPUT_CSV_FILE å‚æ•°")
            return 1

        if not os.path.exists(INPUT_CSV_FILE):
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {INPUT_CSV_FILE}")
            return 1

        file_size_mb = os.path.getsize(INPUT_CSV_FILE) / 1024 / 1024
        print(f"ğŸ“„ è¾“å…¥æ–‡ä»¶å¤§å°: {file_size_mb:.1f} MB")

        resume_mode = False
        if RESUME_FROM_DIR:
            if not os.path.exists(RESUME_FROM_DIR):
                print(f"âŒ æ¢å¤ç›®å½•ä¸å­˜åœ¨: {RESUME_FROM_DIR}")
                return 1
            progress_file = os.path.join(RESUME_FROM_DIR, "progress.json")
            if not os.path.exists(progress_file):
                print(f"âŒ æ¢å¤ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°è¿›åº¦æ–‡ä»¶")
                return 1
            work_dir = RESUME_FROM_DIR
            resume_mode = True
        else:
            work_dir = get_output_dir_name(INPUT_CSV_FILE, CUSTOM_OUTPUT_DIR)
            if os.path.exists(work_dir):
                print(f"âš ï¸ è¾“å‡ºç›®å½•å·²å­˜åœ¨: {work_dir}")
                print("æ­£åœ¨åˆ é™¤å¹¶é‡å»ºç›®å½•...")
                import shutil
                shutil.rmtree(work_dir)
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤ç›®å½•: {work_dir}")

        extractor = SeparatedBatchExtractor(
            work_dir,
            INPUT_CSV_FILE,
            resume_mode
        )

        start_time = time.time()
        initial_memory = get_memory_usage()

        if not extractor.analyze_input_file(INPUT_CSV_FILE):
            print("âŒ è¾“å…¥æ–‡ä»¶åˆ†æå¤±è´¥")
            return 1

        print(f"\nğŸ’¾ åˆå§‹å†…å­˜ä½¿ç”¨: {initial_memory:.1f} MB")

        if EXTRACT_PROTEIN_FEATURES:
            if not extractor.extract_protein_features():
                print("âŒ è›‹ç™½è´¨ç‰¹å¾æå–å¤±è´¥")
                return 1

        if EXTRACT_COMPOUND_FEATURES:
            if not extractor.extract_compound_features_in_batches():
                print("âŒ åŒ–åˆç‰©ç‰¹å¾æå–å¤±è´¥")
                return 1

        extractor.save_processing_stats()
        extractor.progress_manager.mark_completed()

        end_time = time.time()
        processing_time = end_time - start_time
        final_memory = get_memory_usage()

        print("\n" + "=" * 80)
        print("ğŸ‰ åˆ†ç¦»åˆ†æ‰¹ç‰¹å¾æå–å®Œæˆ!")
        print(f"â±ï¸ æ€»å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {work_dir}")
        print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
        print(f"  æ€»è®°å½•æ•°: {extractor.total_rows}")
        print(f"  å”¯ä¸€è›‹ç™½è´¨æ•°: {len(extractor.protein_data)} ä¸ª")
        print(f"  å”¯ä¸€åŒ–åˆç‰©æ•°: {len(extractor.compound_data)} ä¸ª")
        print(f"  åŒ–åˆç‰©æ‰¹æ¬¡æ•°: {extractor.progress_manager.progress['compound_batches_total']}")
        if extractor.total_rows > 0:
            print(f"  å¹³å‡å¤„ç†é€Ÿåº¦: {extractor.total_rows / processing_time:.1f} è®°å½•/ç§’")
        print(f"\nğŸ’¾ å†…å­˜ä½¿ç”¨ç»Ÿè®¡:")
        print(f"  åˆå§‹å†…å­˜: {initial_memory:.1f} MB")
        print(f"  æœ€ç»ˆå†…å­˜: {final_memory:.1f} MB")
        progress_info = extractor.progress_manager.get_progress_info()
        print(f"  å³°å€¼å†…å­˜: {progress_info['memory_peak_mb']:.1f} MB")
        print(f"\nğŸ¯ ç‰¹å¾ç»´åº¦è¯¦æƒ…:")
        print(f"  è›‹ç™½è´¨ç‰¹å¾: {PROTEIN_TOTAL_DIM} ç»´ (AAC+DPC+Enhanced)")
        print(f"  åŒ–åˆç‰©ç‰¹å¾: {COMPOUND_TOTAL_DIM} ç»´ (GNN+ECFP4+MACCS+DTI+Pharm+RDKit)")
        error_count = len(extractor.progress_manager.progress['processing_errors'])
        if error_count > 0:
            print(f"\nâš ï¸ å¤„ç†é”™è¯¯: {error_count} ä¸ª")
        else:
            print(f"\nâœ… å¤„ç†è¿‡ç¨‹æ— é”™è¯¯")
        print("=" * 80)
        return 0

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­å¤„ç†")
        print("å¯é€šè¿‡è®¾ç½® RESUME_FROM_DIR å‚æ•°æ¢å¤è¿è¡Œ")
        if 'work_dir' in locals():
            print(f"æ¢å¤ç›®å½•è®¾ç½®ä¸º: RESUME_FROM_DIR = '{work_dir}'")
        return 1
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    print("\nğŸ”§ å½“å‰é…ç½®ä¿¡æ¯:")
    print(f"  è¾“å…¥æ–‡ä»¶: {INPUT_CSV_FILE}")
    print(f"  è¾“å‡ºç›®å½•: {CUSTOM_OUTPUT_DIR or 'è‡ªåŠ¨ç”Ÿæˆ'}")
    print(f"  æ¢å¤è¿è¡Œç›®å½•: {RESUME_FROM_DIR or 'æ— '}")
    print(f"  æµ‹è¯•æ¨¡å¼: {TEST_MODE}")
    print(f"  è°ƒè¯•æ¨¡å¼: {DEBUG_MODE}")
    print(f"\nğŸ“¦ åˆ†æ‰¹é…ç½®:")
    print(f"  åŒ–åˆç‰©æ‰¹æ¬¡å¤§å°: {COMPOUND_BATCH_SIZE}")
    print(f"  å†…å­˜é™åˆ¶: {MEMORY_LIMIT_MB} MB")
    print(f"\nğŸ¯ æå–é…ç½®:")
    print(f"  æå–è›‹ç™½è´¨ç‰¹å¾: {EXTRACT_PROTEIN_FEATURES}")
    print(f"  æå–åŒ–åˆç‰©ç‰¹å¾: {EXTRACT_COMPOUND_FEATURES}")
    print(f"  ä¿å­˜åŸå§‹æ•°æ®: {SAVE_ORIGINAL_DATA}")
    print(f"  GNNç‰¹å¾ç»´åº¦: {GNN_DIM}")
    print(f"\nğŸ¯ ç‰¹å¾ç»´åº¦:")
    print(f"  è›‹ç™½è´¨: {PROTEIN_TOTAL_DIM} ç»´")
    print(f"  åŒ–åˆç‰©: {COMPOUND_TOTAL_DIM} ç»´")
    print(f"  æ€»è®¡: {TOTAL_FEATURE_DIM} ç»´")
    exit_code = main()
    sys.exit(exit_code)